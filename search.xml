<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[王小二客栈]]></title>
    <url>%2F2018%2F02%2F17%2Fmyblog-test%2F</url>
    <content type="text"><![CDATA[只记录那二年踏过的坑]]></content>
  </entry>
  <entry>
    <title><![CDATA[java基础——String&StringBuffer]]></title>
    <url>%2F2018%2F02%2F17%2Fjava%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94String%26StringBuffer%2F</url>
    <content type="text"><![CDATA[创建字符串创建字符串最简单的方式如下:String greeting = “王小二客栈”;注意:String 类是不可改变的，所以你一旦创建了 String 对象，那它的值就无法改变了。如果需要对字符串做很多修改，那么应该选择使用 StringBuffer &amp; StringBuilder 类。 字符串长度用于获取有关对象的信息的方法称为访问器方法。String 类的一个访问器方法是 length() 方法，它返回字符串对象包含的字符数。 连接字符串String 类提供了连接两个字符串的方法：string1.concat(string2);更常用的是使用’+’操作符来连接字符串，如：“Hello,” + “ xiaoer” + “!” String 方法 char charAt(int index) 返回指定索引处的char值。 int compareTo（Object o） 把这个字符串和另一个对象比较。 int compareTo(String anotherString) 按字典顺序比较两个字符串。 int compareToIgnoreCase(String str) 按字典顺序比较两个字符串，不考虑大小写。 String concat(String str) 将指定字符串连接到此字符串的结尾。 boolean contentEquals(StringBuffer sb) 当且仅当字符串与指定的StringButter有相同顺序的字符时候返回真。 static String copyValueOf(char[] data) 返回指定数组中表示该字符序列的 String。 static String copyValueOf(char[] data, int offset, int count) 返回指定数组中表示该字符序列的 String。 boolean endsWith(String suffix) 测试此字符串是否以指定的后缀结束。 boolean equals(Object anObject) 将此字符串与指定的对象比较。 boolean equalsIgnoreCase(String anotherString) 将此 String 与另一个 String 比较，不考虑大小写。 byte[] getBytes() 使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。 byte[] getBytes(String charsetName) 使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。 void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin) 将字符从此字符串复制到目标字符数组。 int hashCode() 返回此字符串的哈希码。 int indexOf(int ch) 返回指定字符在此字符串中第一次出现处的索引。 int indexOf(int ch, int fromIndex) 返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。 int indexOf(String str) 返回指定子字符串在此字符串中第一次出现处的索引。 int indexOf(String str, int fromIndex) 返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。 String intern() 返回字符串对象的规范化表示形式。 int lastIndexOf(int ch) 返回指定字符在此字符串中最后一次出现处的索引。 int lastIndexOf(int ch, int fromIndex) 返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。 int lastIndexOf(String str) 返回指定子字符串在此字符串中最右边出现处的索引。 int lastIndexOf(String str, int fromIndex) 返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索。 int length() 返回此字符串的长度。 boolean matches(String regex) 告知此字符串是否匹配给定的正则表达式。 boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len) 测试两个字符串区域是否相等。 boolean regionMatches(int toffset, String other, int ooffset, int len) 测试两个字符串区域是否相等。 String replace(char oldChar, char newChar) 返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。 String replaceAll(String regex, String replacement) 使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。 String[] split(String regex) 根据给定正则表达式的匹配拆分此字符串。 String[] split(String regex, int limit) 根据匹配给定的正则表达式来拆分此字符串。 boolean startsWith(String prefix) 测试此字符串是否以指定的前缀开始。 boolean startsWith(String prefix, int toffset) 测试此字符串从指定索引开始的子字符串是否以指定前缀开始。 CharSequence subSequence(int beginIndex, int endIndex) 返回一个新的字符序列，它是此序列的一个子序列。 String substring(int beginIndex) 返回一个新的字符串，它是此字符串的一个子字符串。 String substring(int beginIndex, int endIndex) 返回一个新字符串，它是此字符串的一个子字符串。 char[] toCharArray() 将此字符串转换为一个新的字符数组。 String toLowerCase() 使用默认语言环境的规则将此 String 中的所有字符都转换为小写。 String toLowerCase(Locale locale) 使用给定 Locale 的规则将此 String 中的所有字符都转换为小写。 String toString() 返回此对象本身（它已经是一个字符串！）。 String toUpperCase() 使用默认语言环境的规则将此 String 中的所有字符都转换为大写。 String toUpperCase(Locale locale) 使用给定 Locale 的规则将此 String 中的所有字符都转换为大写。 String trim() 返回字符串的副本，忽略前导空白和尾部空白。 static String valueOf(primitive data type x) 返回给定data type类型x参数的字符串表示形式。]]></content>
  </entry>
  <entry>
    <title><![CDATA[王小二客栈——Java Number&Math]]></title>
    <url>%2F2018%2F02%2F17%2Fjava%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94Number%26Math%2F</url>
    <content type="text"><![CDATA[忆往昔峥嵘岁月，不堪入目 1.所有的包装类（Integer、Long、Byte、Double、Float、Short）都是抽象类Number的子类。 2.Java的Math包含了用于执行基本数学运算的属性和方法，如初等指数、对数、平方根和三角函数等。 Math的方法都被定义为static形式，通过Math类可以在主函数中直接调用。 下面列出Number &amp; Math类常用的一些方法： xxxValue() 将Number对象装换成xxx数据类型的值并返回。 compareTo（） 将number对象与参数比较。 equals() 判断number对象是否与参数相等。 valueOf() 返回一个Number对象制定的内置数据类型。 toString() 以字符串形式返回值。 parseInt() 将字符串解析为int类型。 abs() 返回参数的绝对值。 ceil（） 返回大于等于（&gt;=）给定参数的最小整数。 floor() 返回小雨等于（&lt;=）给定参数的最大整数。 rint（） 返回与参数最接近的整数，返回类型为double。 round() 他表示四舍五入。 min() 返回两个参数之间的最小值。 max() 返回两个参数之间的最大值。 exp（） 返回自然数底数e的参数次方。 log() 返回参数的自然数底数的对数值。 random（) 返回一个随机数。 Java Character 类 Character 类用于对单个字符进行操作。 Character 类在对象中包装一个基本类型 char 的值。转义序列转义序列 描述\t 在文中该处插入一个tab键\b 在文中该处插入一个后退键\n 在文中该处换行\r 在文中该处插入回车\f 在文中该处插入换页符\’ 在文中该处插入单引号\” 在文中该处插入双引号\ 在文中该处插入反斜杠 Character 方法isLetter() 是否是一个字母isDigit() 是否是一个数字字符isWhitespace() 是否为一个空格isUpperCase() 是否是大写字母isLowCase() 是否是小写字母toUpperCase() 制定之母的大写形式toLowCase() 制定之母的小写形式toString() 返回字符的字符串形式，字符串的长短仅为1。]]></content>
      <categories>
        <category>programming</category>
      </categories>
      <tags>
        <tag>youth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java读取Excel表格中的数据]]></title>
    <url>%2F2018%2F02%2F17%2Fjava%E8%AF%BB%E5%8F%96Excel%E8%A1%A8%E6%A0%BC%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[1.需求用java代码读取Excel.xls表格中的数据 2.java代码package com.test;import java.io.File;import jxl.*;public class ReadExcel{ public static void main(String[] args){ ing i; Sheet sheet; Workbook book; Cell cell1,cell2,cell3,cell4,cell5,cell6,cell7; try{ //Excel.xls为要读取的excel文件 book = Workbook.getWorkbook(new File(&quot;文件物理地址&quot;)))； //获取第一个工作表对象（excel中sheet的编号从0开始，0,1,2,3，.....） sheet = book.getSheet(0); //获取左上角的单元格 cell1 = sheet.getCell(0,0);(行，列) System.out.println(&quot;标题：&quot;+cell1.getContents()); i = 1; while(true){ //获取每一行单元格 cell1 = sheet.getCell(0,i); cell2 = sheet.getCell(1,i); cell3 = sheet.getCell(2,i); cell4 = sheet.getCell(3,i); cell5 = sheet.getCell(4,i); cell6 = sheet.getCell(5,i); cell7 = sheet.getCell(6,i); if(&quot;&quot;.equals(cell1.getContents()) == true) //如果读取的数据为空 break; System.out.println(cell1.getContents()+&quot;\t&quot;+cell2.getContents()+&quot;\t&quot;+cell3.getContents()+&quot;\t&quot;+cell4.getContents()+&quot;\t&quot;+cell5.getContents()+&quot;\t&quot;+cell6.getContents()+&quot;\t&quot;); i++; } book.close(); } catch(Exceprion e){ } } }]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hbase-写入方式]]></title>
    <url>%2F2018%2F02%2F17%2FHbase-5%E7%A7%8D%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[只记录那二年踏过的坑HBase写入数据方式（参考：《HBase The Definitive Guide》） 1.直接使用HTable进行导入，代码如下： package hbase.curd;import java.io.IOException;import java.util.ArrayList;import java.util.List;impirt java.util.Random;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.client.Put;import org.apache.hadoop.hbase.util.Bytes; public class PutExample{ private HTable table = HTableUtil.getHTable(&quot;testtable&quot;); public static void main(String args[]) throws IOException{ PutExample pe = new PutExample(); pe.putRows(); } public void putRows(){ List&lt;Put&gt; puts = new ArrayList&lt;Put&gt;; for(int i=0; i&lt;10; i++){ Put put = new Put(Bytes.toBytes(&quot;row_&quot;+i)); Rowdom random = new Random(); if(random.nextBoolean()){ put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i)); } if(random.nextBoolean()){ put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i)); } if(random.nextBoolean()){ put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual3&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i)); } if(random.nextBoolean()){ put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual4&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i)); } if(random.nextBoolean()){ put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual5&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i)); } puts.add(put); } try{ table.put(puts); table.close(); }catch(Exception e){ e.printStackTrace(); return ; } System.out.println(&quot;done put rows&quot;); } } } 其中HTableUtil如下：package hbase.curd; import java.io.IOException; import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.hbase.HBaseConfiguration;import org.apache.hadoop.hbase.client.HTable;import org.apache.hadoop.hbase.util.Bytes; public class HTableUtil { private static HTable table; private static Configuration conf; static{ conf =HBaseConfiguration.create(); conf.set(&quot;mapred.job.tracker&quot;, &quot;hbase:9001&quot;); conf.set(&quot;fs.default.name&quot;, &quot;hbase:9000&quot;); conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;hbase&quot;); try { table = new HTable(conf,&quot;testtable&quot;); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } public static Configuration getConf(){ return conf; } public static HTable getHTable(String tablename){ if(table==null){ try { table= new HTable(conf,tablename); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } return table; } public static byte[] gB(String name){ return Bytes.toBytes(name); } }]]></content>
  </entry>
  <entry>
    <title><![CDATA[Centos7伪分布式安装Hadoop2.6和Hbase0.94]]></title>
    <url>%2F2018%2F02%2F17%2Fcentos7%2Bhadoop2.6%2Bhbase1.0.x%2F</url>
    <content type="text"><![CDATA[只记录那二年踏过的坑一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。 卸载： yum -y remove java javaxxxxx(系统自带的Java版本) 安装jdk，将jdk.tar.gz文件复制到/usr/java中,终端进入/mnt/share ,cp jdk.tar.gz /usr/ava，进入/usr/java解压：tar xzvf jdk.targz 配置环境变量：vi /etc/profile 输入i编辑在尾部添加：export JAVA_HOME=/usr/java/jdkxxxxexport PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 保存并退出： wq使修改生效： source /etc/profile查看Java版本：java -version 二、Hadoop伪分布式安装 1、ssh无密码登陆 终端：ssh-keygen -t rsa (获得rsa公钥私钥,id_rsa和id_rsa.pub)cd .sshcp id_rsa.pub authorized_keys (将公钥复制给authorized_keys) &lt;分布式则要将所有节点id_rsa.pub相互复制&gt; 2、 /mnt/share cp hadoop2.x /usr.hadoop 解压tar xzvf hadoop 2.x 3、修改core-site.xml、hadoop-env.sh、hdfs-site.xml、mapred-site.xml 、yarn-site.xml(hadoop2.x版本的配置文件在/hadoop2.x/etc/hadoop下) ①core-site.xml： fs.default.name hdfs://localhost:9000 ② hadoop-env.sh：export JAVA_HOME=/usr/java/jdkxxx (jdk路径) ③ hdfs-site.xml： 先创建好数据节点和名称节点的存放路径 dfs.datanode.data.dir /user/hadoop/hadoop-2.5.1/data dfs.namenode.name.dir /user/hadoop/hadoop-2.5.1/name dfs.replication 1 ④mapred-site.xml: (注意：这个文件是将/hadoop2.x/etc/hadoop下的mapred-site.xml.template复制并重命名 ) mapreduce.framework.name yarn ⑤yarn-site.xml： yarn.nodemanager.aux-services mapreduce_shuffle 4、namenode格式化（一定要完成） 终端：cd /usr/hadoop/hadoop-2.5.1/bin ./hdfs namenode -format (输入./hadoop namenode -format也行) 5、运行hadoop 终端： cd /usr/hadoop/hadoop-2.5.1/sbin (2.x版本后启动/停止在sbin目录下)./start-hdfs.sh./start-yarn.sh(也可以只输入./start-all.sh) 输入jps查看启动项，当启动了NameNode、DataNode、SecondaryNameNode、ResourceManager、NodeManager即ok。 可进入Firefox中，输入端口号： localhost:50070 进入hadoop可视化页面。 三、Hbase0.94安装 1、/mnt/share cp hbase1.0.1 /usr.hbase 解压tar xzvf hbase1.0.1 2、修改hbase配置文件hbase-env.sh、hbase-site.xml hbase-env.sh: export JAVA_HOME=/usr/java/jdkxxxx (java路径)export HBASE_MANAGES_ZK=true (都得去掉前面#) hbase-site.xml： hbase.rootdir hdfs://localhost:9000/hbase hbase.cluster.distributed true hbase.zookeeper.quorum localhost hbase.tmp.dir file:/usr/hbase/tmp hbase.zookeeper.property.dataDir file:/usr/hbase/zookeeperdata 3、运行hbase 运行前需先启动hadoop，再进入hbase的bin目录下输入指令 ./start-hbase.sh输入jps查看启动项，如有HMaster、HRegionServer、HQuormPeer,则说明hbase启动成功。输入./hbase Shell (进入shell指令，可通过shell指令建表)]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos 6.5 内核升级]]></title>
    <url>%2F2018%2F02%2F17%2Fcentos6.5%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[1.查看centos的内核版本rname -r 2.查看系统版本cat /etc/centos-release 3.安装软件编译安装新内核，依赖于开发环境和开发库yum grouplist //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库； yum groupinstall “Development Tools” //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具 yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行 yum install qt-devel //如果你没有 X 环境，这一条可以不用 yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们 4.编译内核Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成： r.x.y r: 主版本号 x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。 y: 修订版本号 ， 表示修改的次数官网上有stable, longterm等版本，longterm是比stable更稳定的版本。[root@sean ~]#curl -O -L https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz [root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/ [root@sean ~]# cd /usr/src/linux-3.10.58/ [root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config 我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置：`[root@sean linux-3.10.58]# sh -c ‘yes “” | make oldconfig’ HOSTCC scripts/basic/fixdep HOSTCC scripts/kconfig/conf.o SHIPPED scripts/kconfig/zconf.tab.c SHIPPED scripts/kconfig/zconf.lex.c SHIPPED scripts/kconfig/zconf.hash.c HOSTCC scripts/kconfig/zconf.tab.o HOSTLD scripts/kconfig/conf scripts/kconfig/conf –oldconfig Kconfig .config:555:warning: symbol value ‘m’ invalid for PCCARD_NONSTATIC.config:2567:warning: symbol value ‘m’ invalid for MFD_WM8400.config:2568:warning: symbol value ‘m’ invalid for MFD_WM831X.config:2569:warning: symbol value ‘m’ invalid for MFD_WM8350.config:2582:warning: symbol value ‘m’ invalid for MFD_WM8350_I2C.config:2584:warning: symbol value ‘m’ invalid for AB3100_CORE.config:3502:warning: symbol value ‘m’ invalid for MMC_RICOH_MMC * Restart config… * * General setup * …… XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW) Averaging functions (AVERAGE) [Y/?] (NEW)yCORDIC algorithm (CORDIC) [N/m/y/?] (NEW) JEDEC DDR data (DDR) [N/y/?] (NEW) # configuration written to .config`make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写，然后备份.config文件为.config.old，并生成新的.config文件 5.开始编译[root@sean linux-3.10.58]# make -j4 bzImage //生成内核文件[root@sean linux-3.10.58]# make -j4 modules //编译模块[root@sean linux-3.10.58]# make -j4 modules_install //编译安装模块 -j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟） 6.安装[root@sean linux-3.10.58]# make install实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入HYPERVISOR_GUEST=yCONFIG_VMWARE_BALLOON=m（这一部分比较容易出问题，参考下文异常部分） 7.修改grub引导，重启安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。编辑 grub.conf文件，vi /etc/grub.conf #boot=/dev/sdadefault=0timeout=5splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenutitle CentOS (3.10.58) root (hd0,0)… 数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。重启reboot now 8.确认当内核版本[root@sean ~]# uname -r3.10.58 升级内核成功!]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos6.5下搭建hadoop2.7单机伪分布环境]]></title>
    <url>%2F2018%2F02%2F17%2Fcentos6.5%2Bhadoop2.7%2F</url>
    <content type="text"><![CDATA[设置固定IP地址及网关 设置IPvi /etc/sysconfig/network-scripts/ifcfg-eth0 修改内容如下DEVICE=eth0HWADDR=08:00:27:BD:9D:B5 #不用改TYPE=EthernetUUID=53e4e4b6-9724-43ab-9da7-68792e611031 #不用改ONBOOT=yes #开机启动NM_CONTROLLED=yesBOOTPROTO=static #静态IPIPADDR=192.168.30.50 #IP地址NETMASK=255.255.255.0 #子网掩码 设置网关vi /etc/sysconfig/network 添加内容NETWORKING=yesHOSTNAME=Hadoop.MasterGATEWAY=192.168.30.1 #网关 设置DNSvi /etc/resolv.conf 添加内容nameserver xxx.xxx.xxx.xxx #根据实际情况设置nameserver 114.114.114.114 #可以设置多个 重启网卡service network restart 设置主机名对应IP地址vi /etc/hosts#添加如下内容192.168.30.50 Hadoop.Master添加Hadoop用户 添加用户组groupadd hadoop 添加用户并分配用户组useradd -g hadoop hadoop 修改用户密码passwd hadoop关闭服务 关闭防火墙service iptables stop #关闭防火墙服务chkconfig iptables off #关闭防火墙开机启动service ip6tables stopchkconfig ip6tables off 关闭SELinuxvi /etc/sysconfig/selinux#修改如下内容SELINUX=enforcing -&gt; SELINUX=disabled#再执行如下命令setenforce 0getenforce 关闭其他服务VSFTP安装与配置 检查是否安装chkconfig –list|grep vsftpd 安装vsftpyum -y install vsftpd 创建日志文件touch /var/log/vdftpd.log 配置vsftpd服务vi /etc/vsftpd/vsftpd.conf#修改如下内容anonymous_enable=NO #关闭匿名访问xferlog_file=/var/log/vsftpd.log #设置日志文件 – 我们上一步所创建的文件idle_session_timeout=600 #会话超时时间async_abor_enable=YES #开启异步传输ascii_upload_enable=YES #开启ASCII上传ascii_download_enable=YES #开启ASCII下载 查看vsftp运行状态service vsftpd status启动vsftpservice vsftpd start#重启 service vsftpd restart#关闭 service vsftpd stop 查看vsftpd服务启动项chkconfig –list|grep vsftpd 设置vsftp开机启动chkconfig vsftpd onSSH无密码配置 查看ssh与rsync安装状态rpm -qa|grep opensshrpm -qa|grep rsync 安装ssh与rsyncyum -y install sshyum -y install rsync 切换hadoop用户su - hadoop 生成ssh密码对ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsa 将id_dsa.pub追加到授权的key中cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys设置授权key权限chmod 600 ~/.ssh/authorized_keys#权限的设置非常重要，因为不安全的设置安全设置，会让你不能使用RSA功能测试ssh连接ssh localhost#如果不需要输入密码，则是成功安装Java 下载地址http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html 注：我这里使用的是：jdk-7u80-linux-i586.tar.gz 安装Java切换至root用户su root 创建/usr/java文件夹mkdir /usr/java 使用winscp工具上传至服务器 将压缩包上传至/home/hadoop目录 注：我这里使用的是winscp，使用hadoop用户连接 将压缩包解压至/usr/java 目录tar zxvf /home/hadoop/jdk-7u80-linux-i586.tar.gz -C /usr/java/ 设置环境变量vi /etc/profile#追加如下内容export JAVA_HOME=/usr/java/jdk1.7.0_80export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/libexport PATH=$PATH:$JAVA_HOME/bin 使环境变量生效source /etc/profile 测试环境变量设置java -versionHadoop安装与配置下载地址http://hadoop.apache.org/releases.html 注:我下载的是hadoop-2.7.1.tar.gz 安装Hadoop使用winscp工具上传至服务器将压缩包上传至/home/hadoop目录*将压缩包解压至/usr目录tar zxvf /home/hadoop/hadoop-2.7.1.tar.gz -C /usr/ 修改文件夹名称mv /usr/hadoop-2.7.1/ /usr/hadoop 创建hadoop数据目录mkdir /usr/hadoop/tmp 将hadoop文件夹授权给hadoop用户chown -R hadoop:hadoop /usr/hadoop/ 设置环境变量vi /etc/profile#追加如下内容export HADOOP_HOME=/usr/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport HADOOP_OPTS=”-Djava.library.path=$HADOOP_HOME/lib 使环境变量生效source /etc/profile 测试环境变量设置hadoop version配置HDFS 切换至Hadoop用户su - hadoop 修改hadoop-env.shcd /usr/hadoop/etc/hadoop/vi hadoop-env.sh#追加如下内容export JAVA_HOME=/usr/java/jdk1.7.0_80 修改core-site.xmlvi core-site.xml#添加如下内容 fs.defaultFS hdfs://Hadoop.Master:9000 hadoop.tmp.dir /usr/hadoop/tmp/ A base for other temporary directories. 修改hdfs-site.xmlvi hdfs-site.xml#添加如下内容 dfs.replication 1 格式化hdfshdfs namenode -format注：出现Exiting with status 0即为成功 启动hdfsstart-dfs.sh#停止命令 stop-dfs.sh注：输出如下内容15/09/21 18:09:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicableStarting namenodes on [Hadoop.Master]Hadoop.Master: starting namenode, logging to /usr/hadoop/logs/hadoop-hadoop-namenode-Hadoop.Master.outHadoop.Master: starting datanode, logging to /usr/hadoop/logs/hadoop-hadoop-datanode-Hadoop.Master.outStarting secondary namenodes [0.0.0.0]The authenticity of host ‘0.0.0.0 (0.0.0.0)’ can’t be established.RSA key fingerprint is b5:96:b2:68:e6:63:1a:3c:7d:08:67:4b:ae:80:e2:e3.Are you sure you want to continue connecting (yes/no)? yes0.0.0.0: Warning: Permanently added ‘0.0.0.0’ (RSA) to the list of known hosts.0.0.0.0: starting secondarynamenode, logging to /usr/hadoop/logs/hadoop-hadoop-secondarynamenode-Hadoop.Master.out15/09/21 18:09:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicab 查看进程jps注：输出类似如下内容1763 NameNode1881 DataNode2146 Jps2040 SecondaryNameNode 使用web查看Hadoop运行状态http://你的服务器ip地址:50070/在HDFS上运行WordCount 创建HDFS用户目录hdfs dfs -mkdir /userhdfs dfs -mkdir /user/hadoop #根据自己的情况调整/user/ 复制输入文件（要处理的文件）到HDFS上hdfs dfs -put /usr/hadoop/etc/hadoop input 查看我们复制到HDFS上的文件hdfs dfs -ls input 运行单词检索（grep）程序hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output ‘dfs[a-z.]+’#WordCount#hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount input output#说明：output文件夹如已经存在则需要删除或指定其他文件夹。 查看运行结果hdfs dfs -cat output/*配置YARN 修改mapred-site.xmlcd /usr/hadoop/etc/hadoop/cp mapred-site.xml.template mapred-site.xmlvi mapred-site.xml#添加如下内容 mapreduce.framework.name yarn 修改yarn-site.xmlvi yarn-site.xml#添加如下内容 yarn.nodemanager.aux-services mapreduce_shuffle 启动YARNstart-yarn.sh#停止yarn stop-yarn.sh 查看当前java进程jsp#输出如下4918 ResourceManager1663 NameNode1950 SecondaryNameNode5010 NodeManager5218 Jps1759 DataNode 运行你的mapReduce程序 配置好如上配置再运行mapReduce程序时即是yarn中运行。 使用web查看Yarn运行状态http://你的服务器ip地址:8088/ HDFS常用命令 创建HDFS文件夹 在根目录创建input文件夹hdfs dfs -mkdir -p /input 在用户目录创建input文件夹说明：如果不指定“/目录”，则默认在用户目录创建文件夹hdfs dfs -mkdir -p input#等同于 hdfs dfs -mkdir -p /user/hadoop/input 查看HDFS文件夹 查看HDFS根文件夹hdfs dfs -ls / 查看HDFS用户目录文件夹hdfs dfs -ls 查看HDFS用户目录文件夹下input文件夹hdfs dfs -ls input#等同与 hdfs dfs -ls /user/hadoop/input 复制文件到HDFShdfs dfs -put /usr/hadoop/etc/hadoop input 删除文件夹hdfs dfs -rm -r input]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker安装]]></title>
    <url>%2F2018%2F02%2F05%2Fdocker%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[1：关闭selinux临时关闭：setenforce 0永久关闭： 1. vi /etc/sysconfig/selinux插入/编辑以下内容SELINUX=disabled #重启生效 2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel：rpm -ivh http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpmsed -i ‘s/^mirrorlist=https/mirrorlist=http/‘ /etc/yum.repos.d/epel.repo（elpe.repo）[epel]name=epelmirrorlist=http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearchenabled=1gpgcheck=0 3：安装dockeryum install docker-io安装完成后 4：启动dockerservice docker start 5：查看docker版本docker vesion 6：查看docker日志cat /var/log/docker docker安装完成 一：卸载docker列出你安装过的包[root@localhost ~]# yum list installed | grep dockerdocker-io.x86_64 1.7.1-2.el6 @epel删除软件包yum -y remove docker-io.x86_64删除镜像/容器等rm -rf /var/lib/docker 二：升级docker版本为1.10.3升级之前停止docker服务,并将原有的docker服务进行备份. mv /usr/bin/docker /usr/bin/docker.bak nohup wget -c https://get.docker.com/builds/Linux/x86_64/docker-1.10.3 -O /usr/bin/docker给执行权限：chmod 755 /usr/bin/docker 然后重启服务，并查看版本. 报错：Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failedFailed to parse /etc/cgconfig.conf [FAILED]Starting docker: [ OK ] 修改：/etc/cgconfig.conf文件mount { cpuset = /cgroup/cpuset; cpu = /cgroup/cpu; cpuacct = /cgroup/cpuacct; memory = /cgroup/memory;devices = /cgroup/devices; freezer = /cgroup/freezer; net_cls = /cgroup/net_cls; blkio = /cgroup/blkio; }重新启动docker 正常]]></content>
  </entry>
  <entry>
    <title><![CDATA[错误及解决方案]]></title>
    <url>%2F2018%2F02%2F05%2Fambari%E6%90%AD%E5%BB%BA%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[ERROR: Exiting with exit code 1.REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and /var/log/ambari-server/ambari-server-check-database.log for more information.解决方法：查看日志，具体什么错.例如：数据库未开启、数据库配置问题 撤销已经赋予给 MySQL 用户权限的权限。revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：revoke all on . from ‘root’@’192.168.0.197’; [root@datanode01 ~]# yum makecacheLoaded plugins: fastestmirrorDetermining fastest mirrorsambari-2.4.1.0 | 2.9 kB 00:00ambari-2.4.1.0/filelists_db | 139 kB 00:00ambari-2.4.1.0/primary_db | 8.3 kB 00:00ambari-2.4.1.0/other_db | 1.3 kB 00:00file:///mnt/repodata/repomd.xml: [Errno 14] Could not open/read file:///mnt/repodata/repomd.xmlTrying other mirror.Error: Cannot retrieve repository metadata (repomd.xml) for repository: c6-media. Please verify its path and try again 如果有后面两个文件，处理方式mv CentOS-Media.repo CentOS-Media.repo.bak没有的话，源问题，换源repos tip:1、当提示要做如下操作的时候Be?sure?you?have?run:ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/path/to/mysql/**需要下载mysql-connector-java-5.1.39.tar驱动，解压得到mysql-connector-java-5.1.39-bin.jar文件执行如下命令：ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/usr/lib/java/mysql-connector-java-5.1.39/mysql-connector-java-5.1.39-bin.jar同时，设置文件权限为644 2017.7.191.ERROR namenode.NameNode (NameNode.java:main(1759)) - Failed to start namenode.java.net.BindException: Port in use: datanode01:50070 不能获取映射地址，需要修改hosts中的映射ip为真实ip（ifconfig）2.错删自定义的service导致不能登录amnari UI（日志报出database问题） （百度方案无解，最后重装ambari-server(发现重装无法下手，百度后删除ambari相关组件以及数据库的完全卸载，完成)）3.使用ambari-server启动HDFS时，DataNode无法启动（出现port in use：localhost 0）。解决方式，在hosts文件中localhost 172.0.0.1被#；去除#后解决 一般故障排除Ambari服务器：检查/var/log/ambari-server/ambari-server.[log|out]是否存在错误。Ambari代理：检查/var/log/ambari-agent/ambari-agent.[log|out]是否存在错误。请注意，如果Ambari Agent在/var/log/ambari-agent/ambari-agent.out中有任何输出，则表明存在重大问题。 服务无法启动HDFS：检查/ var / log / hadoop / hdfs下的日志文件MapReduce：检查/ var / log / hadoop / mapred下的日志文件HBase：检查/ var / log / hbase下的日志文件Hive：检查/ var / log / hive下的日志文件Oozie：检查/ var / log / oozie下的日志文件ZooKeeper：检查/ var / log / zookeeper下的日志文件WebHCat：检查/ var / log / webhcat下的日志文件Nagios：检查/ var / log / nagios下的日志文件 2017.7.20Service ‘userhome’ check failed: java.io.FileNotFoundException: File does not exist: /user/admin解决方案：sudo -u hdfs hdfs dfs -mkdir /user/adminsudo -u hdfs hdfs dfs -chown admin:hadoop /user/admin 资源池问题FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed forblock pool Block pool BP-1480406410-192.168.1.181-1398701121586 (storage idDS-167510828-192.168.1.191-50010-1398750515421)原因：每次namenode format会重新创建一个namenodeId,而data目录包含了上次format时的id,namenode format清空了namenode下的数据,但是没有清空datanode下的数据,导致启动时失败,所要做的就是每次fotmat前,清空data下的所有目录.: d6 E2 t&amp; M” g7 a* q3 l, H解决办法：停掉集群，删除问题节点的data目录下的所有内容。即hdfs-site.xml文件中配置的dfs.data.dir目录。重新格式化namenode。 另一个更省事的办法：先停掉集群，然后将datanode节点目录/dfs/data/current/VERSION中的修改为与namenode一致即可。其实我没解决，直接重装 block missing问题会导致进入安全模式：处理方式，删除缺失包，在HDFS用户下退出安全模式 添加节点时，需要查看该节点root磁盘下的剩余大小，如果磁盘空间不足，则扩大磁盘再添加节点。不要问我为什么，说多了都是泪。集群就是这么崩盘的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[amabri卸载]]></title>
    <url>%2F2018%2F02%2F05%2Fambari%E5%8D%B8%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[1.删除hdp.repo和hdp-util.repocd /etc/yum.repos.d/rm -rf hdprm -rf HDPrm -rf ambari* 2.删除安装包用yum list installed | grep HDP来检查安装的ambari的包yum remove -y sqoop.noarchyum remove -y lzo-devel.x86_64yum remove -y hadoop-libhdfs.x86_64yum remove -y rrdtool.x86_64yum remove -y hbase.noarchyum remove -y pig.noarchyum remove -y lzo.x86_64yum remove -y ambari-log4j.noarchyum remove -y oozie.noarchyum remove -y oozie-client.noarchyum remove -y gweb.noarchyum remove -y snappy-devel.x86_64yum remove -y hcatalog.noarchyum remove -y python-rrdtool.x86_64yum remove -y nagios.x86_64yum remove -y webhcat-tar-pig.noarchyum remove -y snappy.x86_64yum remove -y libconfuse.x86_64yum remove -y webhcat-tar-hive.noarchyum remove -y ganglia-gmetad.x86_64yum remove -y extjs.noarchyum remove -y hive.noarchyum remove -y hadoop-lzo.x86_64yum remove -y hadoop-lzo-native.x86_64yum remove -y hadoop-native.x86_64yum remove -y hadoop-pipes.x86_64yum remove -y nagios-plugins.x86_64yum remove -y hadoop.x86_64yum remove -y zookeeper.noarchyum remove -y hadoop-sbin.x86_64yum remove -y ganglia-gmond.x86_64yum remove -y libganglia.x86_64yum remove -y perl-rrdtool.x86_64yum remove -y epel-release.noarchyum remove -y compat-readline5*yum remove -y fping.x86_64yum remove -y perl-Crypt-DES.x86_64yum remove -y exim.x86_64yum remove -y ganglia-web.noarchyum remove -y perl-Digest-HMAC.noarchyum remove -y perl-Digest-SHA1.x86_64yum remove -y bigtop-jsvc.x86_64 3.删除快捷方式cd /etc/alternativesrm -rf hadoop-etcrm -rf zookeeper-confrm -rf hbase-confrm -rf hadoop-logrm -rf hadoop-librm -rf hadoop-defaultrm -rf oozie-confrm -rf hcatalog-confrm -rf hive-confrm -rf hadoop-manrm -rf sqoop-confrm -rf hadoop-conf 4.删除用户userdel nagiosuserdel hiveuserdel ambari-qauserdel hbaseuserdel oozieuserdel hcatuserdel mapreduserdel hdfsuserdel rrdcacheduserdel zookeeper #userdel mysqluserdel sqoopuserdel puppetuserdel yarnuserdel tezuserdel hadoopuserdel knoxuserdel stormuserdel falconuserdel flumeuserdel nagiosuserdel adminuserdel postgresuserdel hdfsuserdel zookeeperuserdel hbase 5.删除文件夹rm -rf /hadooprm -rf /etc/hadooprm -rf /etc/hbaserm -rf /etc/hcatalogrm -rf /etc/hiverm -rf /etc/gangliarm -rf /etc/nagiosrm -rf /etc/oozierm -rf /etc/sqooprm -rf /etc/zookeeperrm -rf /var/run/hadooprm -rf /var/run/hbaserm -rf /var/run/hiverm -rf /var/run/gangliarm -rf /var/run/nagiosrm -rf /var/run/oozierm -rf /var/run/zookeeperrm -rf /var/log/hadooprm -rf /var/log/hbaserm -rf /var/log/hiverm -rf /var/log/nagiosrm -rf /var/log/oozierm -rf /var/log/zookeeperrm -rf /usr/lib/hadooprm -rf /usr/lib/hbaserm -rf /usr/lib/hcatalogrm -rf /usr/lib/hiverm -rf /usr/lib/oozierm -rf /usr/lib/sqooprm -rf /usr/lib/zookeeperrm -rf /var/lib/hiverm -rf /var/lib/gangliarm -rf /var/lib/oozierm -rf /var/lib/zookeeperrm -rf /var/tmp/oozierm -rf /tmp/hiverm -rf /tmp/nagiosrm -rf /tmp/ambari-qarm -rf /tmp/sqoop-ambari-qarm -rf /var/nagiosrm -rf /hadoop/oozierm -rf /hadoop/zookeeperrm -rf /hadoop/mapredrm -rf /hadoop/hdfsrm -rf /tmp/hadoop-hiverm -rf /tmp/hadoop-nagiosrm -rf /tmp/hadoop-hcatrm -rf /tmp/hadoop-ambari-qarm -rf /tmp/hsperfdata_hbaserm -rf /tmp/hsperfdata_hiverm -rf /tmp/hsperfdata_nagiosrm -rf /tmp/hsperfdata_oozierm -rf /tmp/hsperfdata_zookeeperrm -rf /tmp/hsperfdata_mapredrm -rf /tmp/hsperfdata_hdfsrm -rf /tmp/hsperfdata_hcatrm -rf /tmp/hsperfdata_ambari-qarm -rf /etc/flumerm -rf /etc/stormrm -rf /etc/hive-hcatalogrm -rf /etc/tezrm -rf /etc/falconrm -rf /var/run/flumerm -rf /var/run/stormrm -rf /var/run/webhcatrm -rf /var/run/hadoop-yarnrm -rf /var/run/hadoop-mapreducerm -rf /var/log/flumerm -rf /var/log/stormrm -rf /var/log/hadoop-yarnrm -rf /var/log/hadoop-mapreducerm -rf /usr/lib/nagiosrm -rf /var/lib/hdfsrm -rf /var/lib/hadoop-hdfsrm -rf /var/lib/hadoop-yarnrm -rf /var/lib/hadoop-mapreducerm -rf /tmp/hadoop-hdfs 5.重置数据库，删除ambari包#采用这句命令来检查yum list installed | grep ambariambari-server stopambari-agent stopambari-server resetyum remove -y ambari-yum remove -y postgresqlrm -rf /etc/yum.repos.d/ambarirm -rf /var/lib/ambarirm -rf /var/log/ambarirm -rf /etc/ambari*]]></content>
  </entry>
  <entry>
    <title><![CDATA[docker]]></title>
    <url>%2F2018%2F02%2F05%2Fdocker-1%2F</url>
    <content type="text"><![CDATA[title: docker安装基本环境配置 1：关闭selinux 临时关闭：setenforce 0 永久关闭： vi /etc/sysconfig/selinux插入/编辑以下内容 SELINUX=disabled#重启生效 2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel： rpm -ivh http://mirrors.sohu.com/fedora- epel/6/x86_64/epel-release-6-8.noarch.rpm sed -i &#39;s/^mirrorlist=https/mirrorlist=http/&#39; /etc/yum.repos.d/epel.repo （elpe.repo） *[epel]* name=epel mirrorlist=http://mirrors.fedoraproject.org/mirrorlist? repo=epel-$releasever&amp;arch=$basearch enabled=1 gpgcheck=0’ 3：安装docker yum install docker-io 安装完成后 4：启动docker service docker start 5：查看docker版本 docker vesion 6：查看docker日志cat /var/log/docker docker安装完成]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ambari搭建]]></title>
    <url>%2F2016%2F11%2F09%2Fambari%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1.物理条件：三台centos前期条件：修改每台centos的名称，分别为namenode、datanode01、datanode02 ssh免密码配置：namenode 可以免密码登录到datanode01、datanode02配置ssh 在namenode上生成密钥对：ssh-keygen –t rsa 在/root/.ssh中会有生成的密钥对 将namenode 的 id_rsa.pub写入datanode01的/root/.ssh authorized_keys文件中。再将datanode01的authorized_keys 写入namenode /root/.sshdatanode02同理操作scp .ssh/id_rsa.pub chenlb@192.168.1.181:/home/chenlb/id_rsa.pubcat id_rsa.pub &gt;&gt; .ssh/authorized_keys 将namenode中的三个机器的私钥 id_rsa提取到桌面，后续使用安装ntp服务yum install ntpservice ntpd startchkconfig ntpd on 2.更换源：将/etc/yum.repos.d/下的原centos.repos备份，然后添加本地源（我这是之前师傅在其他服务器布 置好了的源，你们可在网上查找相关源） 3.验证本机名Hostname -f 显示 namenode 其他两台一样 4.关闭防火墙Service iptables stop 禁用自启动 Chkconfig iptables off 5.禁用ipv6使用lsmod查看系统启动的模块：ipv6相关的模块是net-pf-10 ipv6 在vi /etc/modprobe.d/dist.conf 中最后添加 alias net-pf-10 off alias ipv6 off 重启后，再使用lsmod查看ipv6的相应模块还在不在 6.禁用SELinux配置selinuxvi /etc/sysconfig/selinux插入SELINUX=disabled暂时禁用 setenforce 0 7.配置禁用THP(每次重启机器后需要从新配置) 查看当前THP状态 cat /sys/kernel/mm/transparent_hugepage/enabled 如果为always madvise [never]则为禁用配置禁用echo never &gt; /sys/kernel/mm/redhat_transparent_hugepage/defragecho never &gt; /sys/kernel/mm/redhat_transparent_hugepage/enabledecho never &gt; /sys/kernel/mm/ transparent_hugepage/defragecho never &gt; /sys/kernel/mm/ transparent_hugepage/enabled 8.clean源 重新加载yum clean all yum makecache 9.配置mysql作为数据库（只在ambari-server安装机器上做） 查看当前安装数据库信息 rpm -qa | grep -i mysql 卸载方法 yum -y remove +name 安装MySQL 查看当前源中是否有提供的MySQL yum list | grep mysql 安装mysql-server安装 安装后mysql 只有一个用户root 且第一次开启时需要设置密码，我们这通过命令提前设置 mysqladmin -u root password ‘’ 设置为自启动 chkconfig mysqld on 登录到root用户 mysql -u root -p create user ‘amabri’@’% ’ identified by ‘bigdata’; grant all privileges on *.* to ‘ambari’@’%’; create user ‘ambari’@’localhost’ identified by ‘bigdata’; grant all privileges on *.* to ‘ambari’@’localhost’; create user ‘ambari’@’namenode’ identified by ‘bigdata’; grant all privileges on *.* to ‘ambari’@’namenode’; 登录ambari用户 mysql -u ambari -p bigdata create database ambari; use ambari; 10.部署 （1） yum安装 yum -y install ambari-server (每台都要装)后进入mysql -u ambari -pbigdatause ambari;source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql; （2） jdk的安装 下载jdk1.8.0_45安装包 放入/usr/lib/jvm/jdk1.8.0_45/ 解压 配置环境变量 /etc/profile 文件最后加上 #Java environment JAVA_HOME=/usr/java/jdk1.8.0_45PATH=$JAVA_HOME/bin:$PATHCLASSPATH=.:$JAVA_HOME/lib/export JAVA_HOMEexport PATHexport CLASSPATH执行：sudo update-alternatives –install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_45/bin/java 300sudo update-alternatives –install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_45/bin/javac 300sudo update-alternatives –install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_45/bin/jar 300查看当前Java版本java -version （3） 安装ambari-server (安装在一台centos上即可，部署为ambari-server的机器)ambari-server setup -j /usr/lib/jvm/jdk1.8.0­_45/安装显示：Using python /usr/bin/python Setup ambari‐server Checking SELinux… SELinux status is ‘enabled’ SELinux mode is ‘permissive’ WARNING: SELinux is set to ‘permissive’ mode and temporarily disabled. OK to continue [y/n] (y)? Customize user account for ambari‐server daemon [y/n] (n)? Adjusting ambari‐server permissions and ownership… Checking firewall status… Checking JDK… WARNING: JAVA_HOME /usr/lib/jvm/jdk1.8.0_45 must be valid on ALL hosts WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited Completing setup… Configuring database… Enter advanced database configuration [y/n] (n)? y Configuring database… ============================================================================= Choose one of the following options: [1] ‐ PostgreSQL (Embedded) [2] ‐ Oracle [3] ‐ MySQL / MariaDB [4] ‐ PostgreSQL [5] ‐ Microsoft SQL Server (Tech Preview) [6] ‐ SQL Anywhere [7] ‐ BDB ============================================================================= Enter choice (3): 3 Hostname (localhost): Port (3306): Database name (ambari): Username (ambari): Enter Database Password (bigdata): Configuring ambari database… Copying JDBC drivers to server resources… Configuring remote database connection properties…WARNING: Before starting Ambari Server, you must run the following DDL against the databa se to create the schema: /var/lib/ambari Proceed with configuring remote database connection properties [y/n] (y)? y Extracting system views…………… Adjusting ambari‐server permissions and ownership… Ambari Server ‘setup’ completed successfully. （4）启动ambari-server ambari-server start 启动成功后通过：http：//namenode:8080访问 登录账号及密码：admin （6） 进程操作 1.查看ambari进程 ps -ef | grep ambari 2.停止ambari进程 ambari-server stop 3.重启ambari进程 ambari-server restart （7） 修改端口 vi /etc/ambari-server/conf/ambari.properties 插入或编辑以下内容 Client.api.port = 11 安装ambari-agent(每台机器都要装)1.安装ambari-agent yum install ambari-agent 2.配置 vi /etc/ambari-agent/conf/ambari-agent.ini 插入或更改以下内容 hostname = namenode最后使用谷歌浏览器登录：http://namenode:8080 账号：admin 密码：admin注意：选择操作系统时，应该选择当前机器的版本。如果是本地源，则需要修改HDP、HDP-UTILS的位置 If you are lucky enough, that I wish you success.Said too much, tears. 如果出现ip绑定问题，修改/etc/hosts/中的ip为每台机器的真实ip查看ip命令ifconfig出现mysql drive驱动问题 yum install mysql-connector-java]]></content>
      <categories>
        <category>搭建</category>
      </categories>
      <tags>
        <tag>ambari</tag>
      </tags>
  </entry>
</search>
