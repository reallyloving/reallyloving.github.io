<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王小二客栈</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.wenchong.top/"/>
  <updated>2018-02-17T14:13:57.246Z</updated>
  <id>http://www.wenchong.top/</id>
  
  <author>
    <name>小二</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>王小二客栈</title>
    <link href="http://www.wenchong.top/2018/02/17/myblog-test/"/>
    <id>http://www.wenchong.top/2018/02/17/myblog-test/</id>
    <published>2018-02-17T14:20:06.596Z</published>
    <updated>2018-02-17T14:13:57.246Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>zookeeper搭建</title>
    <link href="http://www.wenchong.top/2018/02/15/zookeeper%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/02/15/zookeeper安装/</id>
    <published>2018-02-14T16:00:00.000Z</published>
    <updated>2018-03-05T13:15:04.288Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本文选用：centos6.5、zookeeper-3.4.6<h3 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h3>【软件】准备好jdk环境，此次我们的环境是open_jdk1.8.0_101<br>　　　　zookeeper-3.4.6.tar.gz<br>【步骤】</li><li><ol><li>准备条件<br>如果有内部dns或者外网有域名，则直接使用域名<br>如果没有需要修改/etc/hosts文件，或者直接使用IP</li></ol></li></ul><p>集群规划</p><p>主机类型 IP地址  域名<br>zookeeper1 192.168.1.1zookeeper1.chinasoft.com<br>zookeeper2 192.168.1.2zookeeper2.chinasoft.com<br>zookeeper3 192.168.1.3zookeeper3.chinasoft.com</p><p>注意：zookeeper因为有主节点和从节点的关系，所以部署的集群台数最好为奇数个，否则可能出现脑裂导致服务异常</p><ul><li><ol><li>安装<br>下载地址：<a href="http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/" target="_blank" rel="noopener">http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/</a><br>解压</li></ol></li></ul><p>tar -zxf zookeeper-3.4.6.tar.gz<br>cd zookeeper-3.4.6</p><p>拷贝配置文件，修改完成后分发给其他节点<br>cd /data/zookeeper-3.4.6/<br>cp zoo_sample.cfg zoo.cfg</p><p>cat zoo.cfg</p><p>tickTime=2000<br>initLimit=10<br>syncLimit=5<br>dataDir=/data/zookeeper-3.4.6/data<br>dataLogDir=/data/zookeeper-3.4.6/logs<br>clientPort=2181<br>server.1=u04rtv01.yaya.corp:2888:3888<br>server.2=u04rtv02.yaya.corp:2888:3888<br>server.3=u04rtv03.yaya.corp:2888:3888</p><ul><li>3.创建data和Log文件夹<br>mkdir /data/zookeeper-3.4.6/data<br>mkdir /data/zookeeper-3.4.6/logs</li></ul><p>　　　　　　　</p><ul><li><p>4、在zoo.cfg中的dataDir指定的目录下，新建myid文件。<br>例如：$ZK_INSTALL/data下，新建myid。在myid文件中输入1。表示为server.1。<br>如果为snapshot/d_2，则myid文件中的内容为 2，依此类推。 </p></li><li><p>启动：在集群中的每台主机上执行如下命令<br>bin/zkServer.sh start </p></li><li><p>查看状态，可以看到其中一台为主节点，其他两台为从节点：<br>bin/zkServer.sh status</p></li><li><p>主节点：<br>./zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: leader</p></li><li>从属节点：<br>./zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: follower</li></ul><ul><li>停止：<br>bin/zkServer.sh stop</li></ul><p>连接：<br>bin/zkCli.sh -server zookeeper1:2181<br>bin/zkCli.sh -server zookeeper2:2181<br>bin/zkCli.sh -server zookeeper3:2181 </p><ul><li>报错：<br>原因就是没有在dataDir目录下创建myid文件并且赋值(如1、2、3分别代表集群中的server1,server2,server3)</li></ul><p>2016-08-22 17:55:16,145 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>2016-08-22 17:55:16,150 [myid:] - INFO  [main:QuorumPeerConfig@340] - Defaulting to majority quorums<br>2016-08-22 17:55:16,150 [myid:] - ERROR [main:QuorumPeerMain@85] - Invalid config, exiting abnormally<br>org.apache.zookeeper.server.quorum.QuorumPeerConfig$ConfigException: Error processing /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:123)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:101)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)<br>Caused by: java.lang.IllegalArgumentException: /data/yunva/zookeeper-3.4.6/data/myid file is missing<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parseProperties(QuorumPeerConfig.java:350)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:119)<br>        … 2 more<br>Invalid config, exiting abnormally</p><h3 id="单机部署——适用于开发测试"><a href="#单机部署——适用于开发测试" class="headerlink" title="单机部署——适用于开发测试"></a>单机部署——适用于开发测试</h3><p>tar -zxvf zookeeper-3.4.6.tar.gz<br>cd zookeeper-3.4.6/conf<br>cp zoo_sample.cfg zoo.cfg</p><ul><li><p>创建日志目录<br>mkdir /data/yunva/zookeeper-3.4.6/data<br>mkdir /data/yunva/zookeeper-3.4.6/logs</p></li><li><p>配置：conf/zoo.cfg</p></li></ul><p>tickTime=2000<br>initLimit=10<br>syncLimit=5<br>dataDir=/data/yunva/zookeeper-3.4.6/logs<br>dataLogDir=/data/yunva/zookeeper-3.4.6/logs<br>clientPort=2181</p><p>#自动清除日志文件<br>autopurge.snapRetainCount=20<br>autopurge.purgeInterval=48</p><ul><li>启动：</li></ul><p>bin/zkServer.sh start </p><ul><li>连接到Zookeeper：</li></ul><p>bin/zkCli.sh -server 127.0.0.1:2181  适用于Java开发</p><ul><li>查看状态：<br>bin/zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: standalone</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;本文选用：centos6.5、zookeeper-3.4.6&lt;h3 id=&quot;集群部署&quot;&gt;&lt;a href=&quot;#集群部署&quot; class=&quot;headerlink&quot; title=&quot;集群部署&quot;&gt;&lt;/a&gt;集群部署&lt;/h3&gt;【软件】准备好jdk环境，此次我们的环境是open_
      
    
    </summary>
    
      <category term="zookeeper" scheme="http://www.wenchong.top/categories/zookeeper/"/>
    
    
      <category term="zookeepere" scheme="http://www.wenchong.top/tags/zookeepere/"/>
    
  </entry>
  
  <entry>
    <title>centos下sqoop环境搭建</title>
    <link href="http://www.wenchong.top/2018/02/15/centos%E4%B8%8Bsqoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.wenchong.top/2018/02/15/centos下sqoop环境搭建/</id>
    <published>2018-02-14T16:00:00.000Z</published>
    <updated>2018-03-05T13:14:36.442Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Sqoop是一个用来将Hadoop（Hive、HBase）和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如：MySQL ,Oracle ,Postgres等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中。</li></ul><h3 id="Sqoop安装"><a href="#Sqoop安装" class="headerlink" title="Sqoop安装"></a>Sqoop安装</h3><ul><li>1.下载Sqoop安装包<br>在Sqoop官网下载安装包，本次使用的是sqoop-1.4.6.bin<strong>hadoop-2.0.4-alpha.tar.gz安装在/usr/local目录下，下载地址为<a href="http://apache.fayea.com/sqoop/1.4.6/sqoop-1.4.6.bin" target="_blank" rel="noopener">http://apache.fayea.com/sqoop/1.4.6/sqoop-1.4.6.bin</a></strong>hadoop-2.0.4-alpha.tar.gz</li><li>2.解压Sqoop安装包<br>#进入sqoop安装目录<br>[hadoop@BigData ~]$ cd /usr/local<br>#解压sqoop安装包<br>[hadoop@BigData ~]$ tar -zxvf sqoop-1.4.6.bin<strong>hadoop-2.0.4-alpha.tar.gz<br>#删除sqoop安装包<br>[hadoop@BigData ~]$ rm -rf sqoop-1.4.6.bin</strong>hadoop-2.0.4-alpha.tar.gz<br>#重命名sqoop目录名<br>[hadoop@BigData ~]$ mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha sqoop</li><li>3.配置Sqoop环境变量<br>#配置Sqoop环境变量<br>[root@BigData ~]# vi /etc/profile<br>export SQOOP_HOME=/usr/local/sqoop<br>export PATH=$PATH:$SQOOP_HOME/bin<br>#保存之后记得source，使之前的配置生效<br>source /etc/profile</li><li>4.将关系型数据库驱动包放到sqoop/lib目录下<br>MySql：mysql-connector-java-5.1.30.jar<br>Oracle：ojdbc14.jar</li><li>5.修改Sqoop配置文件<br>[hadoop@BigData ~]$ mv sqoop-env-template.sh sqoop-env.sh<br>[hadoop@BigData ~]$ vi sqoop-env.sh<br>#Set path to where bin/hadoop is available<br>export HADOOP_COMMON_HOME=/usr/local/hadoop<br>#Set path to where hadoop-*-core.jar is available<br>export HADOOP_MAPRED_HOME=/usr/local/hadoop<br>#set the path to where bin/hbase is available<br>export HBASE_HOME=/usr/local/hbase<br>#Set the path to where bin/hive is available<br>export HIVE_HOME=/usr/local/hive<br>#Set the path for where zookeper config dir is<br>export ZOOCFGDIR=/usr/local/zookeeper<br>到此，sqoop环境就已搭建成功！</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;Sqoop是一个用来将Hadoop（Hive、HBase）和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如：MySQL ,Oracle ,Postgres等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中。&lt;
      
    
    </summary>
    
      <category term="Sqoop" scheme="http://www.wenchong.top/categories/Sqoop/"/>
    
    
      <category term="sqoop" scheme="http://www.wenchong.top/tags/sqoop/"/>
    
  </entry>
  
  <entry>
    <title>docker安装</title>
    <link href="http://www.wenchong.top/2018/02/05/docker%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/02/05/docker安装/</id>
    <published>2018-02-05T13:09:56.999Z</published>
    <updated>2018-02-18T17:27:27.415Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1：关闭selinux"><a href="#1：关闭selinux" class="headerlink" title="1：关闭selinux"></a>1：关闭selinux</h2><p>临时关闭：setenforce 0<br>永久关闭：</p><h2 id="1-vi-etc-sysconfig-selinux"><a href="#1-vi-etc-sysconfig-selinux" class="headerlink" title="1. vi /etc/sysconfig/selinux"></a>1. vi /etc/sysconfig/selinux</h2><p>插入/编辑以下内容<br>SELINUX=disabled</p><p>#重启生效</p><h2 id="2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel："><a href="#2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel：" class="headerlink" title="2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel："></a>2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel：</h2><p>rpm -ivh <a href="http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="noopener">http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm</a><br>sed -i ‘s/^mirrorlist=https/mirrorlist=http/‘ /etc/yum.repos.d/epel.repo<br>（elpe.repo）<br>[epel]<br>name=epel<br>mirrorlist=<a href="http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch" target="_blank" rel="noopener">http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch</a><br>enabled=1<br>gpgcheck=0</p><h2 id="3：安装docker"><a href="#3：安装docker" class="headerlink" title="3：安装docker"></a>3：安装docker</h2><p>yum install docker-io<br>安装完成后</p><h2 id="4：启动docker"><a href="#4：启动docker" class="headerlink" title="4：启动docker"></a>4：启动docker</h2><p>service  docker  start</p><h2 id="5：查看docker版本"><a href="#5：查看docker版本" class="headerlink" title="5：查看docker版本"></a>5：查看docker版本</h2><p>docker vesion</p><h2 id="6：查看docker日志"><a href="#6：查看docker日志" class="headerlink" title="6：查看docker日志"></a>6：查看docker日志</h2><p>cat /var/log/docker</p><p>docker安装完成</p><h1 id="一：卸载docker"><a href="#一：卸载docker" class="headerlink" title="一：卸载docker"></a>一：卸载docker</h1><p>列出你安装过的包<br>[root@localhost ~]# yum list installed | grep docker<br>docker-io.x86_64                     1.7.1-2.el6                        @epel<br>删除软件包<br>yum -y remove docker-io.x86_64<br>删除镜像/容器等<br>rm -rf /var/lib/docker</p><h1 id="二：升级docker版本为1-10-3"><a href="#二：升级docker版本为1-10-3" class="headerlink" title="二：升级docker版本为1.10.3"></a>二：升级docker版本为1.10.3</h1><p>升级之前停止docker服务,并将原有的docker服务进行备份. mv /usr/bin/docker /usr/bin/docker.bak</p><p>nohup wget -c <a href="https://get.docker.com/builds/Linux/x86_64/docker-1.10.3" target="_blank" rel="noopener">https://get.docker.com/builds/Linux/x86_64/docker-1.10.3</a> -O /usr/bin/docker<br>给执行权限：chmod 755 /usr/bin/docker 然后重启服务，并查看版本.</p><h2 id="报错："><a href="#报错：" class="headerlink" title="报错："></a>报错：</h2><p>Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory<br>/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed<br>Failed to parse /etc/cgconfig.conf                         [FAILED]<br>Starting docker:                                       [  OK  ]</p><h2 id="修改：-etc-cgconfig-conf文件"><a href="#修改：-etc-cgconfig-conf文件" class="headerlink" title="修改：/etc/cgconfig.conf文件"></a>修改：/etc/cgconfig.conf文件</h2><p>mount {<br>    cpuset  = /cgroup/cpuset;<br>    cpu = /cgroup/cpu;<br>    cpuacct = /cgroup/cpuacct;</p><h1 id="memory-cgroup-memory"><a href="#memory-cgroup-memory" class="headerlink" title="memory  = /cgroup/memory;"></a>memory  = /cgroup/memory;</h1><pre><code>devices = /cgroup/devices;freezer = /cgroup/freezer;net_cls = /cgroup/net_cls;blkio   = /cgroup/blkio;</code></pre><p>}<br>重新启动docker 正常</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1：关闭selinux&quot;&gt;&lt;a href=&quot;#1：关闭selinux&quot; class=&quot;headerlink&quot; title=&quot;1：关闭selinux&quot;&gt;&lt;/a&gt;1：关闭selinux&lt;/h2&gt;&lt;p&gt;临时关闭：setenforce 0&lt;br&gt;永久关闭：&lt;/p&gt;
&lt;h2
      
    
    </summary>
    
      <category term="docker" scheme="http://www.wenchong.top/categories/docker/"/>
    
    
      <category term="docker" scheme="http://www.wenchong.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Centos7伪分布式安装Hadoop2.6和Hbase0.94</title>
    <link href="http://www.wenchong.top/2017/12/01/centos7+hadoop2.6+hbase1.0.x/"/>
    <id>http://www.wenchong.top/2017/12/01/centos7+hadoop2.6+hbase1.0.x/</id>
    <published>2017-11-30T16:00:00.000Z</published>
    <updated>2018-02-18T17:01:12.088Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1><h2 id="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。"><a href="#一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。" class="headerlink" title="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。"></a>一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。</h2><ul><li>卸载： yum -y remove java javaxxxxx(系统自带的Java版本)</li></ul><p>安装jdk，将jdk.tar.gz文件复制到/usr/java中,终端进入/mnt/share ,cp jdk.tar.gz /usr/ava，进入/usr/java解压：tar xzvf jdk.targz</p><p>配置环境变量：vi /etc/profile 输入i编辑<br>在尾部添加：export JAVA_HOME=/usr/java/jdkxxxx<br>export PATH=$JAVA_HOME/bin:$PATH<br>export CLASSPATH=.:JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p><p>保存并退出： wq<br>使修改生效： source /etc/profile<br>查看Java版本：java -version</p><h2 id="二、Hadoop伪分布式安装"><a href="#二、Hadoop伪分布式安装" class="headerlink" title="二、Hadoop伪分布式安装"></a>二、Hadoop伪分布式安装</h2><ul><li>1、ssh无密码登陆</li></ul><p>终端：ssh-keygen -t rsa (获得rsa公钥私钥,id_rsa和id_rsa.pub)<br>cd .ssh<br>cp id_rsa.pub authorized_keys (将公钥复制给authorized_keys) &lt;分布式则要将所有节点id_rsa.pub相互复制&gt;</p><ul><li>2、 /mnt/share cp hadoop2.x /usr.hadoop</li></ul><p>解压tar xzvf hadoop 2.x</p><ul><li>3、修改core-site.xml、hadoop-env.sh、hdfs-site.xml、mapred-site.xml 、yarn-site.xml(hadoop2.x版本的配置文件在/hadoop2.x/etc/hadoop下)</li></ul><p>①core-site.xml：</p><pre><code>fs.default.namehdfs://localhost:9000</code></pre><p>② hadoop-env.sh：<br>export JAVA_HOME=/usr/java/jdkxxx (jdk路径)</p><p>③ hdfs-site.xml： 先创建好数据节点和名称节点的存放路径</p><pre><code>dfs.datanode.data.dir/user/hadoop/hadoop-2.5.1/datadfs.namenode.name.dir/user/hadoop/hadoop-2.5.1/namedfs.replication1</code></pre><p>④mapred-site.xml: (注意：这个文件是将/hadoop2.x/etc/hadoop下的mapred-site.xml.template复制并重命名 )</p><pre><code>mapreduce.framework.nameyarn</code></pre><p>⑤yarn-site.xml：</p><pre><code>yarn.nodemanager.aux-servicesmapreduce_shuffle</code></pre><ul><li>4、namenode格式化（一定要完成）</li></ul><p>终端：cd /usr/hadoop/hadoop-2.5.1/bin</p><p>./hdfs namenode -format (输入./hadoop namenode -format也行)</p><ul><li>5、运行hadoop</li></ul><p>终端： cd /usr/hadoop/hadoop-2.5.1/sbin (2.x版本后启动/停止在sbin目录下)<br>./start-hdfs.sh<br>./start-yarn.sh<br>(也可以只输入./start-all.sh)</p><p>输入jps查看启动项，当启动了NameNode、DataNode、SecondaryNameNode、ResourceManager、NodeManager即ok。</p><p>可进入Firefox中，输入端口号： localhost:50070 进入hadoop可视化页面。</p><h2 id="三、Hbase0-94安装"><a href="#三、Hbase0-94安装" class="headerlink" title="三、Hbase0.94安装"></a>三、Hbase0.94安装</h2><ul><li>1、/mnt/share cp hbase1.0.1 /usr.hbase</li></ul><p>解压tar xzvf hbase1.0.1</p><ul><li>2、修改hbase配置文件hbase-env.sh、hbase-site.xml</li></ul><p>hbase-env.sh:</p><p>export JAVA_HOME=/usr/java/jdkxxxx (java路径)<br>export HBASE_MANAGES_ZK=true (都得去掉前面#)</p><p>hbase-site.xml：</p><pre><code>hbase.rootdirhdfs://localhost:9000/hbasehbase.cluster.distributedtruehbase.zookeeper.quorumlocalhosthbase.tmp.dirfile:/usr/hbase/tmphbase.zookeeper.property.dataDirfile:/usr/hbase/zookeeperdata</code></pre><ul><li>3、运行hbase</li></ul><p>运行前需先启动hadoop，再进入hbase的bin目录下输入指令 ./start-hbase.sh<br>输入jps查看启动项，如有HMaster、HRegionServer、HQuormPeer,则说明hbase启动成功。<br>输入./hbase Shell (进入shell指令，可通过shell指令建表)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;&lt;h2 id=&quot;一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>centos 6.5 内核升级</title>
    <link href="http://www.wenchong.top/2017/11/15/centos6.5%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"/>
    <id>http://www.wenchong.top/2017/11/15/centos6.5内核升级/</id>
    <published>2017-11-14T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:56.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-查看centos的内核版本"><a href="#1-查看centos的内核版本" class="headerlink" title="1.查看centos的内核版本"></a>1.查看centos的内核版本</h2><p>rname -r</p><h2 id="2-查看系统版本"><a href="#2-查看系统版本" class="headerlink" title="2.查看系统版本"></a>2.查看系统版本</h2><p>cat /etc/centos-release</p><h2 id="3-安装软件"><a href="#3-安装软件" class="headerlink" title="3.安装软件"></a>3.安装软件</h2><p>编译安装新内核，依赖于开发环境和开发库<br>yum grouplist  //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库；</p><p>yum groupinstall “Development Tools”  //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具</p><p>yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行</p><p>yum install qt-devel //如果你没有 X 环境，这一条可以不用</p><p>yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们</p><h2 id="4-编译内核"><a href="#4-编译内核" class="headerlink" title="4.编译内核"></a>4.编译内核</h2><p>Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成： r.x.y</p><ul><li>r: 主版本号</li><li>x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。</li><li>y: 修订版本号 ， 表示修改的次数<br>官网上有stable, longterm等版本，longterm是比stable更稳定的版本。<br><code>[root@sean ~]#curl -O -L  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz[root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/[root@sean ~]# cd /usr/src/linux-3.10.58/[root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config</code></li></ul><p>我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置：<br>`[root@sean linux-3.10.58]# sh -c ‘yes “” | make oldconfig’</p><p>HOSTCC  scripts/basic/fixdep</p><p>HOSTCC  scripts/kconfig/conf.o</p><p>SHIPPED scripts/kconfig/zconf.tab.c</p><p>SHIPPED scripts/kconfig/zconf.lex.c</p><p>SHIPPED scripts/kconfig/zconf.hash.c</p><p>HOSTCC  scripts/kconfig/zconf.tab.o</p><p>HOSTLD  scripts/kconfig/conf</p><p>scripts/kconfig/conf –oldconfig Kconfig</p><p>.config:555:warning: symbol value ‘m’ invalid for PCCARD_NONSTATIC<br>.config:2567:warning: symbol value ‘m’ invalid for MFD_WM8400<br>.config:2568:warning: symbol value ‘m’ invalid for MFD_WM831X<br>.config:2569:warning: symbol value ‘m’ invalid for MFD_WM8350<br>.config:2582:warning: symbol value ‘m’ invalid for MFD_WM8350_I2C<br>.config:2584:warning: symbol value ‘m’ invalid for AB3100_CORE<br>.config:3502:warning: symbol value ‘m’ invalid for MMC_RICOH_MMC</p><p>*</p><ul><li>Restart config…</li></ul><p>*</p><p>*</p><ul><li>General setup</li></ul><p>*</p><p>…<br>…</p><p>XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW)</p><p>Averaging functions (AVERAGE) [Y/?] (NEW)<br>y<br>CORDIC algorithm (CORDIC) [N/m/y/?] (NEW) </p><p>JEDEC DDR data (DDR) [N/y/?] (NEW) </p><p>#</p><p>configuration written to .config`<br>make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写，然后备份.config文件为.config.old，并生成新的.config文件</p><h2 id="5-开始编译"><a href="#5-开始编译" class="headerlink" title="5.开始编译"></a>5.开始编译</h2><p>[root@sean linux-3.10.58]# make -j4 bzImage  //生成内核文件<br>[root@sean linux-3.10.58]# make -j4 modules  //编译模块<br>[root@sean linux-3.10.58]# make -j4 modules_install  //编译安装模块</p><p>-j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟）</p><h2 id="6-安装"><a href="#6-安装" class="headerlink" title="6.安装"></a>6.安装</h2><p>[root@sean linux-3.10.58]# make install<br>实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入<br>HYPERVISOR_GUEST=yCONFIG_VMWARE_BALLOON=m<br>（这一部分比较容易出问题，参考下文异常部分）</p><h2 id="7-修改grub引导，重启"><a href="#7-修改grub引导，重启" class="headerlink" title="7.修改grub引导，重启"></a>7.修改grub引导，重启</h2><p>安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。<br>编辑 grub.conf文件，<br>vi /etc/grub.conf</p><p>#boot=/dev/sda<br>default=0<br>timeout=5<br>splashimage=(hd0,0)/grub/splash.xpm.gz<br>hiddenmenu<br>title CentOS (3.10.58)<br>    root (hd0,0)<br>…</p><p>数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。<br>重启reboot now</p><h2 id="8-确认当内核版本"><a href="#8-确认当内核版本" class="headerlink" title="8.确认当内核版本"></a>8.确认当内核版本</h2><p>[root@sean ~]# uname -r<br>3.10.58</p><p>升级内核成功!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-查看centos的内核版本&quot;&gt;&lt;a href=&quot;#1-查看centos的内核版本&quot; class=&quot;headerlink&quot; title=&quot;1.查看centos的内核版本&quot;&gt;&lt;/a&gt;1.查看centos的内核版本&lt;/h2&gt;&lt;p&gt;rname -r&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
      <category term="运维" scheme="http://www.wenchong.top/categories/operation/"/>
    
    
      <category term="operation" scheme="http://www.wenchong.top/tags/operation/"/>
    
  </entry>
  
  <entry>
    <title>centos6.5下搭建hadoop2.7单机伪分布环境</title>
    <link href="http://www.wenchong.top/2017/10/01/centos6.5+hadoop2.7/"/>
    <id>http://www.wenchong.top/2017/10/01/centos6.5+hadoop2.7/</id>
    <published>2017-09-30T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:42.723Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设置固定IP地址及网关"><a href="#设置固定IP地址及网关" class="headerlink" title="设置固定IP地址及网关"></a>设置固定IP地址及网关</h3><ul><li>设置IP<br>vi /etc/sysconfig/network-scripts/ifcfg-eth0</li><li>修改内容如下<br>DEVICE=eth0<br>HWADDR=08:00:27:BD:9D:B5  #不用改<br>TYPE=Ethernet<br>UUID=53e4e4b6-9724-43ab-9da7-68792e611031 #不用改<br>ONBOOT=yes  #开机启动<br>NM_CONTROLLED=yes<br>BOOTPROTO=static  #静态IP<br>IPADDR=192.168.30.50  #IP地址<br>NETMASK=255.255.255.0 #子网掩码</li><li>设置网关<br>vi /etc/sysconfig/network</li><li>添加内容<br>NETWORKING=yes<br>HOSTNAME=Hadoop.Master<br>GATEWAY=192.168.30.1 #网关</li><li>设置DNS<br>vi /etc/resolv.conf</li><li>添加内容<br>nameserver xxx.xxx.xxx.xxx #根据实际情况设置<br>nameserver 114.114.114.114 #可以设置多个</li><li>重启网卡<br>service network restart</li><li>设置主机名对应IP地址<br>vi /etc/hosts<br>#添加如下内容<br>192.168.30.50 Hadoop.Master<h3 id="添加Hadoop用户"><a href="#添加Hadoop用户" class="headerlink" title="添加Hadoop用户"></a>添加Hadoop用户</h3></li><li>添加用户组<br>groupadd hadoop</li><li>添加用户并分配用户组<br>useradd -g hadoop hadoop</li><li>修改用户密码<br>passwd hadoop<h3 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h3></li><li>关闭防火墙<br>service iptables stop #关闭防火墙服务<br>chkconfig iptables off #关闭防火墙开机启动<br>service ip6tables stop<br>chkconfig ip6tables off</li><li>关闭SELinux<br>vi /etc/sysconfig/selinux<br>#修改如下内容<br>SELINUX=enforcing -&gt; SELINUX=disabled<br>#再执行如下命令<br>setenforce 0<br>getenforce</li><li>关闭其他服务<h3 id="VSFTP安装与配置"><a href="#VSFTP安装与配置" class="headerlink" title="VSFTP安装与配置"></a>VSFTP安装与配置</h3></li><li>检查是否安装<br>chkconfig –list|grep vsftpd</li><li>安装vsftp<br>yum -y install vsftpd</li><li>创建日志文件<br>touch /var/log/vdftpd.log</li><li>配置vsftpd服务<br>vi /etc/vsftpd/vsftpd.conf<br>#修改如下内容<br>anonymous_enable=NO #关闭匿名访问<br>xferlog_file=/var/log/vsftpd.log #设置日志文件 – 我们上一步所创建的文件<br>idle_session_timeout=600 #会话超时时间<br>async_abor_enable=YES  #开启异步传输<br>ascii_upload_enable=YES #开启ASCII上传<br>ascii_download_enable=YES #开启ASCII下载</li><li>查看vsftp运行状态<br>service vsftpd status<h3 id="启动vsftp"><a href="#启动vsftp" class="headerlink" title="启动vsftp"></a>启动vsftp</h3>service vsftpd start<br>#重启 service vsftpd restart<br>#关闭 service vsftpd stop</li><li>查看vsftpd服务启动项<br>chkconfig –list|grep vsftpd</li><li>设置vsftp开机启动<br>chkconfig vsftpd on<h3 id="SSH无密码配置"><a href="#SSH无密码配置" class="headerlink" title="SSH无密码配置"></a>SSH无密码配置</h3></li><li>查看ssh与rsync安装状态<br>rpm -qa|grep openssh<br>rpm -qa|grep rsync</li><li>安装ssh与rsync<br>yum -y install ssh<br>yum -y install rsync</li><li>切换hadoop用户<br>su - hadoop</li><li>生成ssh密码对<br>ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsa</li><li>将id_dsa.pub追加到授权的key中<br>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<h3 id="设置授权key权限"><a href="#设置授权key权限" class="headerlink" title="设置授权key权限"></a>设置授权key权限</h3>chmod 600 ~/.ssh/authorized_keys<br>#权限的设置非常重要，因为不安全的设置安全设置，会让你不能使用RSA功能<h3 id="测试ssh连接"><a href="#测试ssh连接" class="headerlink" title="测试ssh连接"></a>测试ssh连接</h3>ssh localhost<br>#如果不需要输入密码，则是成功<h2 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h2></li><li>下载地址<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html</a></li></ul><p>注：我这里使用的是：jdk-7u80-linux-i586.tar.gz</p><ul><li>安装Java<br>切换至root用户<br>su root</li><li>创建/usr/java文件夹<br>mkdir /usr/java</li><li><p>使用winscp工具上传至服务器</p></li><li><p>将压缩包上传至/home/hadoop目录</p></li></ul><p>注：我这里使用的是winscp，使用hadoop用户连接</p><ul><li>将压缩包解压至/usr/java 目录<br>tar zxvf /home/hadoop/jdk-7u80-linux-i586.tar.gz -C /usr/java/</li><li>设置环境变量<br>vi /etc/profile<br>#追加如下内容<br>export JAVA_HOME=/usr/java/jdk1.7.0_80<br>export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib<br>export PATH=$PATH:$JAVA_HOME/bin</li><li>使环境变量生效<br>source /etc/profile</li><li>测试环境变量设置<br>java -version<h2 id="Hadoop安装与配置"><a href="#Hadoop安装与配置" class="headerlink" title="Hadoop安装与配置"></a>Hadoop安装与配置</h2>下载地址<br><a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a></li></ul><p>注:我下载的是hadoop-2.7.1.tar.gz</p><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>使用winscp工具上传至服务器<br>将压缩包上传至/home/hadoop目录<br>*将压缩包解压至/usr目录<br>tar zxvf /home/hadoop/hadoop-2.7.1.tar.gz -C /usr/</p><ul><li>修改文件夹名称<br>mv /usr/hadoop-2.7.1/ /usr/hadoop</li><li>创建hadoop数据目录<br>mkdir /usr/hadoop/tmp</li><li>将hadoop文件夹授权给hadoop用户<br>chown -R hadoop:hadoop /usr/hadoop/</li><li>设置环境变量<br>vi /etc/profile<br>#追加如下内容<br>export HADOOP_HOME=/usr/hadoop<br>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin<br>export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native<br>export HADOOP_OPTS=”-Djava.library.path=$HADOOP_HOME/lib</li><li>使环境变量生效<br>source /etc/profile</li><li>测试环境变量设置<br>hadoop version<h3 id="配置HDFS"><a href="#配置HDFS" class="headerlink" title="配置HDFS"></a>配置HDFS</h3></li><li>切换至Hadoop用户<br>su - hadoop</li><li>修改hadoop-env.sh<br>cd /usr/hadoop/etc/hadoop/<br>vi hadoop-env.sh<br>#追加如下内容<br>export JAVA_HOME=/usr/java/jdk1.7.0_80</li><li>修改core-site.xml<br>vi core-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>fs.defaultFS</name><br>      <value>hdfs://Hadoop.Master:9000</value><br>  </property><br>  <property><br>      <name>hadoop.tmp.dir</name><br>      <value>/usr/hadoop/tmp/</value><br>      <description>A base for other temporary directories.</description><br>  </property><br></configuration></li><li>修改hdfs-site.xml<br>vi hdfs-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>dfs.replication</name><br>      <value>1</value><br>  </property><br></configuration></li><li>格式化hdfs<br>hdfs namenode -format<br>注：出现Exiting with status 0即为成功</li><li>启动hdfs<br>start-dfs.sh<br>#停止命令 stop-dfs.sh<br>注：输出如下内容<br>15/09/21 18:09:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>Starting namenodes on [Hadoop.Master]<br>Hadoop.Master: starting namenode, logging to /usr/hadoop/logs/hadoop-hadoop-namenode-Hadoop.Master.out<br>Hadoop.Master: starting datanode, logging to /usr/hadoop/logs/hadoop-hadoop-datanode-Hadoop.Master.out<br>Starting secondary namenodes [0.0.0.0]<br>The authenticity of host ‘0.0.0.0 (0.0.0.0)’ can’t be established.<br>RSA key fingerprint is b5:96:b2:68:e6:63:1a:3c:7d:08:67:4b:ae:80:e2:e3.<br>Are you sure you want to continue connecting (yes/no)? yes<br>0.0.0.0: Warning: Permanently added ‘0.0.0.0’ (RSA) to the list of known hosts.<br>0.0.0.0: starting secondarynamenode, logging to /usr/hadoop/logs/hadoop-hadoop-secondarynamenode-Hadoop.Master.out<br>15/09/21 18:09:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicab</li><li>查看进程<br>jps<br>注：输出类似如下内容<br>1763 NameNode<br>1881 DataNode<br>2146 Jps<br>2040 SecondaryNameNode</li><li>使用web查看Hadoop运行状态<br><a href="http://你的服务器ip地址:50070/" target="_blank" rel="noopener">http://你的服务器ip地址:50070/</a><h3 id="在HDFS上运行WordCount"><a href="#在HDFS上运行WordCount" class="headerlink" title="在HDFS上运行WordCount"></a>在HDFS上运行WordCount</h3></li><li>创建HDFS用户目录<br>hdfs dfs -mkdir /user<br>hdfs dfs -mkdir /user/hadoop #根据自己的情况调整/user/<username></username></li><li>复制输入文件（要处理的文件）到HDFS上<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>查看我们复制到HDFS上的文件<br>hdfs dfs -ls input</li><li>运行单词检索（grep）程序<br>hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output ‘dfs[a-z.]+’<br>#WordCount<br>#hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount input output<br>#说明：output文件夹如已经存在则需要删除或指定其他文件夹。</li><li>查看运行结果<br>hdfs dfs -cat output/*<h3 id="配置YARN"><a href="#配置YARN" class="headerlink" title="配置YARN"></a>配置YARN</h3></li><li>修改mapred-site.xml<br>cd /usr/hadoop/etc/hadoop/<br>cp mapred-site.xml.template mapred-site.xml<br>vi mapred-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>mapreduce.framework.name</name><br>      <value>yarn</value><br>  </property><br></configuration></li><li>修改yarn-site.xml<br>vi yarn-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>yarn.nodemanager.aux-services</name><br>      <value>mapreduce_shuffle</value><br>  </property><br></configuration></li><li>启动YARN<br>start-yarn.sh<br>#停止yarn stop-yarn.sh</li><li>查看当前java进程<br>jsp<br>#输出如下<br>4918 ResourceManager<br>1663 NameNode<br>1950 SecondaryNameNode<br>5010 NodeManager<br>5218 Jps<br>1759 DataNode</li><li><p>运行你的mapReduce程序</p></li><li><p>配置好如上配置再运行mapReduce程序时即是yarn中运行。</p></li><li><p>使用web查看Yarn运行状态<br><a href="http://你的服务器ip地址:8088/" target="_blank" rel="noopener">http://你的服务器ip地址:8088/</a></p><h3 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h3></li><li>创建HDFS文件夹</li><li>在根目录创建input文件夹<br>hdfs dfs -mkdir -p /input</li><li>在用户目录创建input文件夹<br>说明：如果不指定“/目录”，则默认在用户目录创建文件夹<br>hdfs dfs -mkdir -p input<br>#等同于 hdfs dfs -mkdir -p /user/hadoop/input</li><li>查看HDFS文件夹</li><li>查看HDFS根文件夹<br>hdfs  dfs  -ls /</li><li>查看HDFS用户目录文件夹<br>hdfs  dfs  -ls</li><li>查看HDFS用户目录文件夹下input文件夹<br>hdfs  dfs  -ls input<br>#等同与 hdfs  dfs  -ls /user/hadoop/input</li><li>复制文件到HDFS<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>删除文件夹<br>hdfs  dfs  -rm -r input</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设置固定IP地址及网关&quot;&gt;&lt;a href=&quot;#设置固定IP地址及网关&quot; class=&quot;headerlink&quot; title=&quot;设置固定IP地址及网关&quot;&gt;&lt;/a&gt;设置固定IP地址及网关&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;设置IP&lt;br&gt;vi /etc/sysconfig/ne
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>hive参数优化</title>
    <link href="http://www.wenchong.top/2017/08/29/hive%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/29/hive参数优化/</id>
    <published>2017-08-28T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:39.661Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><ul><li>1.设置合理solt数<br>mapred.tasktracker.map.tasks.maximum<br>每个tasktracker可同时运行的最大map task数，默认值2。<br>mapred.tasktracker.reduce.tasks.maximum<br>每个tasktracker可同时运行的最大reduce task数，默认值1</li><li>2.配置磁盘块<br>mapred.local.dir<br>map task中间结果写本地磁盘路径，默认值${hadoop.tmp.dir}/mapred/local。<br>可配置多块磁盘缓解写压力。当存在多个可以磁盘时，Hadoop将采用轮询方式将不同的map task中间结果写到磁盘上。</li><li>3.配置RPC Handler数<br>mapred.job.tracker.handler.count<br>jobtracker可并发处理来自tasktracker的RPC请求数，默认值10。</li><li>4.配置HTTP线程数<br>tasktracker.http.threads<br>HTTP服务器的工作线程数，用于获取map task的输出结果，默认值40。</li><li>5.启用批调度</li><li>6.选择合适的压缩算法<br>Job输出结果是否压缩<br>mapred.output.compress<br>是否压缩，默认值false。<br>mapred.output.compression.type<br>压缩类型，有NONE, RECORD和BLOCK，默认值RECORD。<br>mapred.output.compression.codec<br>压缩算法，默认值org.apache.hadoop.io.compress.DefaultCodec。<br>map task输出是否压缩<br>mapred.compress.map.output<br>是否压缩，默认值false<br>mapred.map.output.compression.codec<br>压缩算法，默认值org.apache.hadoop.io.compress.DefaultCodec。</li><li>7.设置失败容忍度<br>mapred.max.map.failures.percent<br>例如：set mapred.max.map.failures.percent=30;<br>作业最多允许失败的map task比例，默认值0。<br>mapred.max.reduce.failures.percent<br>作业最多允许失败的reduce task比例，默认值0。<br>mapred.map.max.attempts<br>一个map task的最多重试次数，默认值4。<br>mapred.reduce.max.attempts<br>一个reduce task的最多重试次数，默认值4。</li><li>8.设置跳过坏记录<br>mapred.skip.attempts.to.start.skipping<br>当任务失败次数达到该值时，启用跳过坏记录功能，默认值2。</li></ul><p>mapred.skip.out.dir<br>检测出的坏记录存放目录，默认值为输出目录的_logs/skip，设置为none表示不输出。<br>mapred.skip.map.max.skip.records<br>map task最多允许的跳过记录数，默认值0。<br>mapred.skip.reduce.max.skip.groups<br>reduce task最多允许的跳过记录数，默认值0。</p><ul><li>9.配置jvm重用<br>mapred.job.reuse.jvm.num.tasks<br>一个jvm可连续启动多个同类型任务，默认值1，若为-1表示不受限制。</li><li>10.配置jvm参数<br>mapred.child.java.opts<br>任务启动的jvm参数，默认值-Xmx200m，建议值-XX:-UseGCOverheadLimit -Xms512m -Xmx2048m -verbose:gc -Xloggc:/tmp/@taskid@.gc</li><li><ol><li>map task调优<br>io.sort.mb<br>默认值100M<br>io.sort.record.percent<br>默认值0.05<br>io.sort.spill.percent<br>默认值0.80</li></ol></li><li>12.reduce task调优<br>io.sort.factor<br>默认值10<br>mapred.reduce.parallel.copies<br>默认值5</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;1.设置合理solt数&lt;br&gt;mapred.tasktracke
      
    
    </summary>
    
      <category term="hive" scheme="http://www.wenchong.top/categories/hive/"/>
    
    
      <category term="Hhive" scheme="http://www.wenchong.top/tags/Hhive/"/>
    
  </entry>
  
  <entry>
    <title>kafka参数优化</title>
    <link href="http://www.wenchong.top/2017/08/25/kafka%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0/"/>
    <id>http://www.wenchong.top/2017/08/25/kafka优化参数/</id>
    <published>2017-08-24T16:00:00.000Z</published>
    <updated>2018-02-18T17:04:52.386Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><ul><li><p>非负整数，用于唯一标识broker<br>broker.id=0</p></li><li><p>broker 服务监听端口<br>port=9092</p></li><li><p>broker 发布给生产者消费者的hostname，会存储在zookeeper。配置好这个host可以实现内网外网同时访问。<br>advertised.host.name=host1</p></li><li><p>broker 发布给生产者消费者的port，会存储在zookeeper。<br>advertised.port=9092</p></li><li><p>处理网络请求的线程数量，一般默认配置就好<br>num.network.threads=3</p></li><li><p>处理磁盘的线程数量，一般默认配置就好<br>num.io.threads=8</p></li><li><p>socket server 发送数据缓冲区大小<br>socket.send.buffer.bytes=102400</p></li><li><p>socket server 接受数据缓冲区大小<br>socket.receive.buffer.bytes=102400</p></li><li><p>soket server 可接受最大消息大小，防止oom<br>socket.request.max.bytes=104857600</p></li><li><p>kafka存放消息的目录<br>log.dirs=/home/data/kafka/kafka-logs</p></li><li><p>每个topic默认partition数量，根据消费者实际情况配置，配置过小会影响消费性能<br>num.partitions=50</p></li><li><p>kafka启动恢复日志,关闭前日志刷盘的线程数<br>num.recovery.threads.per.data.dir=1</p></li><li><p>日志保留时间<br>log.retention.minutes=30</p></li><li><p>日志保留大小<br>log.retention.bytes=53687091200</p></li><li><p>日志 segment file 大小. 超过这个大小创建新segment file<br>log.segment.bytes=67108864</p></li><li><p>日志 segment file 刷新时间. 超过这个时间创建新segment file<br>log.roll.hours=24</p></li><li><p>日志淘汰检查间隔时间<br>log.retention.check.interval.ms=10000</p></li><li><p>Zookeeper host和port<br>zookeeper.connect=localhost:2181</p></li><li><p>连接zookeeper超时时间<br>zookeeper.connection.timeout.ms=6000</p></li><li><p>清除fetch  purgatory 间隔消息条数<br>fetch.purgatory.purge.interval.requests=100</p></li><li><p>清除producer purgatory 间隔消息条数<br>producer .purgatory.purge.interval.requests=100</p></li><li><p>是否可以通过管理工具删除topic，默认是false<br>delete.topic.enable=true</p></li><li><p>日志传输时候的压缩格式，可选择lz4, snappy, gzip,不压缩。建议打开压缩，可以提高传输性能，压缩格式的选择可以参考文章结尾的参考资料。<br>compression.type=snappy</p></li><li><p>启用压缩的topic名称。若上面参数选择了一个压缩格式，那么压缩仅对本参数指定的topic有效，若本参数为空，则对所有topic有效。<br>compressed.topics=topic1</p></li><li><p>用来从主partion同步数据的线程数，默认为1，建议适当调大，数据量大的时候一个同步线程可能不够用<br>num.replica.fetchers=3</p></li><li><p>消息日志备份因子，默认是1<br>default.replication.factor=2</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;非负整数，用于唯一标识broker&lt;br&gt;broker.i
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.wenchong.top/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.wenchong.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Hbase手动优化</title>
    <link href="http://www.wenchong.top/2017/08/20/hbase%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/20/hbase手动优化/</id>
    <published>2017-08-19T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:07.306Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h2><ul><li><p>zookeeper.session.timeout<br>默认值：3分钟（180000ms）<br>说明：RegionServer与Zookeeper间的连接超时时间。当超时时间到后，ReigonServer会被Zookeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台server负责的regions重新balance，让其他存活的* RegionServer接管.<br>调优：<br>这个timeout决定了RegionServer是否能够及时的failover。设置成1分钟或更低，可以减少因等待超时而被延长的failover时间。<br>不过需要注意的是，对于一些Online应用，RegionServer从宕机到恢复时间本身就很短的（网络闪断，crash等故障，运维可快速介入），如果调低timeout时间，反而会得不偿失。因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了（让其他RS根据故障机器记录的WAL日志进行恢复）。当故障的RS在人工介入恢复后，这个balance动作是毫无意义的，反而会使负载不均匀，给RS带来更多负担。特别是那些固定分配regions的场景。</p></li><li><p>Hbase.zookeeper.quorum<br>默认值：localhost<br>说明：hbase所依赖的zookeeper部署<br>调优：<br>部署的zookeeper越多，可靠性就越高，但是部署只能部署奇数个，主要为了便于选出leader。最好给每个zookeeper 1G的内存和独立的磁盘，可以确保高性能。hbase.zookeeper.property.dataDir可以修改zookeeper保存数据的路径。</p></li><li><p>hbase.regionserver.handler.count<br>默认值：10<br>说明：RegionServer的请求处理IO线程数。<br>调优：<br>这个参数的调优与内存息息相关。<br>较少的IO线程，适用于处理单次请求内存消耗较高的Big PUT场景（大容量单次PUT或设置了较大cache的scan，均属于Big PUT）或ReigonServer的内存比较紧张的场景。<br>较多的IO线程，适用于单次请求内存消耗低，TPS要求非常高的场景。设置该值的时候，以监控内存为主要参考。<br>这里需要注意的是如果server的region数量很少，大量的请求都落在一个region上，因快速充满memstore触发flush导致的读写锁会影响全局TPS，不是IO线程数越高越好。<br>压测时，开启Enabling RPC-level logging，可以同时监控每次请求的内存消耗和GC的状况，最后通过多次压测结果来合理调节IO线程数。<br>这里是一个案例?Hadoop and HBase Optimization for Read Intensive Search Applications，作者在SSD的机器上设置IO线程数为100，仅供参考。</p></li><li><p>hbase.hregion.max.filesize<br>默认值：256M<br>说明：在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region。<br>调优：<br>小region对split和compaction友好，因为拆分region或compact小region里的storefile速度很快，内存占用低。缺点是split和compaction会很频繁。<br>特别是数量较多的小region不停地split, compaction，会导致集群响应时间波动很大，region数量太多不仅给管理上带来麻烦，甚至会引发一些Hbase的bug。<br>一般512以下的都算小region。</p></li></ul><p>大region，则不太适合经常split和compaction，因为做一次compact和split会产生较长时间的停顿，对应用的读写性能冲击非常大。此外，大region意味着较大的storefile，compaction时对内存也是一个挑战。<br>当然，大region也有其用武之地。如果你的应用场景中，某个时间点的访问量较低，那么在此时做compact和split，既能顺利完成split和compaction，又能保证绝大多数时间平稳的读写性能。</p><p>既然split和compaction如此影响性能，有没有办法去掉？<br>compaction是无法避免的，split倒是可以从自动调整为手动。<br>只要通过将这个参数值调大到某个很难达到的值，比如100G，就可以间接禁用自动split（RegionServer不会对未到达100G的region做split）。<br>再配合RegionSplitter这个工具，在需要split时，手动split。<br>手动split在灵活性和稳定性上比起自动split要高很多，相反，管理成本增加不多，比较推荐online实时系统使用。</p><p>内存方面，小region在设置memstore的大小值上比较灵活，大region则过大过小都不行，过大会导致flush时app的IO wait增高，过小则因store file过多影响读性能。</p><ul><li><p>hbase.regionserver.global.memstore.upperLimit/lowerLimit<br>默认值：0.4/0.35<br>upperlimit说明：hbase.hregion.memstore.flush.size 这个参数的作用是当单个Region内所有的memstore大小总和超过指定值时，flush该region的所有memstore。RegionServer的flush是通过将请求添加一个队列，模拟生产消费模式来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发OOM。<br>这个参数的作用是防止内存占用过大，当ReigonServer内所有region的memstores所占用内存总和达到heap的40%时，HBase会强制block所有的更新并flush这些region以释放所有memstore占用的内存。<br>lowerLimit说明： 同upperLimit，只不过lowerLimit在所有region的memstores所占用内存达到Heap的35%时，不flush所有的memstore。它会找一个memstore内存占用最大的region，做个别flush，此时写更新还是会被block。lowerLimit算是一个在所有region强制flush导致性能降低前的补救措施。在日志中，表现为 “** Flush thread woke up with memory above low water.”<br>调优：这是一个Heap内存保护参数，默认值已经能适用大多数场景。<br>参数调整会影响读写，如果写的压力大导致经常超过这个阀值，则调小读缓存hfile.block.cache.size增大该阀值，或者Heap余量较多时，不修改读缓存大小。<br>如果在高压情况下，也没超过这个阀值，那么建议你适当调小这个阀值再做压测，确保触发次数不要太多，然后还有较多Heap余量的时候，调大hfile.block.cache.size提高读性能。<br>还有一种可能性是?hbase.hregion.memstore.flush.size保持不变，但RS维护了过多的region，要知道 region数量直接影响占用内存的大小。</p></li><li><p>hfile.block.cache.size</p></li></ul><p>默认值：0.2<br>说明：storefile的读缓存占用Heap的大小百分比，0.2表示20%。该值直接影响数据读的性能。<br>调优：当然是越大越好，如果写比读少很多，开到0.4-0.5也没问题。如果读写较均衡，0.3左右。如果写比读多，果断默认吧。设置这个值的时候，你同时要参考?hbase.regionserver.global.memstore.upperLimit?，该值是memstore占heap的最大百分比，两个参数一个影响读，一个影响写。如果两值加起来超过80-90%，会有OOM的风险，谨慎设置。</p><ul><li><p>hbase.hstore.blockingStoreFiles<br>默认值：7<br>说明：在flush时，当一个region中的Store（Coulmn Family）内有超过7个storefile时，则block所有的写请求进行compaction，以减少storefile数量。<br>调优：block写请求会严重影响当前regionServer的响应时间，但过多的storefile也会影响读性能。从实际应用来看，为了获取较平滑的响应时间，可将值设为无限大。如果能容忍响应时间出现较大的波峰波谷，那么默认或根据自身场景调整即可。</p></li><li><p>hbase.hregion.memstore.block.multiplier<br>默认值：2<br>说明：当一个region里的memstore占用内存大小超过hbase.hregion.memstore.flush.size两倍的大小时，block该region的所有请求，进行flush，释放内存。<br>虽然我们设置了region所占用的memstores总内存大小，比如64M，但想象一下，在最后63.9M的时候，我Put了一个200M的数据，此时memstore的大小会瞬间暴涨到超过预期的hbase.hregion.memstore.flush.size的几倍。这个参数的作用是当memstore的大小增至超过hbase.hregion.memstore.flush.size 2倍时，block所有请求，遏制风险进一步扩大。<br>调优： 这个参数的默认值还是比较靠谱的。如果你预估你的正常应用场景（不包括异常）不会出现突发写或写的量可控，那么保持默认值即可。如果正常情况下，你的写请求量就会经常暴长到正常的几倍，那么你应该调大这个倍数并调整其他参数值，比如hfile.block.cache.size和hbase.regionserver.global.memstore.upperLimit/lowerLimit，以预留更多内存，防止HBase server OOM。</p></li><li><p>hbase.hregion.memstore.mslab.enabled<br>默认值：true<br>说明：减少因内存碎片导致的Full GC，提高整体性能。<br>调优：详见 <a href="http://kenwublog.com/avoid-full-gc-in-hbase-using-arena-allocation" target="_blank" rel="noopener">http://kenwublog.com/avoid-full-gc-in-hbase-using-arena-allocation</a></p></li><li><p>hbase.client.scanner.caching<br>默认值：1<br>说明：scanner调用next方法一次获取的数据条数<br>调优：少的RPC是提高hbase执行效率的一种方法，理论上一次性获取越多数据就会越少的RPC，也就越高效。但是内存是最大的障碍。设置这个值的时候要选择合适的大小，一面一次性获取过多数据占用过多内存，造成其他程序使用内存过少。或者造成程序超时等错误（这个超时与hbase.regionserver.lease.period相关）。</p></li><li><p>hbase.regionserver.lease.period<br>默认值：60000<br>说明：客户端租用HRegion server 期限，即超时阀值。<br>调优：<br>这个配合hbase.client.scanner.caching使用，如果内存够大，但是取出较多数据后计算过程较长，可能超过这个阈值，适当可设置较长的响应时间以防被认为宕机。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;配置优化&quot;&gt;&lt;a href=&quot;#配置优化&quot; class=&quot;head
      
    
    </summary>
    
      <category term="Hbase" scheme="http://www.wenchong.top/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://www.wenchong.top/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce参数优化</title>
    <link href="http://www.wenchong.top/2017/08/19/MapReduce%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/19/MapReduce参数优化/</id>
    <published>2017-08-18T16:00:00.000Z</published>
    <updated>2018-02-18T17:05:07.503Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="1-core-default-xml："><a href="#1-core-default-xml：" class="headerlink" title="1 core-default.xml："></a>1 core-default.xml：</h2><ul><li>hadoop.tmp.dir：</li></ul><p>默认值： /tmp<br>说明： 尽量手动配置这个选项，否则的话都默认存在了里系统的默认临时文件/tmp里。并且手动配置的时候，如果服务器是多磁盘的，每个磁盘都设置一个临时文件目录，这样便于mapreduce或者hdfs等使用的时候提高磁盘IO效率。</p><ul><li>fs.trash.interval：</li></ul><p>默认值： 0<br>说明： 这个是开启hdfs文件删除自动转移到垃圾箱的选项，值为垃圾箱文件清除时间。一般开启这个会比较好，以防错误删除重要文件。单位是分钟。</p><ul><li>io.file.buffer.size：</li></ul><p>默认值：4096<br>说明：SequenceFiles在读写中可以使用的缓存大小，可减少 I/O 次数。在大型的 Hadoop cluster，建议可设定为 65536 到 131072。</p><h2 id="2-hdfs-default-xml："><a href="#2-hdfs-default-xml：" class="headerlink" title="2 hdfs-default.xml："></a>2 hdfs-default.xml：</h2><ul><li>dfs.blocksize：</li></ul><p>默认值：134217728<br>说明： 这个就是hdfs里一个文件块的大小了，CDH5中默认128M。太大的话会有较少map同时计算，太小的话也浪费可用map个数资源，而且文件太小namenode就浪费内存多。根据需要进行设置。</p><ul><li>dfs.namenode.handler.count：</li></ul><p>默认值：10<br>说明：设定 namenode server threads 的数量，这些 threads 會用 RPC 跟其他的 datanodes 沟通。当 datanodes 数量太多时会发現很容易出現 RPC timeout，解決方法是提升网络速度或提高这个值，但要注意的是 thread 数量多也表示 namenode 消耗的内存也随着增加</p><h2 id="3-mapred-default-xml："><a href="#3-mapred-default-xml：" class="headerlink" title="3 mapred-default.xml："></a>3 mapred-default.xml：</h2><ul><li>mapred.reduce.tasks（mapreduce.job.reduces）：</li></ul><p>默认值：1<br>说明：默认启动的reduce数。通过该参数可以手动修改reduce的个数。</p><ul><li>mapreduce.task.io.sort.factor：</li></ul><p>默认值：10<br>说明：Reduce Task中合并小文件时，一次合并的文件数据，每次合并的时候选择最小的前10进行合并。</p><ul><li>mapreduce.task.io.sort.mb：</li></ul><p>默认值：100<br>说明： Map Task缓冲区所占内存大小。</p><ul><li>mapred.child.java.opts：</li></ul><p>默认值：-Xmx200m<br>说明：jvm启动的子线程可以使用的最大内存。建议值-XX:-UseGCOverheadLimit -Xms512m -Xmx2048m -verbose:gc -Xloggc:/tmp/@taskid@.gc</p><ul><li>mapreduce.jobtracker.handler.count：</li></ul><p>默认值：10<br>说明：JobTracker可以启动的线程数，一般为tasktracker节点的4%。</p><ul><li>mapreduce.reduce.shuffle.parallelcopies：</li></ul><p>默认值：5<br>说明：reuduce shuffle阶段并行传输数据的数量。这里改为10。集群大可以增大。</p><ul><li>mapreduce.tasktracker.http.threads：</li></ul><p>默认值：40<br>说明：map和reduce是通过http进行数据传输的，这个是设置传输的并行线程数。</p><ul><li>mapreduce.map.output.compress：</li></ul><p>默认值：false<br>说明： map输出是否进行压缩，如果压缩就会多耗cpu，但是减少传输时间，如果不压缩，就需要较多的传输带宽。配合 mapreduce.map.output.compress.codec使用，默认是 org.apache.hadoop.io.compress.DefaultCodec，可以根据需要设定数据压缩方式。</p><ul><li>mapreduce.reduce.shuffle.merge.percent：</li></ul><p>默认值： 0.66<br>说明：reduce归并接收map的输出数据可占用的内存配置百分比。类似mapreduce.reduce.shuffle.input.buffer.percen属性。</p><ul><li>mapreduce.reduce.shuffle.memory.limit.percent：</li></ul><p>默认值： 0.25<br>说明：一个单一的shuffle的最大内存使用限制。</p><ul><li>mapreduce.jobtracker.handler.count：</li></ul><p>默认值： 10<br>说明：可并发处理来自tasktracker的RPC请求数，默认值10。</p><ul><li>mapred.job.reuse.jvm.num.tasks（mapreduce.job.jvm.numtasks）：</li></ul><p>默认值： 1<br>说明：一个jvm可连续启动多个同类型任务，默认值1，若为-1表示不受限制。</p><ul><li>mapreduce.tasktracker.tasks.reduce.maximum：</li></ul><p>默认值： 2<br>说明：一个tasktracker并发执行的reduce数，建议为cpu核数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;1-core-default-xml：&quot;&gt;&lt;a href=&quot;#1-
      
    
    </summary>
    
      <category term="MapReduce" scheme="http://www.wenchong.top/categories/MapReduce/"/>
    
    
      <category term="MapReduce" scheme="http://www.wenchong.top/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>错误及解决方案</title>
    <link href="http://www.wenchong.top/2017/08/10/ambari%E6%90%AD%E5%BB%BA%E9%94%99%E8%AF%AF/"/>
    <id>http://www.wenchong.top/2017/08/10/ambari搭建错误/</id>
    <published>2017-08-09T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:15.947Z</updated>
    
    <content type="html"><![CDATA[<p>ERROR: Exiting with exit code 1.<br>REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and /var/log/ambari-server/ambari-server-check-database.log for more information.<br>解决方法：查看日志，具体什么错.例如：数据库未开启、数据库配置问题</p><p>撤销已经赋予给 MySQL 用户权限的权限。<br>revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：<br>revoke  all on <em>.</em> from ‘root’@’192.168.0.197’;</p><p>[root@datanode01 ~]# yum makecache<br>Loaded plugins: fastestmirror<br>Determining fastest mirrors<br>ambari-2.4.1.0                                                   | 2.9 kB     00:00<br>ambari-2.4.1.0/filelists_db                                      | 139 kB     00:00<br>ambari-2.4.1.0/primary_db                                        | 8.3 kB     00:00<br>ambari-2.4.1.0/other_db                                          | 1.3 kB     00:00<br>file:///mnt/repodata/repomd.xml: [Errno 14] Could not open/read file:///mnt/repodata/repomd.xml<br>Trying other mirror.<br>Error: Cannot retrieve repository metadata (repomd.xml) for repository: c6-media. Please verify its path and try again</p><p>如果有后面两个文件，处理方式mv CentOS-Media.repo CentOS-Media.repo.bak<br>没有的话，源问题，换源repos</p><h3 id="tip"><a href="#tip" class="headerlink" title="tip:"></a>tip:</h3><p>1、当提示要做如下操作的时候<br>Be?sure?you?have?run:ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/path/to/mysql/<em>**</em><br>需要下载mysql-connector-java-5.1.39.tar驱动，解压得到mysql-connector-java-5.1.39-bin.jar文件<br>执行如下命令：ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/usr/lib/java/mysql-connector-java-5.1.39/mysql-connector-java-5.1.39-<br>bin.jar<br>同时，设置文件权限为644</p><h3 id="2017-7-19"><a href="#2017-7-19" class="headerlink" title="2017.7.19"></a>2017.7.19</h3><p>1.ERROR namenode.NameNode (NameNode.java:main(1759)) - Failed to start namenode.<br>java.net.BindException: Port in use: datanode01:50070<br>  不能获取映射地址，需要修改hosts中的映射ip为真实ip（ifconfig）<br>2.错删自定义的service导致不能登录amnari UI（日志报出database问题） （百度方案无解，最后重装ambari-server(发现重装无法下手，百度后删除ambari相关组件以及数据库的完全卸载，完成)）<br>3.使用ambari-server启动HDFS时，DataNode无法启动（出现port in use：localhost 0）。解决方式，在hosts文件中localhost 172.0.0.1被#；去除#后解决</p><h3 id="一般故障排除"><a href="#一般故障排除" class="headerlink" title="一般故障排除"></a>一般故障排除</h3><p>Ambari服务器：检查/var/log/ambari-server/ambari-server.[log|out]是否存在错误。<br>Ambari代理：检查/var/log/ambari-agent/ambari-agent.[log|out]是否存在错误。<br>请注意，如果Ambari Agent在/var/log/ambari-agent/ambari-agent.out中有任何输出，则表明存在重大问题。</p><h3 id="服务无法启动"><a href="#服务无法启动" class="headerlink" title="服务无法启动"></a>服务无法启动</h3><p>HDFS：检查/ var / log / hadoop / hdfs下的日志文件<br>MapReduce：检查/ var / log / hadoop / mapred下的日志文件<br>HBase：检查/ var / log / hbase下的日志文件<br>Hive：检查/ var / log / hive下的日志文件<br>Oozie：检查/ var / log / oozie下的日志文件<br>ZooKeeper：检查/ var / log / zookeeper下的日志文件<br>WebHCat：检查/ var / log / webhcat下的日志文件<br>Nagios：检查/ var / log / nagios下的日志文件</p><h3 id="2017-7-20"><a href="#2017-7-20" class="headerlink" title="2017.7.20"></a>2017.7.20</h3><p>Service ‘userhome’ check failed: java.io.FileNotFoundException: File does not exist: /user/admin<br>解决方案：sudo -u hdfs hdfs dfs  -mkdir /user/admin<br>sudo -u hdfs hdfs dfs  -chown admin:hadoop /user/admin</p><h3 id="资源池问题"><a href="#资源池问题" class="headerlink" title="资源池问题"></a>资源池问题</h3><p>FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed forblock pool Block pool BP-1480406410-192.168.1.181-1398701121586 (storage idDS-167510828-192.168.1.191-50010-1398750515421)<br>原因：每次namenode format会重新创建一个namenodeId,而data目录包含了上次format时的id,namenode format清空了namenode下的数据,但是没有清空datanode下的数据,导致启动时失败,所要做的就是每次fotmat前,清空data下的所有目录.<br>: d6 E2 t&amp; M” g7 a* q3 l, H<br>解决办法：停掉集群，删除问题节点的data目录下的所有内容。即hdfs-site.xml文件中配置的dfs.data.dir目录。重新格式化namenode。</p><p>另一个更省事的办法：先停掉集群，然后将datanode节点目录/dfs/data/current/VERSION中的修改为与namenode一致即可。<br>其实我没解决，直接重装</p><h3 id="block-missing问题"><a href="#block-missing问题" class="headerlink" title="block missing问题"></a>block missing问题</h3><p>会导致进入安全模式：处理方式，删除缺失包，在HDFS用户下退出安全模式</p><p>添加节点时，需要查看该节点root磁盘下的剩余大小，如果磁盘空间不足，则扩大磁盘再添加节点。<br>不要问我为什么，说多了都是泪。集群就是这么崩盘的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ERROR: Exiting with exit code 1.&lt;br&gt;REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and 
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>amabri卸载</title>
    <link href="http://www.wenchong.top/2017/08/10/ambari%E5%8D%B8%E8%BD%BD/"/>
    <id>http://www.wenchong.top/2017/08/10/ambari卸载/</id>
    <published>2017-08-09T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:22.609Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-删除hdp-repo和hdp-util-repo"><a href="#1-删除hdp-repo和hdp-util-repo" class="headerlink" title="1.删除hdp.repo和hdp-util.repo"></a>1.删除hdp.repo和hdp-util.repo</h2><p>cd /etc/yum.repos.d/<br>rm -rf hdp<em><br>rm -rf HDP</em><br>rm -rf ambari*</p><h2 id="2-删除安装包"><a href="#2-删除安装包" class="headerlink" title="2.删除安装包"></a>2.删除安装包</h2><p>用yum list installed | grep HDP来检查安装的ambari的包<br>yum remove -y  sqoop.noarch<br>yum remove -y  lzo-devel.x86_64<br>yum remove -y  hadoop-libhdfs.x86_64<br>yum remove -y  rrdtool.x86_64<br>yum remove -y  hbase.noarch<br>yum remove -y  pig.noarch<br>yum remove -y  lzo.x86_64<br>yum remove -y  ambari-log4j.noarch<br>yum remove -y  oozie.noarch<br>yum remove -y  oozie-client.noarch<br>yum remove -y  gweb.noarch<br>yum remove -y  snappy-devel.x86_64<br>yum remove -y  hcatalog.noarch<br>yum remove -y  python-rrdtool.x86_64<br>yum remove -y  nagios.x86_64<br>yum remove -y  webhcat-tar-pig.noarch<br>yum remove -y  snappy.x86_64<br>yum remove -y  libconfuse.x86_64<br>yum remove -y  webhcat-tar-hive.noarch<br>yum remove -y  ganglia-gmetad.x86_64<br>yum remove -y  extjs.noarch<br>yum remove -y  hive.noarch<br>yum remove -y  hadoop-lzo.x86_64<br>yum remove -y  hadoop-lzo-native.x86_64<br>yum remove -y  hadoop-native.x86_64<br>yum remove -y  hadoop-pipes.x86_64<br>yum remove -y  nagios-plugins.x86_64<br>yum remove -y  hadoop.x86_64<br>yum remove -y  zookeeper.noarch<br>yum remove -y  hadoop-sbin.x86_64<br>yum remove -y  ganglia-gmond.x86_64<br>yum remove -y  libganglia.x86_64<br>yum remove -y  perl-rrdtool.x86_64<br>yum remove -y  epel-release.noarch<br>yum remove -y  compat-readline5*<br>yum remove -y  fping.x86_64<br>yum remove -y  perl-Crypt-DES.x86_64<br>yum remove -y  exim.x86_64<br>yum remove -y ganglia-web.noarch<br>yum remove -y perl-Digest-HMAC.noarch<br>yum remove -y perl-Digest-SHA1.x86_64<br>yum remove -y bigtop-jsvc.x86_64</p><h2 id="3-删除快捷方式"><a href="#3-删除快捷方式" class="headerlink" title="3.删除快捷方式"></a>3.删除快捷方式</h2><p>cd /etc/alternatives<br>rm -rf hadoop-etc<br>rm -rf zookeeper-conf<br>rm -rf hbase-conf<br>rm -rf hadoop-log<br>rm -rf hadoop-lib<br>rm -rf hadoop-default<br>rm -rf oozie-conf<br>rm -rf hcatalog-conf<br>rm -rf hive-conf<br>rm -rf hadoop-man<br>rm -rf sqoop-conf<br>rm -rf hadoop-conf</p><h2 id="4-删除用户"><a href="#4-删除用户" class="headerlink" title="4.删除用户"></a>4.删除用户</h2><p>userdel nagios<br>userdel hive<br>userdel ambari-qa<br>userdel hbase<br>userdel oozie<br>userdel hcat<br>userdel mapred<br>userdel hdfs<br>userdel rrdcached<br>userdel zookeeper </p><p>#userdel mysql<br>userdel sqoop<br>userdel puppet<br>userdel yarn<br>userdel tez<br>userdel hadoop<br>userdel knox<br>userdel storm<br>userdel falcon<br>userdel flume<br>userdel nagios<br>userdel admin<br>userdel postgres<br>userdel  hdfs<br>userdel  zookeeper<br>userdel hbase</p><h2 id="5-删除文件夹"><a href="#5-删除文件夹" class="headerlink" title="5.删除文件夹"></a>5.删除文件夹</h2><p>rm -rf /hadoop<br>rm -rf /etc/hadoop<br>rm -rf /etc/hbase<br>rm -rf /etc/hcatalog<br>rm -rf /etc/hive<br>rm -rf /etc/ganglia<br>rm -rf /etc/nagios<br>rm -rf /etc/oozie<br>rm -rf /etc/sqoop<br>rm -rf /etc/zookeeper<br>rm -rf /var/run/hadoop<br>rm -rf /var/run/hbase<br>rm -rf /var/run/hive<br>rm -rf /var/run/ganglia<br>rm -rf /var/run/nagios<br>rm -rf /var/run/oozie<br>rm -rf /var/run/zookeeper<br>rm -rf /var/log/hadoop<br>rm -rf /var/log/hbase<br>rm -rf /var/log/hive<br>rm -rf /var/log/nagios<br>rm -rf /var/log/oozie<br>rm -rf /var/log/zookeeper<br>rm -rf /usr/lib/hadoop<br>rm -rf /usr/lib/hbase<br>rm -rf /usr/lib/hcatalog<br>rm -rf /usr/lib/hive<br>rm -rf /usr/lib/oozie<br>rm -rf /usr/lib/sqoop<br>rm -rf /usr/lib/zookeeper<br>rm -rf /var/lib/hive<br>rm -rf /var/lib/ganglia<br>rm -rf /var/lib/oozie<br>rm -rf /var/lib/zookeeper<br>rm -rf /var/tmp/oozie<br>rm -rf /tmp/hive<br>rm -rf /tmp/nagios<br>rm -rf /tmp/ambari-qa<br>rm -rf /tmp/sqoop-ambari-qa<br>rm -rf /var/nagios<br>rm -rf /hadoop/oozie<br>rm -rf /hadoop/zookeeper<br>rm -rf /hadoop/mapred<br>rm -rf /hadoop/hdfs<br>rm -rf /tmp/hadoop-hive<br>rm -rf /tmp/hadoop-nagios<br>rm -rf /tmp/hadoop-hcat<br>rm -rf /tmp/hadoop-ambari-qa<br>rm -rf /tmp/hsperfdata_hbase<br>rm -rf /tmp/hsperfdata_hive<br>rm -rf /tmp/hsperfdata_nagios<br>rm -rf /tmp/hsperfdata_oozie<br>rm -rf /tmp/hsperfdata_zookeeper<br>rm -rf /tmp/hsperfdata_mapred<br>rm -rf /tmp/hsperfdata_hdfs<br>rm -rf /tmp/hsperfdata_hcat<br>rm -rf /tmp/hsperfdata_ambari-qa<br>rm -rf /etc/flume<br>rm -rf /etc/storm<br>rm -rf /etc/hive-hcatalog<br>rm -rf /etc/tez<br>rm -rf /etc/falcon<br>rm -rf /var/run/flume<br>rm -rf /var/run/storm<br>rm -rf /var/run/webhcat<br>rm -rf /var/run/hadoop-yarn<br>rm -rf /var/run/hadoop-mapreduce<br>rm -rf /var/log/flume<br>rm -rf /var/log/storm<br>rm -rf /var/log/hadoop-yarn<br>rm -rf /var/log/hadoop-mapreduce<br>rm -rf /usr/lib/nagios<br>rm -rf /var/lib/hdfs<br>rm -rf /var/lib/hadoop-hdfs<br>rm -rf /var/lib/hadoop-yarn<br>rm -rf /var/lib/hadoop-mapreduce<br>rm -rf /tmp/hadoop-hdfs</p><h2 id="5-重置数据库，删除ambari包"><a href="#5-重置数据库，删除ambari包" class="headerlink" title="5.重置数据库，删除ambari包"></a>5.重置数据库，删除ambari包</h2><p>#采用这句命令来检查yum list installed | grep ambari<br>ambari-server stop<br>ambari-agent stop<br>ambari-server reset<br>yum remove -y ambari-<em><br>yum remove -y postgresql<br>rm -rf /etc/yum.repos.d/ambari</em><br>rm -rf /var/lib/ambari<em><br>rm -rf /var/log/ambari</em><br>rm -rf /etc/ambari*</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-删除hdp-repo和hdp-util-repo&quot;&gt;&lt;a href=&quot;#1-删除hdp-repo和hdp-util-repo&quot; class=&quot;headerlink&quot; title=&quot;1.删除hdp.repo和hdp-util.repo&quot;&gt;&lt;/a&gt;1.删除hdp.
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>Ambari搭建</title>
    <link href="http://www.wenchong.top/2017/08/09/ambari%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.wenchong.top/2017/08/09/ambari搭建/</id>
    <published>2017-08-08T16:00:00.000Z</published>
    <updated>2018-02-18T16:59:50.807Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-物理条件：三台centos"><a href="#1-物理条件：三台centos" class="headerlink" title="1.物理条件：三台centos"></a>1.物理条件：三台centos</h2><p>前期条件：修改每台centos的名称，分别为namenode、datanode01、datanode02<br>          ssh免密码配置：namenode 可以免密码登录到datanode01、datanode02<br>配置ssh<br>      在namenode上生成密钥对：ssh-keygen  –t  rsa<br>      在/root/.ssh中会有生成的密钥对<br>      将namenode  的 id_rsa.pub写入datanode01的/root/.ssh  authorized_keys文件中。再将datanode01的authorized_keys 写入namenode /root/.ssh<br>datanode02同理操作<br>scp .ssh/id_rsa.pub chenlb@192.168.1.181:/home/chenlb/id_rsa.pub<br>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys<br>  将namenode中的三个机器的私钥 id_rsa提取到桌面，后续使用<br>安装ntp服务<br>yum install ntp<br>service ntpd start<br>chkconfig ntpd on</p><h2 id="2-更换源："><a href="#2-更换源：" class="headerlink" title="2.更换源："></a>2.更换源：</h2><p>将/etc/yum.repos.d/下的原centos.repos备份，然后添加本地源（我这是之前师傅在其他服务器布            置好了的源，你们可在网上查找相关源）</p><h2 id="3-验证本机名"><a href="#3-验证本机名" class="headerlink" title="3.验证本机名"></a>3.验证本机名</h2><pre><code>Hostname   -f</code></pre><p>  显示<br>      namenode   其他两台一样</p><h2 id="4-关闭防火墙"><a href="#4-关闭防火墙" class="headerlink" title="4.关闭防火墙"></a>4.关闭防火墙</h2><pre><code>Service iptables stop</code></pre><p>禁用自启动<br>      Chkconfig   iptables  off</p><h2 id="5-禁用ipv6"><a href="#5-禁用ipv6" class="headerlink" title="5.禁用ipv6"></a>5.禁用ipv6</h2><pre><code>使用lsmod查看系统启动的模块：ipv6相关的模块是net-pf-10  ipv6在vi  /etc/modprobe.d/dist.conf    中最后添加</code></pre><p> alias   net-pf-10   off<br>                                    alias  ipv6   off<br>      重启后，再使用lsmod查看ipv6的相应模块还在不在</p><h2 id="6-禁用SELinux"><a href="#6-禁用SELinux" class="headerlink" title="6.禁用SELinux"></a>6.禁用SELinux</h2><p>配置selinux<br>vi  /etc/sysconfig/selinux<br>插入<br>SELINUX=disabled<br>暂时禁用      setenforce  0</p><h2 id="7-配置禁用THP-每次重启机器后需要从新配置"><a href="#7-配置禁用THP-每次重启机器后需要从新配置" class="headerlink" title="7.配置禁用THP(每次重启机器后需要从新配置)"></a>7.配置禁用THP(每次重启机器后需要从新配置)</h2><p>  查看当前THP状态<br>  cat   /sys/kernel/mm/transparent_hugepage/enabled<br>  如果为always  madvise   [never]则为禁用<br>配置禁用<br>echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/defrag<br>echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/enabled<br>echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/defrag<br>echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/enabled</p><h2 id="8-clean源-重新加载"><a href="#8-clean源-重新加载" class="headerlink" title="8.clean源 重新加载"></a>8.clean源 重新加载</h2><pre><code>yum clean allyum makecache</code></pre><h2 id="9-配置mysql作为数据库（只在ambari-server安装机器上做）"><a href="#9-配置mysql作为数据库（只在ambari-server安装机器上做）" class="headerlink" title="9.配置mysql作为数据库（只在ambari-server安装机器上做）"></a>9.配置mysql作为数据库（只在ambari-server安装机器上做）</h2><p>   查看当前安装数据库信息   rpm  -qa  |   grep   -i   mysql<br>    卸载方法 yum   -y   remove  +name<br>    安装MySQL  查看当前源中是否有提供的MySQL<br>    yum   list  |   grep   mysql<br>    安装mysql-server<br>安装<br>    安装后mysql 只有一个用户root 且第一次开启时需要设置密码，我们这通过命令提前设置                   mysqladmin  -u  root  password  ‘’</p><pre><code>设置为自启动  chkconfig  mysqld  on登录到root用户mysql   -u  root   -p create  user  ‘amabri’@’% ’    identified   by   ‘bigdata’;grant   all   privileges   on   *.*    to    ‘ambari’@’%’;create   user   ‘ambari’@’localhost’   identified   by    ‘bigdata’;grant    all    privileges   on   *.*   to    ‘ambari’@’localhost’;create   user   ‘ambari’@’namenode’   identified   by   ‘bigdata’;grant   all   privileges   on   *.*   to   ‘ambari’@’namenode’;登录ambari用户mysql    -u   ambari    -pbigdatacreate  database   ambari;use  ambari;</code></pre><h2 id="10-部署"><a href="#10-部署" class="headerlink" title="10.部署"></a>10.部署</h2><p> （1） yum安装<br> yum  -y  install  ambari-server (每台都要装)<br>后进入mysql -u ambari -p<br>bigdata<br>use ambari;<br>source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql;<br> （2） jdk的安装<br>       下载jdk1.8.0_45安装包  放入/usr/lib/jvm/jdk1.8.0_45/ 解压<br>       配置环境变量  /etc/profile 文件最后加上</p><p>#Java environment<br>       JAVA_HOME=/usr/java/jdk1.8.0_45<br>PATH=$JAVA_HOME/bin:$PATH<br>CLASSPATH=.:$JAVA_HOME/lib/<br>export JAVA_HOME<br>export PATH<br>export CLASSPATH<br>执行：sudo update-alternatives –install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_45/bin/java 300<br>sudo update-alternatives –install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_45/bin/javac 300<br>sudo update-alternatives –install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_45/bin/jar 300<br>查看当前Java版本<br>java  -version<br> （3） 安装ambari-server    (安装在一台centos上即可，部署为ambari-server的机器)<br>ambari-server  setup   -j  /usr/lib/jvm/jdk1.8.0­_45/<br>安装显示：<br>Using python  /usr/bin/python<br> Setup ambari‐server<br>  Checking SELinux…<br> SELinux status is ‘enabled’<br> SELinux mode is ‘permissive’<br>  WARNING: SELinux is set to ‘permissive’ mode and temporarily disabled.<br> OK to continue [y/n] (y)?<br> Customize user account for ambari‐server daemon [y/n] (n)?<br> Adjusting ambari‐server permissions and ownership…<br>  Checking firewall status…<br>  Checking JDK…<br> WARNING: JAVA_HOME /usr/lib/jvm/jdk1.8.0_45 must be valid on ALL hosts  WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited<br>  Completing setup…<br>  Configuring database…<br>  Enter advanced database configuration [y/n] (n)? y<br>  Configuring database…  =============================================================================<br>  Choose one of the following options:<br>  [1] ‐ PostgreSQL (Embedded)<br>  [2] ‐ Oracle<br>  [3] ‐ MySQL / MariaDB<br>  [4] ‐ PostgreSQL<br>  [5] ‐ Microsoft SQL Server (Tech Preview)<br>  [6] ‐ SQL Anywhere<br>  [7] ‐ BDB  =============================================================================<br> Enter choice (3): 3<br>  Hostname (localhost):<br>  Port (3306):<br>  Database name (ambari):<br>  Username (ambari):<br>  Enter Database Password (bigdata):<br>  Configuring ambari database…<br>  Copying JDBC drivers to server resources…<br>  Configuring remote database connection properties…<br>WARNING: Before starting Ambari Server, you must run the following DDL against the databa     se to create the schema: /var/lib/ambari<br> Proceed with configuring remote database connection properties [y/n] (y)? y<br>  Extracting system views……………<br>  Adjusting ambari‐server permissions and ownership…<br>  Ambari Server ‘setup’ completed successfully.<br> （4）启动ambari-server<br>      ambari-server start<br>      启动成功后通过：http：//namenode:8080访问<br>      登录账号及密码：admin<br> （6） 进程操作<br>    1.查看ambari进程<br>      ps   -ef   |   grep   ambari<br>      2.停止ambari进程<br>       ambari-server  stop<br>      3.重启ambari进程<br>       ambari-server  restart<br> （7） 修改端口<br>      vi   /etc/ambari-server/conf/ambari.properties<br>      插入或编辑以下内容<br>      Client.api.port = <port_number></port_number></p><h2 id="11-安装ambari-agent-每台机器都要装"><a href="#11-安装ambari-agent-每台机器都要装" class="headerlink" title="11 安装ambari-agent(每台机器都要装)"></a>11 安装ambari-agent(每台机器都要装)</h2><pre><code>1.安装ambari-agent</code></pre><p>yum   install  ambari-agent<br>    2.配置<br>       vi  /etc/ambari-agent/conf/ambari-agent.ini<br>       插入或更改以下内容<br>       hostname = namenode<br>最后<br>使用谷歌浏览器登录：<a href="http://namenode:8080" target="_blank" rel="noopener">http://namenode:8080</a>        账号：admin    密码：admin<br>注意：选择操作系统时，应该选择当前机器的版本。如果是本地源，<br>则需要修改HDP、HDP-UTILS的位置</p><p>If you are lucky enough, that I wish you success.<br>Said too much, tears.</p><p>如果出现ip绑定问题，修改/etc/hosts/中的ip为每台机器的真实ip<br>查看ip命令ifconfig<br>出现mysql  drive驱动问题   yum  install  mysql-connector-java</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-物理条件：三台centos&quot;&gt;&lt;a href=&quot;#1-物理条件：三台centos&quot; class=&quot;headerlink&quot; title=&quot;1.物理条件：三台centos&quot;&gt;&lt;/a&gt;1.物理条件：三台centos&lt;/h2&gt;&lt;p&gt;前期条件：修改每台centos的名称
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>centos和Ubuntu本地源制作</title>
    <link href="http://www.wenchong.top/2017/08/05/centos%E5%92%8CUbuntu%E5%88%B6%E4%BD%9C%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    <id>http://www.wenchong.top/2017/08/05/centos和Ubuntu制作本地源/</id>
    <published>2017-08-04T16:00:00.000Z</published>
    <updated>2018-02-18T17:01:39.140Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="CentOS系统"><a href="#CentOS系统" class="headerlink" title="CentOS系统"></a>CentOS系统</h2><ul><li>使用yum安装软件时，下载的* .rpm包缓存在/var/cache/yum/x86_64/7/；</li><li>创建目录</li><li>用于存放特定软件所需的软件包；</li></ul><p>mkdir -p /opt/packages</p><ul><li>下载软件包<br>yum install -y –downloadonly –downloaddir=/opt/packages python-openstackclient</li><li>生成repo文件<br>yum install -y createrepo</li></ul><p>createrepo /opt/packages</p><ul><li>生成压缩包</li></ul><p>tar -zcf packages.tgz packages/</p><ul><li>配置本地源</li></ul><p>tar -zxf packages.tgz -C /opt<br>vim /etc/yum.repos.d/local.repo</p><p>[Local]<br>name=Local Yum<br>baseurl=file:////opt/packages/<br>gpgcheck=0<br>enabled=1</p><ul><li>客户端安装软件：<br>yum install python-openstackclient<h2 id="Ubuntu系统"><a href="#Ubuntu系统" class="headerlink" title="Ubuntu系统"></a>Ubuntu系统</h2></li><li>使用apt命令安装软件时，下载的* .deb包缓存在/var/cache/apt/archives/；</li><li>创建目录</li><li>用于存放特定软件所需的软件包；</li></ul><p>mkdir -p /opt/packages</p><ul><li>下载软件包</li><li>清除旧的缓存：</li></ul><p>rm -f /var/cache/apt/archives/* .deb</p><ul><li>下载软件包：</li></ul><p>apt install -d -y –force-yes PACKAGE-NAME</p><ul><li>拷贝软件包</li></ul><p>cp /var/cache/apt/archives/* .deb /opt/packages/</p><ul><li>生成Packages.gz包<br>Packages.gz中包含软件包信息以及其依赖关系信息；</li><li>安装dpkg-dev以便使用dpkg-scanpackages命令生成Packages.gz文件；</li></ul><p>apt install -y dpkg-dev</p><ul><li>单机版本地源</li><li>此处忽略一切的警告(warning)；</li></ul><p>cd /opt/<br>dpkg-scanpackages packages/ /dev/null | gzip &gt; /opt/packages/Packages.gz -r</p><ul><li>制作成压缩包，便于网络传输；</li></ul><p>cd /opt/<br>tar -zcf packages.tgz packages/</p><ul><li><p>将压缩包拷贝到目标主机；</p></li><li><p>解压压缩包并配置软件源(目标主机)：</p></li></ul><p>tar -zxf packages.tgz -C /opt<br>echo ‘deb file:///opt/ packages/‘ &gt; /etc/apt/sources.list</p><ul><li><p>临时的Web共享本地源</p></li><li><p>此处忽略一切的警告(warning)；</p></li></ul><p>cd /opt/packages/<br>dpkg-scanpackages . /dev/null | gzip &gt; /opt/packages/Packages.gz -r</p><ul><li>使用Python自带的SimpleHTTPServer会在当前目录启动一个简易的Web服务器；</li></ul><p>cd /opt/packages/<br>python -m SimpleHTTPServer PORT</p><ul><li>配置软件源(目标主机):<br>echo ‘deb <a href="http://IP:PORT/" target="_blank" rel="noopener">http://IP:PORT/</a> /‘ &gt; /etc/apt/sources.list</li><li><p>搭建Web服务共享本地源</p></li><li><p>搭建主流的Web服务：Apache服务或Nginx服务；</p></li><li>配置Web服务，根目录指向/opt/packages/；</li><li>配置软件源(目标主机):<br>echo ‘deb <a href="http://IP:PORT/" target="_blank" rel="noopener">http://IP:PORT/</a> /‘ &gt; /etc/apt/sources.list</li><li>安装软件(目标主机)<br>apt update<br>apt install -y –force-yes PACKAGE-NAME</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;CentOS系统&quot;&gt;&lt;a href=&quot;#CentOS系统&quot; cla
      
    
    </summary>
    
      <category term="本地源" scheme="http://www.wenchong.top/categories/%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    
    
      <category term="本地源" scheme="http://www.wenchong.top/tags/%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>HDFS手动优化</title>
    <link href="http://www.wenchong.top/2017/07/11/HDFS%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96%20/"/>
    <id>http://www.wenchong.top/2017/07/11/HDFS手动优化 /</id>
    <published>2017-07-10T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:24.090Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="一-Linux文件系统参数调整"><a href="#一-Linux文件系统参数调整" class="headerlink" title="一 Linux文件系统参数调整"></a>一 Linux文件系统参数调整</h2><p>（1） noatime 和 nodiratime属性<br>文件挂载时设置这两个属性可以明显提高性能。。默认情况下，Linux ext2/ext3 文件系统在文件被访问、创建、修改时会记录下文件的时间戳，比如：文件创建时间、最近一次修改时间和最近一次访问时间。如果系统运行时要访问大量文件，关闭这些操作，可提升文件系统的性能。Linux 提供了 noatime 这个参数来禁止记录最近一次访问时间戳。<br>（2） readahead buffer<br>调整linux文件系统中预读缓冲区地大小，可以明显提高顺序读文件的性能。默认buffer大小为256 sectors，可以增大为1024或者2408 sectors（注意，并不是越大越好）。可使用blockdev命令进行调整。<br>（3） 避免RAID和LVM操作<br>避免在TaskTracker和DataNode的机器上执行RAID和LVM操作，这通常会降低性能。<br>3.2.2 Hadoop通用参数调整<br>（1） dfs.namenode.handler.count或mapred.job.tracker.handler.count<br>amenode或者jobtracker中用于处理RPC的线程数，默认是10，较大集群，可调大些，比如64。<br>（2） dfs.datanode.handler.count<br>datanode上用于处理RPC的线程数。默认为3，较大集群，可适当调大些，比如8。需要注意的是，每添加一个线程，需要的内存增加。<br>（3） tasktracker.http.thread<br>HTTP server上的线程数。运行在每个TaskTracker上，用于处理map task输出。大集群，可以将其设为40~50。</p><h2 id="二-HDFS相关配置"><a href="#二-HDFS相关配置" class="headerlink" title="二 HDFS相关配置"></a>二 HDFS相关配置</h2><p>（1） dfs.replicatio<br>文件副本数，通常设为3，不推荐修改。<br>（2） dfs.block.size<br>HDFS中数据block大小，默认为64M，对于较大集群，可设为128MB或者256MB。（也可以通过参数mapred.min.split.size配置）<br>（3） mapred.local.dir和dfs.data.dir<br>这两个参数mapred.local.dir和dfs.data.dir 配置的值应当是分布在各个磁盘上目录，这样可以充分利用节点的IO读写能力。运行 Linux sysstat包下的iostat -dx 5命令可以让每个磁盘都显示它的利用率。<br>3.2.4 map/reduce 相关配置<br>（1） {map/reduce}.tasks.maximum<br>同时运行在TaskTracker上的最大map/reduce task数，一般设为(core_per_node)/2~2*（cores_per_node）。<br>（2） io.sort.factor<br>当一个map task执行完之后，本地磁盘上(mapred.local.dir)有若干个spill文件，map task最后做的一件事就是执行merge sort，把这些spill文件合成一个文件（partition）。执行merge sort的时候，每次同时打开多少个spill文件由该参数决定。打开的文件越多，不一定merge sort就越快，所以要根据数据情况适当的调整。<br>（3） mapred.child.java.opt<br>设置JVM堆的最大可用内存，需从应用程序角度进行配置。</p><h2 id="三-map-task相关配置"><a href="#三-map-task相关配置" class="headerlink" title="三 map task相关配置"></a>三 map task相关配置</h2><p>（1） io.sort.m<br>Map task的输出结果和元数据在内存中所占的buffer总大小。默认为100M，对于大集群，可设为200M。当buffer达到一定阈值，会启动一个后台线程来对buffer的内容进行排序，然后写入本地磁盘(一个spill文件)。<br>（2） io.sort.spill.percent<br>这个值就是上述buffer的阈值，默认是0.8，即80%，当buffer中的数据达到这个阈值，后台线程会起来对buffer中已有的数据进行排序，然后写入磁盘。<br>（3） io.sort.record<br>Io.sort.mb中分配给元数据的内存百分比，默认是0.05。这个需要根据应用程序进行调整。<br>（4） mapred.compress.map.output/ Mapred.output.compre<br>中间结果和最终结果是否要进行压缩，如果是，指定压缩方式（Mapred.compress.map.output.codec/ Mapred.output.compress.codec）。推荐使用LZO压缩。Intel内部测试表明，相比未压缩，使用LZO压缩的TeraSort作业运行时间减少60%，且明显快于Zlib压缩。<br>3.2.6 reduce task相关配置<br>（1） Mapred.reduce.parallel<br>Reduce shuffle阶段copier线程数。默认是5，对于较大集群，可调整为16~25。</p><h2 id="四-通过hadoop的参数进行调优"><a href="#四-通过hadoop的参数进行调优" class="headerlink" title="四 通过hadoop的参数进行调优"></a>四 通过hadoop的参数进行调优</h2><p>(1):设置合理的槽位数目(具体配置 mapred.tasktracker.map.tasks.maximum | mapred.tasktracker.reduce.tasks.maximum |<br>     mapreduce.tasktracker.map.tasks.maximum | mapreduce.tasktracker.reduce.tasks.maximum)<br>(2):调整心跳间隔,对于300台以下的集群 可以把心跳设置成300毫秒(默认是3秒),mapreduce.jobtracker.hearbeat.interval.min | mapred.hearbeats.in.second | mapreduce.jobtracker.heartbeats.scaling.factor<br>(3):启用外心跳,为了减少任务分配延迟(比如我们的任务心跳设置为10秒钟,当有一个任务挂掉了之后,他就不能马上通知jobtracker),<br>所以hadoop引入了外心跳,外心跳是任务运行结束或者任务运行失败的时候触发的,能够在出现空闲资源时第一时间通知jobtracker,以便他能够迅速为空闲资源分配新的任务<br>外心跳的配置参数是 mapreduce.tasktracker.outofband.hearbeat<br>   (4):磁盘快的配置. map task会把中间结果放到本地磁盘中,所以对于I/O密集的任务来说这部分数据会对本地磁盘造成很大的压力,我们可以配置多块可用磁盘,hadoop将采用轮训的方式将不同的maptask的中间结果写到磁盘上<br>                    maptask中间结果的配置参数是mapred.local.dir | mapreduce.cluster.local.dir<br>   (5):配置RPC Handler的数量,jobracker需要冰法处理来自各个tasktracker的RPC请求,我们可以根据集群规模和服务器并发处理的情况调整RPC Handler的数目,以使jobtracker的服务能力最佳<br>    配置参数是 mapred.job.tracker.handler.count | mapreduce.jobtracker.handler.count  (默认是10)<br>   (6):配置HTTP线程数.  在shuffle阶段,reduce task 通过http请求从各个tasktracker上读取map task中间结果,而每个tasktracker通过jetty server处理这些http请求,所以可以适当配置调整jetty server的工作线程数<br>    配置参数是 tasktracker.http.thread | mapreduce.tasktracker.http.threads  (默认是40)<br>   (7):如果我们在运行作业的过程中发现某些机器被频繁地添加到黑名单里面,我们可以把此功能关闭<br>   (8):使用合理调度器<br>   (9):使用合适的压缩算法,在hadoop里面支持的压缩格式是: gzip,zip,bzip2,LZO,Snappy,LZO和Snappy的呀搜比和压缩效率都很优秀,Snappy是谷歌的开源数据压缩哭,他已经内置在hadoop1.0之后的版本,LZO得自己去编译<br>   (10):开启预读机制. 预读机制可以有效提高磁盘I/O的读性能,目前标准版的apache hadoop不支持此功能,但是在cdh中是支持的<br>    配置参数是: mapred.tasktracker.shuffle.fadvise=true (是否启用shuffle预读取机制)<br>              mapred.tasktracker.shuffle.readahead.bytes=4MB (shuffle预读取缓冲区大小)<br>              mapreduce.ifile.readahead = true (是否启用ifile预读取机制)<br>              mapreduce.ifile.readahead.bytes = 4MB (IFile预读取缓冲区大小)<br>   (11):启用推测执行机制<br>   (12):map task调优: 合理调整io.sort.record.percent值,可减少中间文件数据,提高任务执行效率.<br>    (map task的输出结果将被暂时存放到一个环形缓冲区中,这个缓冲区的大小由参数”io.sort.mb”指定,单位MB,默认是100MB,<br>    该缓冲区主要由两部分组成,索引和实际数据,默认情况下,索引占整个buffer的比例为io.sort.record.percent,默认是5%,<br>    剩余空间存放数据,仅当满足以下任意一个条件时才会触发一次flush,生成一个临时文件,索引或者数据空间使用率达到比例为<br>    io.sort.spill.percent的80%)<br>    所以具体调优参数如下:  io.sort.mb | io.sort.record.percent | io.sort.spill.percent<br>    (13):reduce task调优   reduce task会启动多个拷贝线程从每个map task上读取相应的中间结果,参数是”mapred.reduce.parallel.copies”(默认是5)<br>    原理是这样的–&gt;对于每个待拷贝的文件,如果文件小于一定的阀值A,则将其放入到内存中,否则已文件的形式存放到磁盘上,<br>    如果内存中文件满足一定条件D,则会将这些数据写入磁盘中,而当磁盘上文件数目达到io.sort.factor(默认是10)时,<br>    所以如果中间结果非常大,可以适当地调节这个参数的值<br>    (14):跳过坏记录 看具体参数说明,=号后面是默认值<br>    mapred.skip.attempts.to.start.skipping=2 当任务失败次数达到该值时,才会进入到skip mode,即启用跳过坏记录gongnneg<br>    mapred.skip.map.max,skip.records=0 用户可通过该参数设置最多运行跳过的记录数目<br>    mapred.skip.reduce.max.skip.groups=0 用户可通过设置该参数设置Reduce Task最多允许跳过的记录数目<br>    mapred.skip.out.dir =${mapred.output.dir}/logs/ 检测出得坏记录存放到目录里面(一般为HDFS路径),hadoop将坏记录保存起来以便于用户调试和跟踪</p><pre><code>(15):使用JVM重用 : mapred.job.reuse.jvm.aum.tasks | mapreduce.job.jvm.num.tasks = -1</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;一-Linux文件系统参数调整&quot;&gt;&lt;a href=&quot;#一-Linu
      
    
    </summary>
    
      <category term="HDFS" scheme="http://www.wenchong.top/categories/HDFS/"/>
    
    
      <category term="HDFS" scheme="http://www.wenchong.top/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>java读取Excel表格中的数据</title>
    <link href="http://www.wenchong.top/2017/05/20/java%E8%AF%BB%E5%8F%96Excel%E8%A1%A8%E6%A0%BC%E6%95%B0%E6%8D%AE/"/>
    <id>http://www.wenchong.top/2017/05/20/java读取Excel表格数据/</id>
    <published>2017-05-19T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:56.955Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-需求"><a href="#1-需求" class="headerlink" title="1.需求"></a>1.需求</h3><p>用java代码读取Excel.xls表格中的数据</p><h3 id="2-java代码"><a href="#2-java代码" class="headerlink" title="2.java代码"></a>2.java代码</h3><p>package com.test;<br>import java.io.File;<br>import jxl.*;<br>public class ReadExcel{<br>    public static void main(String[] args){<br>        ing i;<br>        Sheet sheet;<br>        Workbook book;<br>        Cell cell1,cell2,cell3,cell4,cell5,cell6,cell7;<br>        try{</p><pre><code>        //Excel.xls为要读取的excel文件        book = Workbook.getWorkbook(new File(&quot;文件物理地址&quot;)))；        //获取第一个工作表对象（excel中sheet的编号从0开始，0,1,2,3，.....）        sheet = book.getSheet(0);        //获取左上角的单元格        cell1 = sheet.getCell(0,0);(行，列)        System.out.println(&quot;标题：&quot;+cell1.getContents());        i = 1;        while(true){            //获取每一行单元格            cell1 = sheet.getCell(0,i);            cell2 = sheet.getCell(1,i);            cell3 = sheet.getCell(2,i);            cell4 = sheet.getCell(3,i);            cell5 = sheet.getCell(4,i);            cell6 = sheet.getCell(5,i);            cell7 = sheet.getCell(6,i);            if(&quot;&quot;.equals(cell1.getContents()) == true) //如果读取的数据为空            break;            System.out.println(cell1.getContents()+&quot;\t&quot;+cell2.getContents()+&quot;\t&quot;+cell3.getContents()+&quot;\t&quot;+cell4.getContents()+&quot;\t&quot;+cell5.getContents()+&quot;\t&quot;+cell6.getContents()+&quot;\t&quot;);            i++;        }        book.close();    }    catch(Exceprion e){        }}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-需求&quot;&gt;&lt;a href=&quot;#1-需求&quot; class=&quot;headerlink&quot; title=&quot;1.需求&quot;&gt;&lt;/a&gt;1.需求&lt;/h3&gt;&lt;p&gt;用java代码读取Excel.xls表格中的数据&lt;/p&gt;
&lt;h3 id=&quot;2-java代码&quot;&gt;&lt;a href=&quot;#2-jav
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Hbase-写入方式</title>
    <link href="http://www.wenchong.top/2017/05/08/Hbase-5%E7%A7%8D%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F/"/>
    <id>http://www.wenchong.top/2017/05/08/Hbase-5种写入方式/</id>
    <published>2017-05-07T16:00:00.000Z</published>
    <updated>2018-02-18T17:02:47.521Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1><h3 id="HBase写入数据方式（参考：《HBase-The-Definitive-Guide》）"><a href="#HBase写入数据方式（参考：《HBase-The-Definitive-Guide》）" class="headerlink" title="HBase写入数据方式（参考：《HBase The Definitive Guide》）"></a>HBase写入数据方式（参考：《HBase The Definitive Guide》）</h3><ul><li>1.直接使用HTable进行导入，代码如下：</li></ul><p>package hbase.curd;<br>import java.io.IOException;<br>import java.util.ArrayList;<br>import java.util.List;<br>impirt java.util.Random;<br>import org.apache.hadoop.hbase.client.HTable;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.util.Bytes;</p><p>public class PutExample{</p><pre><code>private HTable table = HTableUtil.getHTable(&quot;testtable&quot;);public static void main(String args[]) throws IOException{    PutExample pe = new PutExample();    pe.putRows();}    public void putRows(){    List&lt;Put&gt; puts = new ArrayList&lt;Put&gt;;    for(int i=0; i&lt;10; i++){        Put put = new Put(Bytes.toBytes(&quot;row_&quot;+i));        Rowdom random = new Random();        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual3&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual4&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));            }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual5&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        puts.add(put);    }    try{        table.put(puts);        table.close();    }catch(Exception e){        e.printStackTrace();        return ;    }    System.out.println(&quot;done put rows&quot;);    }}</code></pre><p>}</p><h3 id="其中HTableUtil如下："><a href="#其中HTableUtil如下：" class="headerlink" title="其中HTableUtil如下："></a>其中HTableUtil如下：</h3><p>package hbase.curd;</p><p>import java.io.IOException;</p><p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.hbase.HBaseConfiguration;<br>import org.apache.hadoop.hbase.client.HTable;<br>import org.apache.hadoop.hbase.util.Bytes;</p><p>public class HTableUtil {<br>    private static HTable table;<br>    private static Configuration conf;</p><pre><code>static{    conf =HBaseConfiguration.create();    conf.set(&quot;mapred.job.tracker&quot;, &quot;hbase:9001&quot;);    conf.set(&quot;fs.default.name&quot;, &quot;hbase:9000&quot;);    conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;hbase&quot;);    try {        table = new HTable(conf,&quot;testtable&quot;);    } catch (IOException e) {        // TODO Auto-generated catch block        e.printStackTrace();    }}public static Configuration getConf(){    return conf;}public static HTable getHTable(String tablename){    if(table==null){        try {            table= new HTable(conf,tablename);        } catch (IOException e) {            // TODO Auto-generated catch block            e.printStackTrace();        }     }    return table;}public static  byte[] gB(String name){    return Bytes.toBytes(name);}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;&lt;h3 id=&quot;HBase写入数据方式（参考：《HBase-The-Definit
      
    
    </summary>
    
      <category term="Hbase" scheme="http://www.wenchong.top/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://www.wenchong.top/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>java基础——String&amp;StringBuffer</title>
    <link href="http://www.wenchong.top/2017/03/14/java%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94String&amp;StringBuffer/"/>
    <id>http://www.wenchong.top/2017/03/14/java基础——String&amp;StringBuffer/</id>
    <published>2017-03-13T16:00:00.000Z</published>
    <updated>2018-02-18T17:04:37.608Z</updated>
    
    <content type="html"><![CDATA[<ul><li>创建字符串<br>创建字符串最简单的方式如下:<br>String greeting = “王小二客栈”;<br>注意:String 类是不可改变的，所以你一旦创建了 String 对象，那它的值就无法改变了。<br>如果需要对字符串做很多修改，那么应该选择使用 StringBuffer &amp; StringBuilder 类。</li><li>字符串长度<br>用于获取有关对象的信息的方法称为访问器方法。<br>String 类的一个访问器方法是 length() 方法，它返回字符串对象包含的字符数。</li><li><p>连接字符串<br>String 类提供了连接两个字符串的方法：<br>string1.concat(string2);<br>更常用的是使用’+’操作符来连接字符串，如：<br>“Hello,” + “ xiaoer” + “!”</p><h3 id="String-方法"><a href="#String-方法" class="headerlink" title="String 方法"></a>String 方法</h3><ul><li>char charAt(int index)  返回指定索引处的char值。 </li><li>int compareTo（Object o）  把这个字符串和另一个对象比较。  </li><li>int compareTo(String anotherString)  按字典顺序比较两个字符串。  </li><li>int compareToIgnoreCase(String str)  按字典顺序比较两个字符串，不考虑大小写。  </li><li>String concat(String str)  将指定字符串连接到此字符串的结尾。  </li><li>boolean contentEquals(StringBuffer sb)  当且仅当字符串与指定的StringButter有相同顺序的字符时候返回真。  </li><li>static String copyValueOf(char[] data)  返回指定数组中表示该字符序列的 String。  </li><li>static String copyValueOf(char[] data, int offset, int count)  返回指定数组中表示该字符序列的 String。  </li><li>boolean endsWith(String suffix)  测试此字符串是否以指定的后缀结束。  </li><li>boolean equals(Object anObject)  将此字符串与指定的对象比较。    boolean equalsIgnoreCase(String anotherString)     将此 String 与另一个 String 比较，不考虑大小写。  </li><li>byte[] getBytes()  使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。  </li><li>byte[] getBytes(String charsetName)  使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。  </li><li>void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)  将字符从此字符串复制到目标字符数组。  </li><li>int hashCode()  返回此字符串的哈希码。  </li><li>int indexOf(int ch)  返回指定字符在此字符串中第一次出现处的索引。  </li><li>int indexOf(int ch, int fromIndex)  返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。  </li><li>int indexOf(String str)  返回指定子字符串在此字符串中第一次出现处的索引。  </li><li>int indexOf(String str, int fromIndex)  返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。  </li><li>String intern()  返回字符串对象的规范化表示形式。  </li><li>int lastIndexOf(int ch)  返回指定字符在此字符串中最后一次出现处的索引。  </li><li>int lastIndexOf(int ch, int fromIndex)  返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。  </li><li>int lastIndexOf(String str)  返回指定子字符串在此字符串中最右边出现处的索引。  </li><li>int lastIndexOf(String str, int fromIndex)  返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索。  </li><li>int length()  返回此字符串的长度。  </li><li>boolean matches(String regex)  告知此字符串是否匹配给定的正则表达式。  </li><li>boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len)  测试两个字符串区域是否相等。  </li><li>boolean regionMatches(int toffset, String other, int ooffset, int len)  测试两个字符串区域是否相等。  </li><li>String replace(char oldChar, char newChar)  返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。  </li><li>String replaceAll(String regex, String replacement)  使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。  </li><li>String[] split(String regex)  根据给定正则表达式的匹配拆分此字符串。  </li><li>String[] split(String regex, int limit)  根据匹配给定的正则表达式来拆分此字符串。  </li><li>boolean startsWith(String prefix)  测试此字符串是否以指定的前缀开始。  </li><li>boolean startsWith(String prefix, int toffset)  测试此字符串从指定索引开始的子字符串是否以指定前缀开始。  </li><li>CharSequence subSequence(int beginIndex, int endIndex)  返回一个新的字符序列，它是此序列的一个子序列。  </li><li>String substring(int beginIndex)  返回一个新的字符串，它是此字符串的一个子字符串。  </li><li>String substring(int beginIndex, int endIndex)  返回一个新字符串，它是此字符串的一个子字符串。  </li><li>char[] toCharArray()  将此字符串转换为一个新的字符数组。  </li><li>String toLowerCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为小写。  </li><li>String toLowerCase(Locale locale)  使用给定 Locale 的规则将此 String 中的所有字符都转换为小写。  </li><li>String toString()  返回此对象本身（它已经是一个字符串！）。  </li><li>String toUpperCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为大写。  </li><li>String toUpperCase(Locale locale)  使用给定 Locale 的规则将此 String 中的所有字符都转换为大写。  </li><li>String trim()  返回字符串的副本，忽略前导空白和尾部空白。  </li><li>static String valueOf(primitive data type x)  返回给定data type类型x参数的字符串表示形式。  </li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;创建字符串&lt;br&gt;创建字符串最简单的方式如下:&lt;br&gt;String greeting = “王小二客栈”;&lt;br&gt;注意:String 类是不可改变的，所以你一旦创建了 String 对象，那它的值就无法改变了。&lt;br&gt;如果需要对字符串做很多修改，那么应该选择使用
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>王小二客栈——Java Number&amp;Math</title>
    <link href="http://www.wenchong.top/2017/03/13/java%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94Number&amp;Math/"/>
    <id>http://www.wenchong.top/2017/03/13/java基础——Number&amp;Math/</id>
    <published>2017-03-12T16:00:00.000Z</published>
    <updated>2018-02-18T17:04:22.900Z</updated>
    
    <content type="html"><![CDATA[<h2 id="忆往昔峥嵘岁月，不堪入目"><a href="#忆往昔峥嵘岁月，不堪入目" class="headerlink" title="忆往昔峥嵘岁月，不堪入目"></a>忆往昔峥嵘岁月，不堪入目</h2><ul><li>1.所有的包装类（Integer、Long、Byte、Double、Float、Short）都是抽象类Number的子类。</li><li>2.Java的Math包含了用于执行基本数学运算的属性和方法，如初等指数、对数、平方根和三角函数等。</li><li>Math的方法都被定义为static形式，通过Math类可以在主函数中直接调用。</li></ul><h3 id="下面列出Number-amp-Math类常用的一些方法："><a href="#下面列出Number-amp-Math类常用的一些方法：" class="headerlink" title="下面列出Number &amp; Math类常用的一些方法："></a>下面列出Number &amp; Math类常用的一些方法：</h3><ul><li>xxxValue()    将Number对象装换成xxx数据类型的值并返回。</li><li>compareTo（）    将number对象与参数比较。</li><li>equals()    判断number对象是否与参数相等。</li><li>valueOf()    返回一个Number对象制定的内置数据类型。</li><li>toString()    以字符串形式返回值。</li><li>parseInt()    将字符串解析为int类型。</li><li>abs()        返回参数的绝对值。</li><li>ceil（）    返回大于等于（&gt;=）给定参数的最小整数。</li><li>floor()    返回小雨等于（&lt;=）给定参数的最大整数。</li><li>rint（）    返回与参数最接近的整数，返回类型为double。</li><li>round()    他表示四舍五入。</li><li>min()        返回两个参数之间的最小值。</li><li>max()        返回两个参数之间的最大值。</li><li>exp（）    返回自然数底数e的参数次方。</li><li>log()        返回参数的自然数底数的对数值。</li><li><strong>random（)</strong>    返回一个随机数。</li></ul><h2 id="Java-Character-类"><a href="#Java-Character-类" class="headerlink" title="Java Character 类"></a>Java Character 类</h2><ul><li>Character 类用于对单个字符进行操作。</li><li>Character 类在对象中包装一个基本类型 char 的值。<h3 id="转义序列"><a href="#转义序列" class="headerlink" title="转义序列"></a>转义序列</h3>转义序列    描述<br>\t    在文中该处插入一个tab键<br>\b    在文中该处插入一个后退键<br>\n    在文中该处换行<br>\r    在文中该处插入回车<br>\f    在文中该处插入换页符<br>\’    在文中该处插入单引号<br>\”    在文中该处插入双引号<br>\    在文中该处插入反斜杠</li></ul><h3 id="Character-方法"><a href="#Character-方法" class="headerlink" title="Character 方法"></a>Character 方法</h3><p>isLetter()    是否是一个字母<br>isDigit()    是否是一个数字字符<br>isWhitespace()    是否为一个空格<br>isUpperCase()    是否是大写字母<br>isLowCase()    是否是小写字母<br>toUpperCase()    制定之母的大写形式<br>toLowCase()    制定之母的小写形式<br>toString()    返回字符的字符串形式，字符串的长短仅为1。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;忆往昔峥嵘岁月，不堪入目&quot;&gt;&lt;a href=&quot;#忆往昔峥嵘岁月，不堪入目&quot; class=&quot;headerlink&quot; title=&quot;忆往昔峥嵘岁月，不堪入目&quot;&gt;&lt;/a&gt;忆往昔峥嵘岁月，不堪入目&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;1.所有的包装类（Integer、Long、By
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
</feed>
