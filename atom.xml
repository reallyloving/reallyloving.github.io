<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王小二客栈</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.wenchong.top/"/>
  <updated>2018-02-17T14:13:57.246Z</updated>
  <id>http://www.wenchong.top/</id>
  
  <author>
    <name>小二</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>王小二客栈</title>
    <link href="http://www.wenchong.top/2018/02/17/myblog-test/"/>
    <id>http://www.wenchong.top/2018/02/17/myblog-test/</id>
    <published>2018-02-17T14:20:06.596Z</published>
    <updated>2018-02-17T14:13:57.246Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>java基础——String&amp;StringBuffer</title>
    <link href="http://www.wenchong.top/2018/02/17/java%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94String&amp;StringBuffer/"/>
    <id>http://www.wenchong.top/2018/02/17/java基础——String&amp;StringBuffer/</id>
    <published>2018-02-17T14:20:06.588Z</published>
    <updated>2018-02-17T15:52:45.244Z</updated>
    
    <content type="html"><![CDATA[<ul><li>创建字符串<br>创建字符串最简单的方式如下:<br>String greeting = “王小二客栈”;<br>注意:String 类是不可改变的，所以你一旦创建了 String 对象，那它的值就无法改变了。<br>如果需要对字符串做很多修改，那么应该选择使用 StringBuffer &amp; StringBuilder 类。</li><li>字符串长度<br>用于获取有关对象的信息的方法称为访问器方法。<br>String 类的一个访问器方法是 length() 方法，它返回字符串对象包含的字符数。</li><li><p>连接字符串<br>String 类提供了连接两个字符串的方法：<br>string1.concat(string2);<br>更常用的是使用’+’操作符来连接字符串，如：<br>“Hello,” + “ xiaoer” + “!”</p><h3 id="String-方法"><a href="#String-方法" class="headerlink" title="String 方法"></a>String 方法</h3><ul><li>char charAt(int index)  返回指定索引处的char值。 </li><li>int compareTo（Object o）  把这个字符串和另一个对象比较。  </li><li>int compareTo(String anotherString)  按字典顺序比较两个字符串。  </li><li>int compareToIgnoreCase(String str)  按字典顺序比较两个字符串，不考虑大小写。  </li><li>String concat(String str)  将指定字符串连接到此字符串的结尾。  </li><li>boolean contentEquals(StringBuffer sb)  当且仅当字符串与指定的StringButter有相同顺序的字符时候返回真。  </li><li>static String copyValueOf(char[] data)  返回指定数组中表示该字符序列的 String。  </li><li>static String copyValueOf(char[] data, int offset, int count)  返回指定数组中表示该字符序列的 String。  </li><li>boolean endsWith(String suffix)  测试此字符串是否以指定的后缀结束。  </li><li>boolean equals(Object anObject)  将此字符串与指定的对象比较。    boolean equalsIgnoreCase(String anotherString)     将此 String 与另一个 String 比较，不考虑大小写。  </li><li>byte[] getBytes()  使用平台的默认字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。  </li><li>byte[] getBytes(String charsetName)  使用指定的字符集将此 String 编码为 byte 序列，并将结果存储到一个新的 byte 数组中。  </li><li>void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)  将字符从此字符串复制到目标字符数组。  </li><li>int hashCode()  返回此字符串的哈希码。  </li><li>int indexOf(int ch)  返回指定字符在此字符串中第一次出现处的索引。  </li><li>int indexOf(int ch, int fromIndex)  返回在此字符串中第一次出现指定字符处的索引，从指定的索引开始搜索。  </li><li>int indexOf(String str)  返回指定子字符串在此字符串中第一次出现处的索引。  </li><li>int indexOf(String str, int fromIndex)  返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始。  </li><li>String intern()  返回字符串对象的规范化表示形式。  </li><li>int lastIndexOf(int ch)  返回指定字符在此字符串中最后一次出现处的索引。  </li><li>int lastIndexOf(int ch, int fromIndex)  返回指定字符在此字符串中最后一次出现处的索引，从指定的索引处开始进行反向搜索。  </li><li>int lastIndexOf(String str)  返回指定子字符串在此字符串中最右边出现处的索引。  </li><li>int lastIndexOf(String str, int fromIndex)  返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索。  </li><li>int length()  返回此字符串的长度。  </li><li>boolean matches(String regex)  告知此字符串是否匹配给定的正则表达式。  </li><li>boolean regionMatches(boolean ignoreCase, int toffset, String other, int ooffset, int len)  测试两个字符串区域是否相等。  </li><li>boolean regionMatches(int toffset, String other, int ooffset, int len)  测试两个字符串区域是否相等。  </li><li>String replace(char oldChar, char newChar)  返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。  </li><li>String replaceAll(String regex, String replacement)  使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。  </li><li>String[] split(String regex)  根据给定正则表达式的匹配拆分此字符串。  </li><li>String[] split(String regex, int limit)  根据匹配给定的正则表达式来拆分此字符串。  </li><li>boolean startsWith(String prefix)  测试此字符串是否以指定的前缀开始。  </li><li>boolean startsWith(String prefix, int toffset)  测试此字符串从指定索引开始的子字符串是否以指定前缀开始。  </li><li>CharSequence subSequence(int beginIndex, int endIndex)  返回一个新的字符序列，它是此序列的一个子序列。  </li><li>String substring(int beginIndex)  返回一个新的字符串，它是此字符串的一个子字符串。  </li><li>String substring(int beginIndex, int endIndex)  返回一个新字符串，它是此字符串的一个子字符串。  </li><li>char[] toCharArray()  将此字符串转换为一个新的字符数组。  </li><li>String toLowerCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为小写。  </li><li>String toLowerCase(Locale locale)  使用给定 Locale 的规则将此 String 中的所有字符都转换为小写。  </li><li>String toString()  返回此对象本身（它已经是一个字符串！）。  </li><li>String toUpperCase()  使用默认语言环境的规则将此 String 中的所有字符都转换为大写。  </li><li>String toUpperCase(Locale locale)  使用给定 Locale 的规则将此 String 中的所有字符都转换为大写。  </li><li>String trim()  返回字符串的副本，忽略前导空白和尾部空白。  </li><li>static String valueOf(primitive data type x)  返回给定data type类型x参数的字符串表示形式。  </li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;创建字符串&lt;br&gt;创建字符串最简单的方式如下:&lt;br&gt;String greeting = “王小二客栈”;&lt;br&gt;注意:String 类是不可改变的，所以你一旦创建了 String 对象，那它的值就无法改变了。&lt;br&gt;如果需要对字符串做很多修改，那么应该选择使用
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>王小二客栈——Java Number&amp;Math</title>
    <link href="http://www.wenchong.top/2018/02/17/java%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94Number&amp;Math/"/>
    <id>http://www.wenchong.top/2018/02/17/java基础——Number&amp;Math/</id>
    <published>2018-02-17T14:20:06.580Z</published>
    <updated>2018-02-17T15:53:47.575Z</updated>
    
    <content type="html"><![CDATA[<h2 id="忆往昔峥嵘岁月，不堪入目"><a href="#忆往昔峥嵘岁月，不堪入目" class="headerlink" title="忆往昔峥嵘岁月，不堪入目"></a>忆往昔峥嵘岁月，不堪入目</h2><ul><li>1.所有的包装类（Integer、Long、Byte、Double、Float、Short）都是抽象类Number的子类。</li><li>2.Java的Math包含了用于执行基本数学运算的属性和方法，如初等指数、对数、平方根和三角函数等。</li><li>Math的方法都被定义为static形式，通过Math类可以在主函数中直接调用。</li></ul><h3 id="下面列出Number-amp-Math类常用的一些方法："><a href="#下面列出Number-amp-Math类常用的一些方法：" class="headerlink" title="下面列出Number &amp; Math类常用的一些方法："></a>下面列出Number &amp; Math类常用的一些方法：</h3><ul><li>xxxValue()    将Number对象装换成xxx数据类型的值并返回。</li><li>compareTo（）    将number对象与参数比较。</li><li>equals()    判断number对象是否与参数相等。</li><li>valueOf()    返回一个Number对象制定的内置数据类型。</li><li>toString()    以字符串形式返回值。</li><li>parseInt()    将字符串解析为int类型。</li><li>abs()        返回参数的绝对值。</li><li>ceil（）    返回大于等于（&gt;=）给定参数的最小整数。</li><li>floor()    返回小雨等于（&lt;=）给定参数的最大整数。</li><li>rint（）    返回与参数最接近的整数，返回类型为double。</li><li>round()    他表示四舍五入。</li><li>min()        返回两个参数之间的最小值。</li><li>max()        返回两个参数之间的最大值。</li><li>exp（）    返回自然数底数e的参数次方。</li><li>log()        返回参数的自然数底数的对数值。</li><li><strong>random（)</strong>    返回一个随机数。</li></ul><h2 id="Java-Character-类"><a href="#Java-Character-类" class="headerlink" title="Java Character 类"></a>Java Character 类</h2><ul><li>Character 类用于对单个字符进行操作。</li><li>Character 类在对象中包装一个基本类型 char 的值。<h3 id="转义序列"><a href="#转义序列" class="headerlink" title="转义序列"></a>转义序列</h3>转义序列    描述<br>\t    在文中该处插入一个tab键<br>\b    在文中该处插入一个后退键<br>\n    在文中该处换行<br>\r    在文中该处插入回车<br>\f    在文中该处插入换页符<br>\’    在文中该处插入单引号<br>\”    在文中该处插入双引号<br>\    在文中该处插入反斜杠</li></ul><h3 id="Character-方法"><a href="#Character-方法" class="headerlink" title="Character 方法"></a>Character 方法</h3><p>isLetter()    是否是一个字母<br>isDigit()    是否是一个数字字符<br>isWhitespace()    是否为一个空格<br>isUpperCase()    是否是大写字母<br>isLowCase()    是否是小写字母<br>toUpperCase()    制定之母的大写形式<br>toLowCase()    制定之母的小写形式<br>toString()    返回字符的字符串形式，字符串的长短仅为1。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;忆往昔峥嵘岁月，不堪入目&quot;&gt;&lt;a href=&quot;#忆往昔峥嵘岁月，不堪入目&quot; class=&quot;headerlink&quot; title=&quot;忆往昔峥嵘岁月，不堪入目&quot;&gt;&lt;/a&gt;忆往昔峥嵘岁月，不堪入目&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;1.所有的包装类（Integer、Long、By
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>java读取Excel表格中的数据</title>
    <link href="http://www.wenchong.top/2018/02/17/java%E8%AF%BB%E5%8F%96Excel%E8%A1%A8%E6%A0%BC%E6%95%B0%E6%8D%AE/"/>
    <id>http://www.wenchong.top/2018/02/17/java读取Excel表格数据/</id>
    <published>2018-02-17T14:20:06.571Z</published>
    <updated>2018-02-17T15:52:15.878Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-需求"><a href="#1-需求" class="headerlink" title="1.需求"></a>1.需求</h3><p>用java代码读取Excel.xls表格中的数据</p><h3 id="2-java代码"><a href="#2-java代码" class="headerlink" title="2.java代码"></a>2.java代码</h3><p>package com.test;<br>import java.io.File;<br>import jxl.*;<br>public class ReadExcel{<br>    public static void main(String[] args){<br>        ing i;<br>        Sheet sheet;<br>        Workbook book;<br>        Cell cell1,cell2,cell3,cell4,cell5,cell6,cell7;<br>        try{</p><pre><code>        //Excel.xls为要读取的excel文件        book = Workbook.getWorkbook(new File(&quot;文件物理地址&quot;)))；        //获取第一个工作表对象（excel中sheet的编号从0开始，0,1,2,3，.....）        sheet = book.getSheet(0);        //获取左上角的单元格        cell1 = sheet.getCell(0,0);(行，列)        System.out.println(&quot;标题：&quot;+cell1.getContents());        i = 1;        while(true){            //获取每一行单元格            cell1 = sheet.getCell(0,i);            cell2 = sheet.getCell(1,i);            cell3 = sheet.getCell(2,i);            cell4 = sheet.getCell(3,i);            cell5 = sheet.getCell(4,i);            cell6 = sheet.getCell(5,i);            cell7 = sheet.getCell(6,i);            if(&quot;&quot;.equals(cell1.getContents()) == true) //如果读取的数据为空            break;            System.out.println(cell1.getContents()+&quot;\t&quot;+cell2.getContents()+&quot;\t&quot;+cell3.getContents()+&quot;\t&quot;+cell4.getContents()+&quot;\t&quot;+cell5.getContents()+&quot;\t&quot;+cell6.getContents()+&quot;\t&quot;);            i++;        }        book.close();    }    catch(Exceprion e){        }}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-需求&quot;&gt;&lt;a href=&quot;#1-需求&quot; class=&quot;headerlink&quot; title=&quot;1.需求&quot;&gt;&lt;/a&gt;1.需求&lt;/h3&gt;&lt;p&gt;用java代码读取Excel.xls表格中的数据&lt;/p&gt;
&lt;h3 id=&quot;2-java代码&quot;&gt;&lt;a href=&quot;#2-jav
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Hbase-写入方式</title>
    <link href="http://www.wenchong.top/2018/02/17/Hbase-5%E7%A7%8D%E5%86%99%E5%85%A5%E6%96%B9%E5%BC%8F/"/>
    <id>http://www.wenchong.top/2018/02/17/Hbase-5种写入方式/</id>
    <published>2018-02-17T14:20:06.563Z</published>
    <updated>2018-02-17T15:51:47.622Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1><h3 id="HBase写入数据方式（参考：《HBase-The-Definitive-Guide》）"><a href="#HBase写入数据方式（参考：《HBase-The-Definitive-Guide》）" class="headerlink" title="HBase写入数据方式（参考：《HBase The Definitive Guide》）"></a>HBase写入数据方式（参考：《HBase The Definitive Guide》）</h3><ul><li>1.直接使用HTable进行导入，代码如下：</li></ul><p>package hbase.curd;<br>import java.io.IOException;<br>import java.util.ArrayList;<br>import java.util.List;<br>impirt java.util.Random;<br>import org.apache.hadoop.hbase.client.HTable;<br>import org.apache.hadoop.hbase.client.Put;<br>import org.apache.hadoop.hbase.util.Bytes;</p><p>public class PutExample{</p><pre><code>private HTable table = HTableUtil.getHTable(&quot;testtable&quot;);public static void main(String args[]) throws IOException{    PutExample pe = new PutExample();    pe.putRows();}    public void putRows(){    List&lt;Put&gt; puts = new ArrayList&lt;Put&gt;;    for(int i=0; i&lt;10; i++){        Put put = new Put(Bytes.toBytes(&quot;row_&quot;+i));        Rowdom random = new Random();        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual3&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual4&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));            }        if(random.nextBoolean()){            put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual5&quot;), Bytes.toBytes(&quot;colfam1_qual1_value_&quot;+i));        }        puts.add(put);    }    try{        table.put(puts);        table.close();    }catch(Exception e){        e.printStackTrace();        return ;    }    System.out.println(&quot;done put rows&quot;);    }}</code></pre><p>}</p><h3 id="其中HTableUtil如下："><a href="#其中HTableUtil如下：" class="headerlink" title="其中HTableUtil如下："></a>其中HTableUtil如下：</h3><p>package hbase.curd;</p><p>import java.io.IOException;</p><p>import org.apache.hadoop.conf.Configuration;<br>import org.apache.hadoop.hbase.HBaseConfiguration;<br>import org.apache.hadoop.hbase.client.HTable;<br>import org.apache.hadoop.hbase.util.Bytes;</p><p>public class HTableUtil {<br>    private static HTable table;<br>    private static Configuration conf;</p><pre><code>static{    conf =HBaseConfiguration.create();    conf.set(&quot;mapred.job.tracker&quot;, &quot;hbase:9001&quot;);    conf.set(&quot;fs.default.name&quot;, &quot;hbase:9000&quot;);    conf.set(&quot;hbase.zookeeper.quorum&quot;, &quot;hbase&quot;);    try {        table = new HTable(conf,&quot;testtable&quot;);    } catch (IOException e) {        // TODO Auto-generated catch block        e.printStackTrace();    }}public static Configuration getConf(){    return conf;}public static HTable getHTable(String tablename){    if(table==null){        try {            table= new HTable(conf,tablename);        } catch (IOException e) {            // TODO Auto-generated catch block            e.printStackTrace();        }     }    return table;}public static  byte[] gB(String name){    return Bytes.toBytes(name);}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;&lt;h3 id=&quot;HBase写入数据方式（参考：《HBase-The-Definit
      
    
    </summary>
    
      <category term="Hbase" scheme="http://www.wenchong.top/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://www.wenchong.top/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>Centos7伪分布式安装Hadoop2.6和Hbase0.94</title>
    <link href="http://www.wenchong.top/2018/02/17/centos7+hadoop2.6+hbase1.0.x/"/>
    <id>http://www.wenchong.top/2018/02/17/centos7+hadoop2.6+hbase1.0.x/</id>
    <published>2018-02-17T14:20:06.548Z</published>
    <updated>2018-02-17T15:50:46.400Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1><h2 id="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。"><a href="#一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。" class="headerlink" title="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。"></a>一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。</h2><ul><li>卸载： yum -y remove java javaxxxxx(系统自带的Java版本)</li></ul><p>安装jdk，将jdk.tar.gz文件复制到/usr/java中,终端进入/mnt/share ,cp jdk.tar.gz /usr/ava，进入/usr/java解压：tar xzvf jdk.targz</p><p>配置环境变量：vi /etc/profile 输入i编辑<br>在尾部添加：export JAVA_HOME=/usr/java/jdkxxxx<br>export PATH=$JAVA_HOME/bin:$PATH<br>export CLASSPATH=.:JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p><p>保存并退出： wq<br>使修改生效： source /etc/profile<br>查看Java版本：java -version</p><h2 id="二、Hadoop伪分布式安装"><a href="#二、Hadoop伪分布式安装" class="headerlink" title="二、Hadoop伪分布式安装"></a>二、Hadoop伪分布式安装</h2><ul><li>1、ssh无密码登陆</li></ul><p>终端：ssh-keygen -t rsa (获得rsa公钥私钥,id_rsa和id_rsa.pub)<br>cd .ssh<br>cp id_rsa.pub authorized_keys (将公钥复制给authorized_keys) &lt;分布式则要将所有节点id_rsa.pub相互复制&gt;</p><ul><li>2、 /mnt/share cp hadoop2.x /usr.hadoop</li></ul><p>解压tar xzvf hadoop 2.x</p><ul><li>3、修改core-site.xml、hadoop-env.sh、hdfs-site.xml、mapred-site.xml 、yarn-site.xml(hadoop2.x版本的配置文件在/hadoop2.x/etc/hadoop下)</li></ul><p>①core-site.xml：</p><pre><code>fs.default.namehdfs://localhost:9000</code></pre><p>② hadoop-env.sh：<br>export JAVA_HOME=/usr/java/jdkxxx (jdk路径)</p><p>③ hdfs-site.xml： 先创建好数据节点和名称节点的存放路径</p><pre><code>dfs.datanode.data.dir/user/hadoop/hadoop-2.5.1/datadfs.namenode.name.dir/user/hadoop/hadoop-2.5.1/namedfs.replication1</code></pre><p>④mapred-site.xml: (注意：这个文件是将/hadoop2.x/etc/hadoop下的mapred-site.xml.template复制并重命名 )</p><pre><code>mapreduce.framework.nameyarn</code></pre><p>⑤yarn-site.xml：</p><pre><code>yarn.nodemanager.aux-servicesmapreduce_shuffle</code></pre><ul><li>4、namenode格式化（一定要完成）</li></ul><p>终端：cd /usr/hadoop/hadoop-2.5.1/bin</p><p>./hdfs namenode -format (输入./hadoop namenode -format也行)</p><ul><li>5、运行hadoop</li></ul><p>终端： cd /usr/hadoop/hadoop-2.5.1/sbin (2.x版本后启动/停止在sbin目录下)<br>./start-hdfs.sh<br>./start-yarn.sh<br>(也可以只输入./start-all.sh)</p><p>输入jps查看启动项，当启动了NameNode、DataNode、SecondaryNameNode、ResourceManager、NodeManager即ok。</p><p>可进入Firefox中，输入端口号： localhost:50070 进入hadoop可视化页面。</p><h2 id="三、Hbase0-94安装"><a href="#三、Hbase0-94安装" class="headerlink" title="三、Hbase0.94安装"></a>三、Hbase0.94安装</h2><ul><li>1、/mnt/share cp hbase1.0.1 /usr.hbase</li></ul><p>解压tar xzvf hbase1.0.1</p><ul><li>2、修改hbase配置文件hbase-env.sh、hbase-site.xml</li></ul><p>hbase-env.sh:</p><p>export JAVA_HOME=/usr/java/jdkxxxx (java路径)<br>export HBASE_MANAGES_ZK=true (都得去掉前面#)</p><p>hbase-site.xml：</p><pre><code>hbase.rootdirhdfs://localhost:9000/hbasehbase.cluster.distributedtruehbase.zookeeper.quorumlocalhosthbase.tmp.dirfile:/usr/hbase/tmphbase.zookeeper.property.dataDirfile:/usr/hbase/zookeeperdata</code></pre><ul><li>3、运行hbase</li></ul><p>运行前需先启动hadoop，再进入hbase的bin目录下输入指令 ./start-hbase.sh<br>输入jps查看启动项，如有HMaster、HRegionServer、HQuormPeer,则说明hbase启动成功。<br>输入./hbase Shell (进入shell指令，可通过shell指令建表)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;&lt;h2 id=&quot;一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>centos 6.5 内核升级</title>
    <link href="http://www.wenchong.top/2018/02/17/centos6.5%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"/>
    <id>http://www.wenchong.top/2018/02/17/centos6.5内核升级/</id>
    <published>2018-02-17T14:20:06.539Z</published>
    <updated>2018-02-17T15:50:27.195Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-查看centos的内核版本"><a href="#1-查看centos的内核版本" class="headerlink" title="1.查看centos的内核版本"></a>1.查看centos的内核版本</h2><p>rname -r</p><h2 id="2-查看系统版本"><a href="#2-查看系统版本" class="headerlink" title="2.查看系统版本"></a>2.查看系统版本</h2><p>cat /etc/centos-release</p><h2 id="3-安装软件"><a href="#3-安装软件" class="headerlink" title="3.安装软件"></a>3.安装软件</h2><p>编译安装新内核，依赖于开发环境和开发库<br>yum grouplist  //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库；</p><p>yum groupinstall “Development Tools”  //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具</p><p>yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行</p><p>yum install qt-devel //如果你没有 X 环境，这一条可以不用</p><p>yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们</p><h2 id="4-编译内核"><a href="#4-编译内核" class="headerlink" title="4.编译内核"></a>4.编译内核</h2><p>Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成： r.x.y</p><ul><li>r: 主版本号</li><li>x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。</li><li>y: 修订版本号 ， 表示修改的次数<br>官网上有stable, longterm等版本，longterm是比stable更稳定的版本。<br><code>[root@sean ~]#curl -O -L  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz[root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/[root@sean ~]# cd /usr/src/linux-3.10.58/[root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config</code></li></ul><p>我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置：<br>`[root@sean linux-3.10.58]# sh -c ‘yes “” | make oldconfig’</p><p>HOSTCC  scripts/basic/fixdep</p><p>HOSTCC  scripts/kconfig/conf.o</p><p>SHIPPED scripts/kconfig/zconf.tab.c</p><p>SHIPPED scripts/kconfig/zconf.lex.c</p><p>SHIPPED scripts/kconfig/zconf.hash.c</p><p>HOSTCC  scripts/kconfig/zconf.tab.o</p><p>HOSTLD  scripts/kconfig/conf</p><p>scripts/kconfig/conf –oldconfig Kconfig</p><p>.config:555:warning: symbol value ‘m’ invalid for PCCARD_NONSTATIC<br>.config:2567:warning: symbol value ‘m’ invalid for MFD_WM8400<br>.config:2568:warning: symbol value ‘m’ invalid for MFD_WM831X<br>.config:2569:warning: symbol value ‘m’ invalid for MFD_WM8350<br>.config:2582:warning: symbol value ‘m’ invalid for MFD_WM8350_I2C<br>.config:2584:warning: symbol value ‘m’ invalid for AB3100_CORE<br>.config:3502:warning: symbol value ‘m’ invalid for MMC_RICOH_MMC</p><p>*</p><ul><li>Restart config…</li></ul><p>*</p><p>*</p><ul><li>General setup</li></ul><p>*</p><p>…<br>…</p><p>XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW)</p><p>Averaging functions (AVERAGE) [Y/?] (NEW)<br>y<br>CORDIC algorithm (CORDIC) [N/m/y/?] (NEW) </p><p>JEDEC DDR data (DDR) [N/y/?] (NEW) </p><p>#</p><p>configuration written to .config`<br>make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写，然后备份.config文件为.config.old，并生成新的.config文件</p><h2 id="5-开始编译"><a href="#5-开始编译" class="headerlink" title="5.开始编译"></a>5.开始编译</h2><p>[root@sean linux-3.10.58]# make -j4 bzImage  //生成内核文件<br>[root@sean linux-3.10.58]# make -j4 modules  //编译模块<br>[root@sean linux-3.10.58]# make -j4 modules_install  //编译安装模块</p><p>-j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟）</p><h2 id="6-安装"><a href="#6-安装" class="headerlink" title="6.安装"></a>6.安装</h2><p>[root@sean linux-3.10.58]# make install<br>实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入<br>HYPERVISOR_GUEST=yCONFIG_VMWARE_BALLOON=m<br>（这一部分比较容易出问题，参考下文异常部分）</p><h2 id="7-修改grub引导，重启"><a href="#7-修改grub引导，重启" class="headerlink" title="7.修改grub引导，重启"></a>7.修改grub引导，重启</h2><p>安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。<br>编辑 grub.conf文件，<br>vi /etc/grub.conf</p><p>#boot=/dev/sda<br>default=0<br>timeout=5<br>splashimage=(hd0,0)/grub/splash.xpm.gz<br>hiddenmenu<br>title CentOS (3.10.58)<br>    root (hd0,0)<br>…</p><p>数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。<br>重启reboot now</p><h2 id="8-确认当内核版本"><a href="#8-确认当内核版本" class="headerlink" title="8.确认当内核版本"></a>8.确认当内核版本</h2><p>[root@sean ~]# uname -r<br>3.10.58</p><p>升级内核成功!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-查看centos的内核版本&quot;&gt;&lt;a href=&quot;#1-查看centos的内核版本&quot; class=&quot;headerlink&quot; title=&quot;1.查看centos的内核版本&quot;&gt;&lt;/a&gt;1.查看centos的内核版本&lt;/h2&gt;&lt;p&gt;rname -r&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
      <category term="运维" scheme="http://www.wenchong.top/categories/operation/"/>
    
    
      <category term="operation" scheme="http://www.wenchong.top/tags/operation/"/>
    
  </entry>
  
  <entry>
    <title>centos6.5下搭建hadoop2.7单机伪分布环境</title>
    <link href="http://www.wenchong.top/2018/02/17/centos6.5+hadoop2.7/"/>
    <id>http://www.wenchong.top/2018/02/17/centos6.5+hadoop2.7/</id>
    <published>2018-02-17T14:20:06.521Z</published>
    <updated>2018-02-17T15:49:35.615Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设置固定IP地址及网关"><a href="#设置固定IP地址及网关" class="headerlink" title="设置固定IP地址及网关"></a>设置固定IP地址及网关</h3><ul><li>设置IP<br>vi /etc/sysconfig/network-scripts/ifcfg-eth0</li><li>修改内容如下<br>DEVICE=eth0<br>HWADDR=08:00:27:BD:9D:B5  #不用改<br>TYPE=Ethernet<br>UUID=53e4e4b6-9724-43ab-9da7-68792e611031 #不用改<br>ONBOOT=yes  #开机启动<br>NM_CONTROLLED=yes<br>BOOTPROTO=static  #静态IP<br>IPADDR=192.168.30.50  #IP地址<br>NETMASK=255.255.255.0 #子网掩码</li><li>设置网关<br>vi /etc/sysconfig/network</li><li>添加内容<br>NETWORKING=yes<br>HOSTNAME=Hadoop.Master<br>GATEWAY=192.168.30.1 #网关</li><li>设置DNS<br>vi /etc/resolv.conf</li><li>添加内容<br>nameserver xxx.xxx.xxx.xxx #根据实际情况设置<br>nameserver 114.114.114.114 #可以设置多个</li><li>重启网卡<br>service network restart</li><li>设置主机名对应IP地址<br>vi /etc/hosts<br>#添加如下内容<br>192.168.30.50 Hadoop.Master<h3 id="添加Hadoop用户"><a href="#添加Hadoop用户" class="headerlink" title="添加Hadoop用户"></a>添加Hadoop用户</h3></li><li>添加用户组<br>groupadd hadoop</li><li>添加用户并分配用户组<br>useradd -g hadoop hadoop</li><li>修改用户密码<br>passwd hadoop<h3 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h3></li><li>关闭防火墙<br>service iptables stop #关闭防火墙服务<br>chkconfig iptables off #关闭防火墙开机启动<br>service ip6tables stop<br>chkconfig ip6tables off</li><li>关闭SELinux<br>vi /etc/sysconfig/selinux<br>#修改如下内容<br>SELINUX=enforcing -&gt; SELINUX=disabled<br>#再执行如下命令<br>setenforce 0<br>getenforce</li><li>关闭其他服务<h3 id="VSFTP安装与配置"><a href="#VSFTP安装与配置" class="headerlink" title="VSFTP安装与配置"></a>VSFTP安装与配置</h3></li><li>检查是否安装<br>chkconfig –list|grep vsftpd</li><li>安装vsftp<br>yum -y install vsftpd</li><li>创建日志文件<br>touch /var/log/vdftpd.log</li><li>配置vsftpd服务<br>vi /etc/vsftpd/vsftpd.conf<br>#修改如下内容<br>anonymous_enable=NO #关闭匿名访问<br>xferlog_file=/var/log/vsftpd.log #设置日志文件 – 我们上一步所创建的文件<br>idle_session_timeout=600 #会话超时时间<br>async_abor_enable=YES  #开启异步传输<br>ascii_upload_enable=YES #开启ASCII上传<br>ascii_download_enable=YES #开启ASCII下载</li><li>查看vsftp运行状态<br>service vsftpd status<h3 id="启动vsftp"><a href="#启动vsftp" class="headerlink" title="启动vsftp"></a>启动vsftp</h3>service vsftpd start<br>#重启 service vsftpd restart<br>#关闭 service vsftpd stop</li><li>查看vsftpd服务启动项<br>chkconfig –list|grep vsftpd</li><li>设置vsftp开机启动<br>chkconfig vsftpd on<h3 id="SSH无密码配置"><a href="#SSH无密码配置" class="headerlink" title="SSH无密码配置"></a>SSH无密码配置</h3></li><li>查看ssh与rsync安装状态<br>rpm -qa|grep openssh<br>rpm -qa|grep rsync</li><li>安装ssh与rsync<br>yum -y install ssh<br>yum -y install rsync</li><li>切换hadoop用户<br>su - hadoop</li><li>生成ssh密码对<br>ssh-keygen -t rsa -P ‘’ -f ~/.ssh/id_rsa</li><li>将id_dsa.pub追加到授权的key中<br>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys<h3 id="设置授权key权限"><a href="#设置授权key权限" class="headerlink" title="设置授权key权限"></a>设置授权key权限</h3>chmod 600 ~/.ssh/authorized_keys<br>#权限的设置非常重要，因为不安全的设置安全设置，会让你不能使用RSA功能<h3 id="测试ssh连接"><a href="#测试ssh连接" class="headerlink" title="测试ssh连接"></a>测试ssh连接</h3>ssh localhost<br>#如果不需要输入密码，则是成功<h2 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h2></li><li>下载地址<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html</a></li></ul><p>注：我这里使用的是：jdk-7u80-linux-i586.tar.gz</p><ul><li>安装Java<br>切换至root用户<br>su root</li><li>创建/usr/java文件夹<br>mkdir /usr/java</li><li><p>使用winscp工具上传至服务器</p></li><li><p>将压缩包上传至/home/hadoop目录</p></li></ul><p>注：我这里使用的是winscp，使用hadoop用户连接</p><ul><li>将压缩包解压至/usr/java 目录<br>tar zxvf /home/hadoop/jdk-7u80-linux-i586.tar.gz -C /usr/java/</li><li>设置环境变量<br>vi /etc/profile<br>#追加如下内容<br>export JAVA_HOME=/usr/java/jdk1.7.0_80<br>export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib<br>export PATH=$PATH:$JAVA_HOME/bin</li><li>使环境变量生效<br>source /etc/profile</li><li>测试环境变量设置<br>java -version<h2 id="Hadoop安装与配置"><a href="#Hadoop安装与配置" class="headerlink" title="Hadoop安装与配置"></a>Hadoop安装与配置</h2>下载地址<br><a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a></li></ul><p>注:我下载的是hadoop-2.7.1.tar.gz</p><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>使用winscp工具上传至服务器<br>将压缩包上传至/home/hadoop目录<br>*将压缩包解压至/usr目录<br>tar zxvf /home/hadoop/hadoop-2.7.1.tar.gz -C /usr/</p><ul><li>修改文件夹名称<br>mv /usr/hadoop-2.7.1/ /usr/hadoop</li><li>创建hadoop数据目录<br>mkdir /usr/hadoop/tmp</li><li>将hadoop文件夹授权给hadoop用户<br>chown -R hadoop:hadoop /usr/hadoop/</li><li>设置环境变量<br>vi /etc/profile<br>#追加如下内容<br>export HADOOP_HOME=/usr/hadoop<br>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin<br>export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native<br>export HADOOP_OPTS=”-Djava.library.path=$HADOOP_HOME/lib</li><li>使环境变量生效<br>source /etc/profile</li><li>测试环境变量设置<br>hadoop version<h3 id="配置HDFS"><a href="#配置HDFS" class="headerlink" title="配置HDFS"></a>配置HDFS</h3></li><li>切换至Hadoop用户<br>su - hadoop</li><li>修改hadoop-env.sh<br>cd /usr/hadoop/etc/hadoop/<br>vi hadoop-env.sh<br>#追加如下内容<br>export JAVA_HOME=/usr/java/jdk1.7.0_80</li><li>修改core-site.xml<br>vi core-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>fs.defaultFS</name><br>      <value>hdfs://Hadoop.Master:9000</value><br>  </property><br>  <property><br>      <name>hadoop.tmp.dir</name><br>      <value>/usr/hadoop/tmp/</value><br>      <description>A base for other temporary directories.</description><br>  </property><br></configuration></li><li>修改hdfs-site.xml<br>vi hdfs-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>dfs.replication</name><br>      <value>1</value><br>  </property><br></configuration></li><li>格式化hdfs<br>hdfs namenode -format<br>注：出现Exiting with status 0即为成功</li><li>启动hdfs<br>start-dfs.sh<br>#停止命令 stop-dfs.sh<br>注：输出如下内容<br>15/09/21 18:09:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>Starting namenodes on [Hadoop.Master]<br>Hadoop.Master: starting namenode, logging to /usr/hadoop/logs/hadoop-hadoop-namenode-Hadoop.Master.out<br>Hadoop.Master: starting datanode, logging to /usr/hadoop/logs/hadoop-hadoop-datanode-Hadoop.Master.out<br>Starting secondary namenodes [0.0.0.0]<br>The authenticity of host ‘0.0.0.0 (0.0.0.0)’ can’t be established.<br>RSA key fingerprint is b5:96:b2:68:e6:63:1a:3c:7d:08:67:4b:ae:80:e2:e3.<br>Are you sure you want to continue connecting (yes/no)? yes<br>0.0.0.0: Warning: Permanently added ‘0.0.0.0’ (RSA) to the list of known hosts.<br>0.0.0.0: starting secondarynamenode, logging to /usr/hadoop/logs/hadoop-hadoop-secondarynamenode-Hadoop.Master.out<br>15/09/21 18:09:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicab</li><li>查看进程<br>jps<br>注：输出类似如下内容<br>1763 NameNode<br>1881 DataNode<br>2146 Jps<br>2040 SecondaryNameNode</li><li>使用web查看Hadoop运行状态<br><a href="http://你的服务器ip地址:50070/" target="_blank" rel="noopener">http://你的服务器ip地址:50070/</a><h3 id="在HDFS上运行WordCount"><a href="#在HDFS上运行WordCount" class="headerlink" title="在HDFS上运行WordCount"></a>在HDFS上运行WordCount</h3></li><li>创建HDFS用户目录<br>hdfs dfs -mkdir /user<br>hdfs dfs -mkdir /user/hadoop #根据自己的情况调整/user/<username></username></li><li>复制输入文件（要处理的文件）到HDFS上<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>查看我们复制到HDFS上的文件<br>hdfs dfs -ls input</li><li>运行单词检索（grep）程序<br>hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output ‘dfs[a-z.]+’<br>#WordCount<br>#hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount input output<br>#说明：output文件夹如已经存在则需要删除或指定其他文件夹。</li><li>查看运行结果<br>hdfs dfs -cat output/*<h3 id="配置YARN"><a href="#配置YARN" class="headerlink" title="配置YARN"></a>配置YARN</h3></li><li>修改mapred-site.xml<br>cd /usr/hadoop/etc/hadoop/<br>cp mapred-site.xml.template mapred-site.xml<br>vi mapred-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>mapreduce.framework.name</name><br>      <value>yarn</value><br>  </property><br></configuration></li><li>修改yarn-site.xml<br>vi yarn-site.xml<br>#添加如下内容<configuration><br>  <property><br>      <name>yarn.nodemanager.aux-services</name><br>      <value>mapreduce_shuffle</value><br>  </property><br></configuration></li><li>启动YARN<br>start-yarn.sh<br>#停止yarn stop-yarn.sh</li><li>查看当前java进程<br>jsp<br>#输出如下<br>4918 ResourceManager<br>1663 NameNode<br>1950 SecondaryNameNode<br>5010 NodeManager<br>5218 Jps<br>1759 DataNode</li><li><p>运行你的mapReduce程序</p></li><li><p>配置好如上配置再运行mapReduce程序时即是yarn中运行。</p></li><li><p>使用web查看Yarn运行状态<br><a href="http://你的服务器ip地址:8088/" target="_blank" rel="noopener">http://你的服务器ip地址:8088/</a></p><h3 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h3></li><li>创建HDFS文件夹</li><li>在根目录创建input文件夹<br>hdfs dfs -mkdir -p /input</li><li>在用户目录创建input文件夹<br>说明：如果不指定“/目录”，则默认在用户目录创建文件夹<br>hdfs dfs -mkdir -p input<br>#等同于 hdfs dfs -mkdir -p /user/hadoop/input</li><li>查看HDFS文件夹</li><li>查看HDFS根文件夹<br>hdfs  dfs  -ls /</li><li>查看HDFS用户目录文件夹<br>hdfs  dfs  -ls</li><li>查看HDFS用户目录文件夹下input文件夹<br>hdfs  dfs  -ls input<br>#等同与 hdfs  dfs  -ls /user/hadoop/input</li><li>复制文件到HDFS<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>删除文件夹<br>hdfs  dfs  -rm -r input</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设置固定IP地址及网关&quot;&gt;&lt;a href=&quot;#设置固定IP地址及网关&quot; class=&quot;headerlink&quot; title=&quot;设置固定IP地址及网关&quot;&gt;&lt;/a&gt;设置固定IP地址及网关&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;设置IP&lt;br&gt;vi /etc/sysconfig/ne
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>docker安装</title>
    <link href="http://www.wenchong.top/2018/02/05/docker%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/02/05/docker安装/</id>
    <published>2018-02-05T13:09:56.999Z</published>
    <updated>2018-02-05T13:18:27.788Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1：关闭selinux"><a href="#1：关闭selinux" class="headerlink" title="1：关闭selinux"></a>1：关闭selinux</h2><p>临时关闭：setenforce 0<br>永久关闭：</p><h2 id="1-vi-etc-sysconfig-selinux"><a href="#1-vi-etc-sysconfig-selinux" class="headerlink" title="1. vi /etc/sysconfig/selinux"></a>1. vi /etc/sysconfig/selinux</h2><p>插入/编辑以下内容<br>SELINUX=disabled</p><p>#重启生效</p><h2 id="2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel："><a href="#2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel：" class="headerlink" title="2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel："></a>2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel：</h2><p>rpm -ivh <a href="http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="noopener">http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm</a><br>sed -i ‘s/^mirrorlist=https/mirrorlist=http/‘ /etc/yum.repos.d/epel.repo<br>（elpe.repo）<br>[epel]<br>name=epel<br>mirrorlist=<a href="http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch" target="_blank" rel="noopener">http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch</a><br>enabled=1<br>gpgcheck=0</p><h2 id="3：安装docker"><a href="#3：安装docker" class="headerlink" title="3：安装docker"></a>3：安装docker</h2><p>yum install docker-io<br>安装完成后</p><h2 id="4：启动docker"><a href="#4：启动docker" class="headerlink" title="4：启动docker"></a>4：启动docker</h2><p>service  docker  start</p><h2 id="5：查看docker版本"><a href="#5：查看docker版本" class="headerlink" title="5：查看docker版本"></a>5：查看docker版本</h2><p>docker vesion</p><h2 id="6：查看docker日志"><a href="#6：查看docker日志" class="headerlink" title="6：查看docker日志"></a>6：查看docker日志</h2><p>cat /var/log/docker</p><p>docker安装完成</p><h1 id="一：卸载docker"><a href="#一：卸载docker" class="headerlink" title="一：卸载docker"></a>一：卸载docker</h1><p>列出你安装过的包<br>[root@localhost ~]# yum list installed | grep docker<br>docker-io.x86_64                     1.7.1-2.el6                        @epel<br>删除软件包<br>yum -y remove docker-io.x86_64<br>删除镜像/容器等<br>rm -rf /var/lib/docker</p><h1 id="二：升级docker版本为1-10-3"><a href="#二：升级docker版本为1-10-3" class="headerlink" title="二：升级docker版本为1.10.3"></a>二：升级docker版本为1.10.3</h1><p>升级之前停止docker服务,并将原有的docker服务进行备份. mv /usr/bin/docker /usr/bin/docker.bak</p><p>nohup wget -c <a href="https://get.docker.com/builds/Linux/x86_64/docker-1.10.3" target="_blank" rel="noopener">https://get.docker.com/builds/Linux/x86_64/docker-1.10.3</a> -O /usr/bin/docker<br>给执行权限：chmod 755 /usr/bin/docker 然后重启服务，并查看版本.</p><h2 id="报错："><a href="#报错：" class="headerlink" title="报错："></a>报错：</h2><p>Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory<br>/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed<br>Failed to parse /etc/cgconfig.conf                         [FAILED]<br>Starting docker:                                       [  OK  ]</p><h2 id="修改：-etc-cgconfig-conf文件"><a href="#修改：-etc-cgconfig-conf文件" class="headerlink" title="修改：/etc/cgconfig.conf文件"></a>修改：/etc/cgconfig.conf文件</h2><p>mount {<br>    cpuset  = /cgroup/cpuset;<br>    cpu = /cgroup/cpu;<br>    cpuacct = /cgroup/cpuacct;</p><h1 id="memory-cgroup-memory"><a href="#memory-cgroup-memory" class="headerlink" title="memory  = /cgroup/memory;"></a>memory  = /cgroup/memory;</h1><pre><code>devices = /cgroup/devices;freezer = /cgroup/freezer;net_cls = /cgroup/net_cls;blkio   = /cgroup/blkio;</code></pre><p>}<br>重新启动docker 正常</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1：关闭selinux&quot;&gt;&lt;a href=&quot;#1：关闭selinux&quot; class=&quot;headerlink&quot; title=&quot;1：关闭selinux&quot;&gt;&lt;/a&gt;1：关闭selinux&lt;/h2&gt;&lt;p&gt;临时关闭：setenforce 0&lt;br&gt;永久关闭：&lt;/p&gt;
&lt;h2
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>错误及解决方案</title>
    <link href="http://www.wenchong.top/2018/02/05/ambari%E6%90%AD%E5%BB%BA%E9%94%99%E8%AF%AF/"/>
    <id>http://www.wenchong.top/2018/02/05/ambari搭建错误/</id>
    <published>2018-02-05T13:06:14.277Z</published>
    <updated>2018-02-17T15:48:58.074Z</updated>
    
    <content type="html"><![CDATA[<p>ERROR: Exiting with exit code 1.<br>REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and /var/log/ambari-server/ambari-server-check-database.log for more information.<br>解决方法：查看日志，具体什么错.例如：数据库未开启、数据库配置问题</p><p>撤销已经赋予给 MySQL 用户权限的权限。<br>revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：<br>revoke  all on <em>.</em> from ‘root’@’192.168.0.197’;</p><p>[root@datanode01 ~]# yum makecache<br>Loaded plugins: fastestmirror<br>Determining fastest mirrors<br>ambari-2.4.1.0                                                   | 2.9 kB     00:00<br>ambari-2.4.1.0/filelists_db                                      | 139 kB     00:00<br>ambari-2.4.1.0/primary_db                                        | 8.3 kB     00:00<br>ambari-2.4.1.0/other_db                                          | 1.3 kB     00:00<br>file:///mnt/repodata/repomd.xml: [Errno 14] Could not open/read file:///mnt/repodata/repomd.xml<br>Trying other mirror.<br>Error: Cannot retrieve repository metadata (repomd.xml) for repository: c6-media. Please verify its path and try again</p><p>如果有后面两个文件，处理方式mv CentOS-Media.repo CentOS-Media.repo.bak<br>没有的话，源问题，换源repos</p><h3 id="tip"><a href="#tip" class="headerlink" title="tip:"></a>tip:</h3><p>1、当提示要做如下操作的时候<br>Be?sure?you?have?run:ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/path/to/mysql/<em>**</em><br>需要下载mysql-connector-java-5.1.39.tar驱动，解压得到mysql-connector-java-5.1.39-bin.jar文件<br>执行如下命令：ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/usr/lib/java/mysql-connector-java-5.1.39/mysql-connector-java-5.1.39-<br>bin.jar<br>同时，设置文件权限为644</p><h3 id="2017-7-19"><a href="#2017-7-19" class="headerlink" title="2017.7.19"></a>2017.7.19</h3><p>1.ERROR namenode.NameNode (NameNode.java:main(1759)) - Failed to start namenode.<br>java.net.BindException: Port in use: datanode01:50070<br>  不能获取映射地址，需要修改hosts中的映射ip为真实ip（ifconfig）<br>2.错删自定义的service导致不能登录amnari UI（日志报出database问题） （百度方案无解，最后重装ambari-server(发现重装无法下手，百度后删除ambari相关组件以及数据库的完全卸载，完成)）<br>3.使用ambari-server启动HDFS时，DataNode无法启动（出现port in use：localhost 0）。解决方式，在hosts文件中localhost 172.0.0.1被#；去除#后解决</p><h3 id="一般故障排除"><a href="#一般故障排除" class="headerlink" title="一般故障排除"></a>一般故障排除</h3><p>Ambari服务器：检查/var/log/ambari-server/ambari-server.[log|out]是否存在错误。<br>Ambari代理：检查/var/log/ambari-agent/ambari-agent.[log|out]是否存在错误。<br>请注意，如果Ambari Agent在/var/log/ambari-agent/ambari-agent.out中有任何输出，则表明存在重大问题。</p><h3 id="服务无法启动"><a href="#服务无法启动" class="headerlink" title="服务无法启动"></a>服务无法启动</h3><p>HDFS：检查/ var / log / hadoop / hdfs下的日志文件<br>MapReduce：检查/ var / log / hadoop / mapred下的日志文件<br>HBase：检查/ var / log / hbase下的日志文件<br>Hive：检查/ var / log / hive下的日志文件<br>Oozie：检查/ var / log / oozie下的日志文件<br>ZooKeeper：检查/ var / log / zookeeper下的日志文件<br>WebHCat：检查/ var / log / webhcat下的日志文件<br>Nagios：检查/ var / log / nagios下的日志文件</p><h3 id="2017-7-20"><a href="#2017-7-20" class="headerlink" title="2017.7.20"></a>2017.7.20</h3><p>Service ‘userhome’ check failed: java.io.FileNotFoundException: File does not exist: /user/admin<br>解决方案：sudo -u hdfs hdfs dfs  -mkdir /user/admin<br>sudo -u hdfs hdfs dfs  -chown admin:hadoop /user/admin</p><h3 id="资源池问题"><a href="#资源池问题" class="headerlink" title="资源池问题"></a>资源池问题</h3><p>FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed forblock pool Block pool BP-1480406410-192.168.1.181-1398701121586 (storage idDS-167510828-192.168.1.191-50010-1398750515421)<br>原因：每次namenode format会重新创建一个namenodeId,而data目录包含了上次format时的id,namenode format清空了namenode下的数据,但是没有清空datanode下的数据,导致启动时失败,所要做的就是每次fotmat前,清空data下的所有目录.<br>: d6 E2 t&amp; M” g7 a* q3 l, H<br>解决办法：停掉集群，删除问题节点的data目录下的所有内容。即hdfs-site.xml文件中配置的dfs.data.dir目录。重新格式化namenode。</p><p>另一个更省事的办法：先停掉集群，然后将datanode节点目录/dfs/data/current/VERSION中的修改为与namenode一致即可。<br>其实我没解决，直接重装</p><h3 id="block-missing问题"><a href="#block-missing问题" class="headerlink" title="block missing问题"></a>block missing问题</h3><p>会导致进入安全模式：处理方式，删除缺失包，在HDFS用户下退出安全模式</p><p>添加节点时，需要查看该节点root磁盘下的剩余大小，如果磁盘空间不足，则扩大磁盘再添加节点。<br>不要问我为什么，说多了都是泪。集群就是这么崩盘的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;ERROR: Exiting with exit code 1.&lt;br&gt;REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and 
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>amabri卸载</title>
    <link href="http://www.wenchong.top/2018/02/05/ambari%E5%8D%B8%E8%BD%BD/"/>
    <id>http://www.wenchong.top/2018/02/05/ambari卸载/</id>
    <published>2018-02-05T12:53:44.167Z</published>
    <updated>2018-02-17T15:49:18.965Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-删除hdp-repo和hdp-util-repo"><a href="#1-删除hdp-repo和hdp-util-repo" class="headerlink" title="1.删除hdp.repo和hdp-util.repo"></a>1.删除hdp.repo和hdp-util.repo</h2><p>cd /etc/yum.repos.d/<br>rm -rf hdp<em><br>rm -rf HDP</em><br>rm -rf ambari*</p><h2 id="2-删除安装包"><a href="#2-删除安装包" class="headerlink" title="2.删除安装包"></a>2.删除安装包</h2><p>用yum list installed | grep HDP来检查安装的ambari的包<br>yum remove -y  sqoop.noarch<br>yum remove -y  lzo-devel.x86_64<br>yum remove -y  hadoop-libhdfs.x86_64<br>yum remove -y  rrdtool.x86_64<br>yum remove -y  hbase.noarch<br>yum remove -y  pig.noarch<br>yum remove -y  lzo.x86_64<br>yum remove -y  ambari-log4j.noarch<br>yum remove -y  oozie.noarch<br>yum remove -y  oozie-client.noarch<br>yum remove -y  gweb.noarch<br>yum remove -y  snappy-devel.x86_64<br>yum remove -y  hcatalog.noarch<br>yum remove -y  python-rrdtool.x86_64<br>yum remove -y  nagios.x86_64<br>yum remove -y  webhcat-tar-pig.noarch<br>yum remove -y  snappy.x86_64<br>yum remove -y  libconfuse.x86_64<br>yum remove -y  webhcat-tar-hive.noarch<br>yum remove -y  ganglia-gmetad.x86_64<br>yum remove -y  extjs.noarch<br>yum remove -y  hive.noarch<br>yum remove -y  hadoop-lzo.x86_64<br>yum remove -y  hadoop-lzo-native.x86_64<br>yum remove -y  hadoop-native.x86_64<br>yum remove -y  hadoop-pipes.x86_64<br>yum remove -y  nagios-plugins.x86_64<br>yum remove -y  hadoop.x86_64<br>yum remove -y  zookeeper.noarch<br>yum remove -y  hadoop-sbin.x86_64<br>yum remove -y  ganglia-gmond.x86_64<br>yum remove -y  libganglia.x86_64<br>yum remove -y  perl-rrdtool.x86_64<br>yum remove -y  epel-release.noarch<br>yum remove -y  compat-readline5*<br>yum remove -y  fping.x86_64<br>yum remove -y  perl-Crypt-DES.x86_64<br>yum remove -y  exim.x86_64<br>yum remove -y ganglia-web.noarch<br>yum remove -y perl-Digest-HMAC.noarch<br>yum remove -y perl-Digest-SHA1.x86_64<br>yum remove -y bigtop-jsvc.x86_64</p><h2 id="3-删除快捷方式"><a href="#3-删除快捷方式" class="headerlink" title="3.删除快捷方式"></a>3.删除快捷方式</h2><p>cd /etc/alternatives<br>rm -rf hadoop-etc<br>rm -rf zookeeper-conf<br>rm -rf hbase-conf<br>rm -rf hadoop-log<br>rm -rf hadoop-lib<br>rm -rf hadoop-default<br>rm -rf oozie-conf<br>rm -rf hcatalog-conf<br>rm -rf hive-conf<br>rm -rf hadoop-man<br>rm -rf sqoop-conf<br>rm -rf hadoop-conf</p><h2 id="4-删除用户"><a href="#4-删除用户" class="headerlink" title="4.删除用户"></a>4.删除用户</h2><p>userdel nagios<br>userdel hive<br>userdel ambari-qa<br>userdel hbase<br>userdel oozie<br>userdel hcat<br>userdel mapred<br>userdel hdfs<br>userdel rrdcached<br>userdel zookeeper </p><p>#userdel mysql<br>userdel sqoop<br>userdel puppet<br>userdel yarn<br>userdel tez<br>userdel hadoop<br>userdel knox<br>userdel storm<br>userdel falcon<br>userdel flume<br>userdel nagios<br>userdel admin<br>userdel postgres<br>userdel  hdfs<br>userdel  zookeeper<br>userdel hbase</p><h2 id="5-删除文件夹"><a href="#5-删除文件夹" class="headerlink" title="5.删除文件夹"></a>5.删除文件夹</h2><p>rm -rf /hadoop<br>rm -rf /etc/hadoop<br>rm -rf /etc/hbase<br>rm -rf /etc/hcatalog<br>rm -rf /etc/hive<br>rm -rf /etc/ganglia<br>rm -rf /etc/nagios<br>rm -rf /etc/oozie<br>rm -rf /etc/sqoop<br>rm -rf /etc/zookeeper<br>rm -rf /var/run/hadoop<br>rm -rf /var/run/hbase<br>rm -rf /var/run/hive<br>rm -rf /var/run/ganglia<br>rm -rf /var/run/nagios<br>rm -rf /var/run/oozie<br>rm -rf /var/run/zookeeper<br>rm -rf /var/log/hadoop<br>rm -rf /var/log/hbase<br>rm -rf /var/log/hive<br>rm -rf /var/log/nagios<br>rm -rf /var/log/oozie<br>rm -rf /var/log/zookeeper<br>rm -rf /usr/lib/hadoop<br>rm -rf /usr/lib/hbase<br>rm -rf /usr/lib/hcatalog<br>rm -rf /usr/lib/hive<br>rm -rf /usr/lib/oozie<br>rm -rf /usr/lib/sqoop<br>rm -rf /usr/lib/zookeeper<br>rm -rf /var/lib/hive<br>rm -rf /var/lib/ganglia<br>rm -rf /var/lib/oozie<br>rm -rf /var/lib/zookeeper<br>rm -rf /var/tmp/oozie<br>rm -rf /tmp/hive<br>rm -rf /tmp/nagios<br>rm -rf /tmp/ambari-qa<br>rm -rf /tmp/sqoop-ambari-qa<br>rm -rf /var/nagios<br>rm -rf /hadoop/oozie<br>rm -rf /hadoop/zookeeper<br>rm -rf /hadoop/mapred<br>rm -rf /hadoop/hdfs<br>rm -rf /tmp/hadoop-hive<br>rm -rf /tmp/hadoop-nagios<br>rm -rf /tmp/hadoop-hcat<br>rm -rf /tmp/hadoop-ambari-qa<br>rm -rf /tmp/hsperfdata_hbase<br>rm -rf /tmp/hsperfdata_hive<br>rm -rf /tmp/hsperfdata_nagios<br>rm -rf /tmp/hsperfdata_oozie<br>rm -rf /tmp/hsperfdata_zookeeper<br>rm -rf /tmp/hsperfdata_mapred<br>rm -rf /tmp/hsperfdata_hdfs<br>rm -rf /tmp/hsperfdata_hcat<br>rm -rf /tmp/hsperfdata_ambari-qa<br>rm -rf /etc/flume<br>rm -rf /etc/storm<br>rm -rf /etc/hive-hcatalog<br>rm -rf /etc/tez<br>rm -rf /etc/falcon<br>rm -rf /var/run/flume<br>rm -rf /var/run/storm<br>rm -rf /var/run/webhcat<br>rm -rf /var/run/hadoop-yarn<br>rm -rf /var/run/hadoop-mapreduce<br>rm -rf /var/log/flume<br>rm -rf /var/log/storm<br>rm -rf /var/log/hadoop-yarn<br>rm -rf /var/log/hadoop-mapreduce<br>rm -rf /usr/lib/nagios<br>rm -rf /var/lib/hdfs<br>rm -rf /var/lib/hadoop-hdfs<br>rm -rf /var/lib/hadoop-yarn<br>rm -rf /var/lib/hadoop-mapreduce<br>rm -rf /tmp/hadoop-hdfs</p><h2 id="5-重置数据库，删除ambari包"><a href="#5-重置数据库，删除ambari包" class="headerlink" title="5.重置数据库，删除ambari包"></a>5.重置数据库，删除ambari包</h2><p>#采用这句命令来检查yum list installed | grep ambari<br>ambari-server stop<br>ambari-agent stop<br>ambari-server reset<br>yum remove -y ambari-<em><br>yum remove -y postgresql<br>rm -rf /etc/yum.repos.d/ambari</em><br>rm -rf /var/lib/ambari<em><br>rm -rf /var/log/ambari</em><br>rm -rf /etc/ambari*</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-删除hdp-repo和hdp-util-repo&quot;&gt;&lt;a href=&quot;#1-删除hdp-repo和hdp-util-repo&quot; class=&quot;headerlink&quot; title=&quot;1.删除hdp.repo和hdp-util.repo&quot;&gt;&lt;/a&gt;1.删除hdp.
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>Ambari搭建</title>
    <link href="http://www.wenchong.top/2016/11/09/ambari%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.wenchong.top/2016/11/09/ambari搭建/</id>
    <published>2016-11-08T16:00:00.000Z</published>
    <updated>2018-02-17T15:45:31.942Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-物理条件：三台centos"><a href="#1-物理条件：三台centos" class="headerlink" title="1.物理条件：三台centos"></a>1.物理条件：三台centos</h2><p>前期条件：修改每台centos的名称，分别为namenode、datanode01、datanode02<br>          ssh免密码配置：namenode 可以免密码登录到datanode01、datanode02<br>配置ssh<br>      在namenode上生成密钥对：ssh-keygen  –t  rsa<br>      在/root/.ssh中会有生成的密钥对<br>      将namenode  的 id_rsa.pub写入datanode01的/root/.ssh  authorized_keys文件中。再将datanode01的authorized_keys 写入namenode /root/.ssh<br>datanode02同理操作<br>scp .ssh/id_rsa.pub chenlb@192.168.1.181:/home/chenlb/id_rsa.pub<br>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys<br>  将namenode中的三个机器的私钥 id_rsa提取到桌面，后续使用<br>安装ntp服务<br>yum install ntp<br>service ntpd start<br>chkconfig ntpd on</p><h2 id="2-更换源："><a href="#2-更换源：" class="headerlink" title="2.更换源："></a>2.更换源：</h2><p>将/etc/yum.repos.d/下的原centos.repos备份，然后添加本地源（我这是之前师傅在其他服务器布            置好了的源，你们可在网上查找相关源）</p><h2 id="3-验证本机名"><a href="#3-验证本机名" class="headerlink" title="3.验证本机名"></a>3.验证本机名</h2><pre><code>Hostname   -f</code></pre><p>  显示<br>      namenode   其他两台一样</p><h2 id="4-关闭防火墙"><a href="#4-关闭防火墙" class="headerlink" title="4.关闭防火墙"></a>4.关闭防火墙</h2><pre><code>Service iptables stop</code></pre><p>禁用自启动<br>      Chkconfig   iptables  off</p><h2 id="5-禁用ipv6"><a href="#5-禁用ipv6" class="headerlink" title="5.禁用ipv6"></a>5.禁用ipv6</h2><pre><code>使用lsmod查看系统启动的模块：ipv6相关的模块是net-pf-10  ipv6在vi  /etc/modprobe.d/dist.conf    中最后添加</code></pre><p> alias   net-pf-10   off<br>                                    alias  ipv6   off<br>      重启后，再使用lsmod查看ipv6的相应模块还在不在</p><h2 id="6-禁用SELinux"><a href="#6-禁用SELinux" class="headerlink" title="6.禁用SELinux"></a>6.禁用SELinux</h2><p>配置selinux<br>vi  /etc/sysconfig/selinux<br>插入<br>SELINUX=disabled<br>暂时禁用      setenforce  0</p><h2 id="7-配置禁用THP-每次重启机器后需要从新配置"><a href="#7-配置禁用THP-每次重启机器后需要从新配置" class="headerlink" title="7.配置禁用THP(每次重启机器后需要从新配置)"></a>7.配置禁用THP(每次重启机器后需要从新配置)</h2><p>  查看当前THP状态<br>  cat   /sys/kernel/mm/transparent_hugepage/enabled<br>  如果为always  madvise   [never]则为禁用<br>配置禁用<br>echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/defrag<br>echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/enabled<br>echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/defrag<br>echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/enabled</p><h2 id="8-clean源-重新加载"><a href="#8-clean源-重新加载" class="headerlink" title="8.clean源 重新加载"></a>8.clean源 重新加载</h2><pre><code>yum clean allyum makecache</code></pre><h2 id="9-配置mysql作为数据库（只在ambari-server安装机器上做）"><a href="#9-配置mysql作为数据库（只在ambari-server安装机器上做）" class="headerlink" title="9.配置mysql作为数据库（只在ambari-server安装机器上做）"></a>9.配置mysql作为数据库（只在ambari-server安装机器上做）</h2><p>   查看当前安装数据库信息   rpm  -qa  |   grep   -i   mysql<br>    卸载方法 yum   -y   remove  +name<br>    安装MySQL  查看当前源中是否有提供的MySQL<br>    yum   list  |   grep   mysql<br>    安装mysql-server<br>安装<br>    安装后mysql 只有一个用户root 且第一次开启时需要设置密码，我们这通过命令提前设置                   mysqladmin  -u  root  password  ‘’</p><pre><code>设置为自启动  chkconfig  mysqld  on登录到root用户mysql   -u  root   -p create  user  ‘amabri’@’% ’    identified   by   ‘bigdata’;grant   all   privileges   on   *.*    to    ‘ambari’@’%’;create   user   ‘ambari’@’localhost’   identified   by    ‘bigdata’;grant    all    privileges   on   *.*   to    ‘ambari’@’localhost’;create   user   ‘ambari’@’namenode’   identified   by   ‘bigdata’;grant   all   privileges   on   *.*   to   ‘ambari’@’namenode’;登录ambari用户mysql    -u   ambari    -pbigdatacreate  database   ambari;use  ambari;</code></pre><h2 id="10-部署"><a href="#10-部署" class="headerlink" title="10.部署"></a>10.部署</h2><p> （1） yum安装<br> yum  -y  install  ambari-server (每台都要装)<br>后进入mysql -u ambari -p<br>bigdata<br>use ambari;<br>source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql;<br> （2） jdk的安装<br>       下载jdk1.8.0_45安装包  放入/usr/lib/jvm/jdk1.8.0_45/ 解压<br>       配置环境变量  /etc/profile 文件最后加上</p><p>#Java environment<br>       JAVA_HOME=/usr/java/jdk1.8.0_45<br>PATH=$JAVA_HOME/bin:$PATH<br>CLASSPATH=.:$JAVA_HOME/lib/<br>export JAVA_HOME<br>export PATH<br>export CLASSPATH<br>执行：sudo update-alternatives –install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_45/bin/java 300<br>sudo update-alternatives –install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_45/bin/javac 300<br>sudo update-alternatives –install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_45/bin/jar 300<br>查看当前Java版本<br>java  -version<br> （3） 安装ambari-server    (安装在一台centos上即可，部署为ambari-server的机器)<br>ambari-server  setup   -j  /usr/lib/jvm/jdk1.8.0­_45/<br>安装显示：<br>Using python  /usr/bin/python<br> Setup ambari‐server<br>  Checking SELinux…<br> SELinux status is ‘enabled’<br> SELinux mode is ‘permissive’<br>  WARNING: SELinux is set to ‘permissive’ mode and temporarily disabled.<br> OK to continue [y/n] (y)?<br> Customize user account for ambari‐server daemon [y/n] (n)?<br> Adjusting ambari‐server permissions and ownership…<br>  Checking firewall status…<br>  Checking JDK…<br> WARNING: JAVA_HOME /usr/lib/jvm/jdk1.8.0_45 must be valid on ALL hosts  WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited<br>  Completing setup…<br>  Configuring database…<br>  Enter advanced database configuration [y/n] (n)? y<br>  Configuring database…  =============================================================================<br>  Choose one of the following options:<br>  [1] ‐ PostgreSQL (Embedded)<br>  [2] ‐ Oracle<br>  [3] ‐ MySQL / MariaDB<br>  [4] ‐ PostgreSQL<br>  [5] ‐ Microsoft SQL Server (Tech Preview)<br>  [6] ‐ SQL Anywhere<br>  [7] ‐ BDB  =============================================================================<br> Enter choice (3): 3<br>  Hostname (localhost):<br>  Port (3306):<br>  Database name (ambari):<br>  Username (ambari):<br>  Enter Database Password (bigdata):<br>  Configuring ambari database…<br>  Copying JDBC drivers to server resources…<br>  Configuring remote database connection properties…<br>WARNING: Before starting Ambari Server, you must run the following DDL against the databa     se to create the schema: /var/lib/ambari<br> Proceed with configuring remote database connection properties [y/n] (y)? y<br>  Extracting system views……………<br>  Adjusting ambari‐server permissions and ownership…<br>  Ambari Server ‘setup’ completed successfully.<br> （4）启动ambari-server<br>      ambari-server start<br>      启动成功后通过：http：//namenode:8080访问<br>      登录账号及密码：admin<br> （6） 进程操作<br>    1.查看ambari进程<br>      ps   -ef   |   grep   ambari<br>      2.停止ambari进程<br>       ambari-server  stop<br>      3.重启ambari进程<br>       ambari-server  restart<br> （7） 修改端口<br>      vi   /etc/ambari-server/conf/ambari.properties<br>      插入或编辑以下内容<br>      Client.api.port = <port_number></port_number></p><h2 id="11-安装ambari-agent-每台机器都要装"><a href="#11-安装ambari-agent-每台机器都要装" class="headerlink" title="11 安装ambari-agent(每台机器都要装)"></a>11 安装ambari-agent(每台机器都要装)</h2><pre><code>1.安装ambari-agent</code></pre><p>yum   install  ambari-agent<br>    2.配置<br>       vi  /etc/ambari-agent/conf/ambari-agent.ini<br>       插入或更改以下内容<br>       hostname = namenode<br>最后<br>使用谷歌浏览器登录：<a href="http://namenode:8080" target="_blank" rel="noopener">http://namenode:8080</a>        账号：admin    密码：admin<br>注意：选择操作系统时，应该选择当前机器的版本。如果是本地源，<br>则需要修改HDP、HDP-UTILS的位置</p><p>If you are lucky enough, that I wish you success.<br>Said too much, tears.</p><p>如果出现ip绑定问题，修改/etc/hosts/中的ip为每台机器的真实ip<br>查看ip命令ifconfig<br>出现mysql  drive驱动问题   yum  install  mysql-connector-java</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-物理条件：三台centos&quot;&gt;&lt;a href=&quot;#1-物理条件：三台centos&quot; class=&quot;headerlink&quot; title=&quot;1.物理条件：三台centos&quot;&gt;&lt;/a&gt;1.物理条件：三台centos&lt;/h2&gt;&lt;p&gt;前期条件：修改每台centos的名称
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
</feed>
