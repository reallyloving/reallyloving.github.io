<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>王小二客栈</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.wenchong.top/"/>
  <updated>2018-05-14T06:16:03.670Z</updated>
  <id>http://www.wenchong.top/</id>
  
  <author>
    <name>小二</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux常用命令</title>
    <link href="http://www.wenchong.top/2018/05/14/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.wenchong.top/2018/05/14/Linux常用命令/</id>
    <published>2018-05-14T03:08:03.323Z</published>
    <updated>2018-05-14T06:16:03.670Z</updated>
    
    <content type="html"><![CDATA[<p>** 使用Linux时，会有大量的命令，而一般常用的命令并不是很多（当然Linux系统管理员除外）。<br>1.cd命令<br>这是一个非常基本，也是大家经常需要使用的命令，它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /root/Docements # 切换到目录/root/Docements  </span><br><span class="line">cd ./path          # 切换到当前目录下的path目录中，“.”表示当前目录    </span><br><span class="line">cd ../path         # 切换到上层目录中的path目录中，“..”表示上一层目录</span><br></pre></td></tr></table></figure></p><p>2、ls命令<br>这是一个非常有用的查看文件与目录的命令，list之意，它的参数非常多，下面就列出一些我常用的参数吧，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-l ：列出长数据串，包含文件的属性与权限数据等  </span><br><span class="line">-a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用）  </span><br><span class="line">-d ：仅列出目录本身，而不是列出目录的文件数据  </span><br><span class="line">-h ：将文件容量以较易读的方式（GB，kB等）列出来  </span><br><span class="line">-R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来  </span><br><span class="line">注：这些参数也可以组合使用，下面举两个例子：</span><br><span class="line"></span><br><span class="line">ls -l #以长数据串的形式列出当前目录下的数据文件和目录  </span><br><span class="line">ls -lR #以长数据串的形式列出当前目录下的所有文件</span><br></pre></td></tr></table></figure></p><p>3、grep命令<br>该命令常用于分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等，它的简单语法为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">grep [-acinv] [--color=auto] &apos;查找字符串&apos; filename  </span><br><span class="line">它的常用参数如下：</span><br><span class="line"></span><br><span class="line">-a ：将binary文件以text文件的方式查找数据  </span><br><span class="line">-c ：计算找到‘查找字符串’的次数  </span><br><span class="line">-i ：忽略大小写的区别，即把大小写视为相同  </span><br><span class="line">-v ：反向选择，即显示出没有‘查找字符串’内容的那一行  </span><br><span class="line"># 例如：  </span><br><span class="line"># 取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色  </span><br><span class="line">grep --color=auto &apos;MANPATH&apos; /etc/man.config  </span><br><span class="line"># 把ls -l的输出中包含字母file（不区分大小写）的内容输出  </span><br><span class="line">ls -l | grep -i file</span><br></pre></td></tr></table></figure></p><p>4、find命令<br>find是一个基于查找的功能非常强大的命令，相对而言，它的使用也相对较为复杂，参数也比较多，所以在这里将给把它们分类列出，它的基本语法如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">find [PATH] [option] [action]  </span><br><span class="line">  </span><br><span class="line">** 与时间有关的参数：  </span><br><span class="line">-mtime n : n为数字，意思为在n天之前的“一天内”被更改过的文件；  </span><br><span class="line">-mtime +n : 列出在n天之前（不含n天本身）被更改过的文件名；  </span><br><span class="line">-mtime -n : 列出在n天之内（含n天本身）被更改过的文件名；  </span><br><span class="line">-newer file : 列出比file还要新的文件名  </span><br><span class="line"># 例如：  </span><br><span class="line">find /root -mtime 0 # 在当前目录下查找今天之内有改动的文件</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">与用户或用户组名有关的参数：  </span><br><span class="line">-user name : 列出文件所有者为name的文件  </span><br><span class="line">-group name : 列出文件所属用户组为name的文件  </span><br><span class="line">-uid n : 列出文件所有者为用户ID为n的文件  </span><br><span class="line">-gid n : 列出文件所属用户组为用户组ID为n的文件  </span><br><span class="line"># 例如：  </span><br><span class="line">find /home/ljianhui -user ljianhui # 在目录/home/ljianhui中找出所有者为ljianhui的文件</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 与文件权限及名称有关的参数：  </span><br><span class="line">-name filename ：找出文件名为filename的文件  </span><br><span class="line">-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件  </span><br><span class="line">-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、  </span><br><span class="line">             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；  </span><br><span class="line">-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；  </span><br><span class="line">-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示  </span><br><span class="line">-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示  </span><br><span class="line"># 例如：  </span><br><span class="line">find / -name passwd # 查找文件名为passwd的文件  </span><br><span class="line">find . -perm 0755 # 查找当前目录中文件权限的0755的文件  </span><br><span class="line">find . -size +12k # 查找当前目录中大于12KB的文件，注意c表示byte</span><br></pre></td></tr></table></figure><p>5、cp命令<br>该命令用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下，它的常用参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-a ：将文件的特性一起复制  </span><br><span class="line">-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份  </span><br><span class="line">-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行  </span><br><span class="line">-r ：递归持续复制，用于目录的复制行为  </span><br><span class="line">-u ：目标文件与源文件有差异时才会复制  </span><br><span class="line">例如 ：</span><br><span class="line"></span><br><span class="line">cp -a file1 file2 #连同文件的所有特性把文件file1复制成文件file2  </span><br><span class="line">cp file1 file2 file3 dir #把文件file1、file2、file3复制到目录dir中</span><br></pre></td></tr></table></figure></p><p>6、mv命令<br>该命令用于移动文件、目录或更名，move之意，它的常用参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖  </span><br><span class="line">-i ：若目标文件已经存在，就会询问是否覆盖  </span><br><span class="line">-u ：若目标文件已经存在，且比目标文件新，才会更新  </span><br><span class="line">注：该命令可以把一个文件或多个文件一次移动一个文件夹中，但是最后一个目标文件一定要是“目录”。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line">[plain] view plain copy</span><br><span class="line">mv file1 file2 file3 dir # 把文件file1、file2、file3移动到目录dir中  </span><br><span class="line">mv file1 file2 # 把文件file1重命名为file2</span><br></pre></td></tr></table></figure></p><p>7、rm命令<br>该命令用于删除文件或目录，remove之间，它的常用参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">-f ：就是force的意思，忽略不存在的文件，不会出现警告消息  </span><br><span class="line">-i ：互动模式，在删除前会询问用户是否操作  </span><br><span class="line">-r ：递归删除，最常用于目录删除，它是一个非常危险的参数  </span><br><span class="line">例如：</span><br><span class="line">[plain] view plain copy</span><br><span class="line">rm -i file # 删除文件file，在删除之前会询问是否进行该操作  </span><br><span class="line">rm -fr dir # 强制删除目录dir中的所有文件 </span><br><span class="line">``` </span><br><span class="line">8、ps命令</span><br><span class="line">该命令用于将某个时间点的进程运行情况选取下来并输出，process之意，它的常用参数如下：</span><br></pre></td></tr></table></figure></p><p>-A ：所有的进程均显示出来<br>-a ：不与terminal有关的所有进程<br>-u ：有效用户的相关进程<br>-x ：一般与a参数一起使用，可列出较完整的信息<br>-l ：较长，较详细地将PID的信息列出<br>其实我们只要记住ps一般使用的命令参数搭配即可，它们并不多，如下：<br>[plain] view plain copy<br>ps aux # 查看系统所有的进程数据<br>ps ax # 查看不与terminal有关的所有进程<br>ps -lA # 查看系统所有的进程数据<br>ps axjf # 查看连同一部分进程树状态<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">9、kill命令</span><br><span class="line">该命令用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用，它的基本语法如下：</span><br></pre></td></tr></table></figure></p><p>kill -signal PID<br>signal的常用参数如下：<br>注：最前面的数字为信号的代号，使用时可以用代号代替相应的信号。<br>[plain] view plain copy<br>1：SIGHUP，启动被终止的进程<br>2：SIGINT，相当于输入ctrl+c，中断一个程序的进行<br>9：SIGKILL，强制中断一个进程的进行<br>15：SIGTERM，以正常的结束进程方式来终止进程<br>17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行<br>例如：<br>[plain] view plain copy</p><h1 id="以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程"><a href="#以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程" class="headerlink" title="以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程"></a>以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程</h1><p>kill -SIGTERM %1   </p><h1 id="重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得"><a href="#重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得" class="headerlink" title="重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得"></a>重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得</h1><p>kill -SIGHUP PID<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">10、killall命令</span><br><span class="line">该命令用于向一个命令启动的进程发送一个信号，它的一般语法如下：</span><br></pre></td></tr></table></figure></p><p>killall [-iIe] [command name]<br>它的参数如下：<br>[plain] view plain copy<br>-i ：交互式的意思，若需要删除时，会询问用户<br>-e ：表示后面接的command name要一致，但command name不能超过15个字符<br>-I ：命令名称忽略大小写  </p><h1 id="例如："><a href="#例如：" class="headerlink" title="例如："></a>例如：</h1><p>killall -SIGHUP syslogd # 重新启动syslogd<br>11、file命令<br>该命令用于判断接在file命令后的文件的基本数据，因为在Linux下文件的类型并不是以后缀为分的，所以这个命令对我们来说就很有用了，它的用法非常简单，基本语法如下：<br>[plain] view plain copy<br>file filename  </p><p>#例如：<br>file ./test<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">12、tar命令</span><br><span class="line">该命令用于对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压。它的常用参数如下：</span><br></pre></td></tr></table></figure></p><p>-c ：新建打包文件<br>-t ：查看打包文件的内容含有哪些文件名<br>-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中<br>-j ：通过bzip2的支持进行压缩/解压缩<br>-z ：通过gzip的支持进行压缩/解压缩<br>-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来<br>-f filename ：filename为要处理的文件<br>-C dir ：指定压缩/解压缩的目录dir<br>上面的解说可以已经让你晕过去了，但是通常我们只需要记住下面三条命令即可：<br>[plain] view plain copy<br>压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称<br>查询：tar -jtv -f filename.tar.bz2<br>解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录<br>注：文件名并不定要以后缀tar.bz2结尾，这里主要是为了说明使用的压缩程序为bzip2<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">13、cat命令</span><br><span class="line">该命令用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用，从而可以一页页地查看数据。例如：</span><br></pre></td></tr></table></figure></p><p>cat text | less # 查看text文件中的内容  </p><h1 id="注：这条命令也可以使用less-text来代替"><a href="#注：这条命令也可以使用less-text来代替" class="headerlink" title="注：这条命令也可以使用less text来代替"></a>注：这条命令也可以使用less text来代替</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">14、chgrp命令</span><br><span class="line">该命令用于改变文件所属用户组，它的使用非常简单，它的基本用法如下：</span><br></pre></td></tr></table></figure><p>chgrp [-R] dirname/filename<br>-R ：进行递归的持续对所有文件和子目录更改  </p><h1 id="例如：-1"><a href="#例如：-1" class="headerlink" title="例如："></a>例如：</h1><p>chgrp users -R ./dir # 递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">15、chown命令</span><br><span class="line">该命令用于改变文件的所有者，与chgrp命令的使用方法相同，只是修改的文件属性不同，不再详述。</span><br><span class="line"></span><br><span class="line">16、chmod命令</span><br><span class="line">该命令用于改变文件的权限，一般的用法如下：</span><br></pre></td></tr></table></figure></p><p>chmod [-R] xyz 文件或目录<br>-R：进行递归的持续更改，即连同子目录下的所有文件都会更改<br>同时，chmod还可以使用u（user）、g（group）、o（other）、a（all）和+（加入）、-（删除）、=（设置）跟rwx搭配来对文件的权限进行更改。</p><p>[plain] view plain copy</p><h1 id="例如：-2"><a href="#例如：-2" class="headerlink" title="例如："></a>例如：</h1><p>chmod 0755 file # 把file的文件权限改变为-rxwr-xr-x<br>chmod g+w file # 向file的文件权限中加入用户组可写权限<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">18、vim命令</span><br><span class="line">该命令主要用于文本编辑，它接一个或多个文件名作为参数，如果文件存在就打开，如果文件不存在就以该文件名创建一个文件。vim是一个非常好用的文本编辑器，它里面有很多非常好用的命令，在这里不再多说。你可以从这里下载vim常用操作的详细说明。</span><br><span class="line"></span><br><span class="line">19、gcc命令</span><br><span class="line">对于一个用Linux开发C程序的人来说，这个命令就非常重要了，它用于把C语言的源程序文件，编译成可执行程序，由于g++的很多参数跟它非常相似，所以这里只介绍gcc的参数，它的常用参数如下：</span><br></pre></td></tr></table></figure></p><p>-o ：output之意，用于指定生成一个可执行文件的文件名<br>-c ：用于把源文件生成目标文件（.o)，并阻止编译器创建一个完整的程序<br>-I ：增加编译时搜索头文件的路径<br>-L ：增加编译时搜索静态连接库的路径<br>-S ：把源文件生成汇编代码文件<br>-lm：表示标准库的目录中名为libm.a的函数库<br>-lpthread ：连接NPTL实现的线程库<br>-std= ：用于指定把使用的C语言的版本  </p><h1 id="例如：-3"><a href="#例如：-3" class="headerlink" title="例如："></a>例如：</h1><h1 id="把源文件test-c按照c99标准编译成可执行程序test"><a href="#把源文件test-c按照c99标准编译成可执行程序test" class="headerlink" title="把源文件test.c按照c99标准编译成可执行程序test"></a>把源文件test.c按照c99标准编译成可执行程序test</h1><p>gcc -o test test.c -lm -std=c99  </p><p>#把源文件test.c转换为相应的汇编程序源文件test.s<br>gcc -S test.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">20、time命令</span><br><span class="line">该命令用于测算一个命令（即程序）的执行时间。它的使用非常简单，就像平时输入命令一样，不过在命令的前面加入一个time即可，例如：</span><br></pre></td></tr></table></figure></p><p>time ./process<br>time ps aux<br>在程序或命令运行结束后，在最后输出了三个时间，它们分别是：<br>user：用户CPU时间，命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；<br>system：系统CPU时间，命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和；<br>real：实际时间，从command命令行开始执行到运行终止的消逝时间；<br>```<br>注：用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;** 使用Linux时，会有大量的命令，而一般常用的命令并不是很多（当然Linux系统管理员除外）。&lt;br&gt;1.cd命令&lt;br&gt;这是一个非常基本，也是大家经常需要使用的命令，它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径。如：&lt;br&gt;&lt;
      
    
    </summary>
    
      <category term="运维" scheme="http://www.wenchong.top/categories/operation/"/>
    
    
      <category term="Linux" scheme="http://www.wenchong.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>nginx安装</title>
    <link href="http://www.wenchong.top/2018/05/11/nginx%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/05/11/nginx安装/</id>
    <published>2018-05-10T16:00:00.000Z</published>
    <updated>2018-05-14T06:13:40.805Z</updated>
    
    <content type="html"><![CDATA[<p>** Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。</p><p>** 在高连接并发的情况下，Nginx是Apache服务器不错的替代品。</p><h3 id="Nginx-安装"><a href="#Nginx-安装" class="headerlink" title="Nginx 安装"></a>Nginx 安装</h3><p>系统平台：CentOS release 6.6 (Final) 64位。</p><h3 id="一、安装编译工具及库文件"><a href="#一、安装编译工具及库文件" class="headerlink" title="一、安装编译工具及库文件"></a>一、安装编译工具及库文件</h3><p>yum -y install make zlib zlib-devel gcc-c++ libtool  openssl openssl-devel</p><h3 id="二、首先要安装-PCRE"><a href="#二、首先要安装-PCRE" class="headerlink" title="二、首先要安装 PCRE"></a>二、首先要安装 PCRE</h3><p>PCRE 作用是让 Nginx 支持 Rewrite 功能。</p><p>1、下载 PCRE 安装包，下载地址： <a href="http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz</a></p><p>[root@bogon src]# wget <a href="http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz" target="_blank" rel="noopener">http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz</a></p><p>2、解压安装包:</p><p>[root@bogon src]# tar zxvf pcre-8.35.tar.gz<br>3、进入安装包目录</p><p>[root@bogon src]# cd pcre-8.35<br>4、编译安装 </p><p>[root@bogon pcre-8.35]# ./configure<br>[root@bogon pcre-8.35]# make &amp;&amp; make install<br>5、查看pcre版本</p><p>[root@bogon pcre-8.35]# pcre-config –version</p><h3 id="安装-Nginx"><a href="#安装-Nginx" class="headerlink" title="安装 Nginx"></a>安装 Nginx</h3><p>1、下载 Nginx，下载地址：<a href="http://nginx.org/download/nginx-1.6.2.tar.gz" target="_blank" rel="noopener">http://nginx.org/download/nginx-1.6.2.tar.gz</a></p><p>[root@bogon src]# wget <a href="http://nginx.org/download/nginx-1.6.2.tar.gz" target="_blank" rel="noopener">http://nginx.org/download/nginx-1.6.2.tar.gz</a><br>2、解压安装包</p><p>[root@bogon src]# tar zxvf nginx-1.6.2.tar.gz<br>3、进入安装包目录</p><p>[root@bogon src]# cd nginx-1.6.2<br>4、编译安装</p><p>[root@bogon nginx-1.6.2]# ./configure –prefix=/usr/local/webserver/nginx –with-http_stub_status_module –with-http_ssl_module –with-pcre=/usr/local/src/pcre-8.35<br>[root@bogon nginx-1.6.2]# make<br>[root@bogon nginx-1.6.2]# make install<br>5、查看nginx版本</p><p>[root@bogon nginx-1.6.2]# /usr/local/webserver/nginx/sbin/nginx -v</p><p>** 到此，nginx安装完成。</p><h3 id="Nginx-配置"><a href="#Nginx-配置" class="headerlink" title="Nginx 配置"></a>Nginx 配置</h3><p>创建 Nginx 运行使用的用户 www：</p><p>[root@bogon conf]# /usr/sbin/groupadd www<br>[root@bogon conf]# /usr/sbin/useradd -g www www<br>配置nginx.conf ，将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容</p><p>[root@bogon conf]#  cat /usr/local/webserver/nginx/conf/nginx.conf<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">user www www;</span><br><span class="line">worker_processes 2; #设置值和CPU核心数一致</span><br><span class="line">error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别</span><br><span class="line">pid /usr/local/webserver/nginx/nginx.pid;</span><br><span class="line">#Specifies the value for maximum file descriptors that can be opened by this process.</span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line">events</span><br><span class="line">&#123;</span><br><span class="line">  use epoll;</span><br><span class="line">  worker_connections 65535;</span><br><span class="line">&#125;</span><br><span class="line">http</span><br><span class="line">&#123;</span><br><span class="line">  include mime.types;</span><br><span class="line">  default_type application/octet-stream;</span><br><span class="line">  log_format main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;</span><br><span class="line">               &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;</span><br><span class="line">               &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;</span><br><span class="line">  </span><br><span class="line">#charset gb2312;</span><br><span class="line">     </span><br><span class="line">  server_names_hash_bucket_size 128;</span><br><span class="line">  client_header_buffer_size 32k;</span><br><span class="line">  large_client_header_buffers 4 32k;</span><br><span class="line">  client_max_body_size 8m;</span><br><span class="line">     </span><br><span class="line">  sendfile on;</span><br><span class="line">  tcp_nopush on;</span><br><span class="line">  keepalive_timeout 60;</span><br><span class="line">  tcp_nodelay on;</span><br><span class="line">  fastcgi_connect_timeout 300;</span><br><span class="line">  fastcgi_send_timeout 300;</span><br><span class="line">  fastcgi_read_timeout 300;</span><br><span class="line">  fastcgi_buffer_size 64k;</span><br><span class="line">  fastcgi_buffers 4 64k;</span><br><span class="line">  fastcgi_busy_buffers_size 128k;</span><br><span class="line">  fastcgi_temp_file_write_size 128k;</span><br><span class="line">  gzip on; </span><br><span class="line">  gzip_min_length 1k;</span><br><span class="line">  gzip_buffers 4 16k;</span><br><span class="line">  gzip_http_version 1.0;</span><br><span class="line">  gzip_comp_level 2;</span><br><span class="line">  gzip_types text/plain application/x-javascript text/css application/xml;</span><br><span class="line">  gzip_vary on;</span><br><span class="line"> </span><br><span class="line">  #limit_zone crawler $binary_remote_addr 10m;</span><br><span class="line"> #下面是server虚拟主机的配置</span><br><span class="line"> server</span><br><span class="line">  &#123;</span><br><span class="line">    listen 80;#监听端口</span><br><span class="line">    server_name localhost;#域名</span><br><span class="line">    index index.html index.htm index.php;</span><br><span class="line">    root /usr/local/webserver/nginx/html;#站点目录</span><br><span class="line">      location ~ .*\.(php|php5)?$</span><br><span class="line">    &#123;</span><br><span class="line">      #fastcgi_pass unix:/tmp/php-cgi.sock;</span><br><span class="line">      fastcgi_pass 127.0.0.1:9000;</span><br><span class="line">      fastcgi_index index.php;</span><br><span class="line">      include fastcgi.conf;</span><br><span class="line">    &#125;</span><br><span class="line">    location ~ .*\.(gif|jpg|jpeg|png|bmp|swf|ico)$</span><br><span class="line">    &#123;</span><br><span class="line">      expires 30d;</span><br><span class="line">#access_log off;</span><br><span class="line">    &#125;</span><br><span class="line">    location ~ .*\.(js|css)?$</span><br><span class="line">    &#123;</span><br><span class="line">      expires 15d;</span><br><span class="line">#access_log off;</span><br><span class="line">    &#125;</span><br><span class="line">    access_log off;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>检查配置文件ngnix.conf的正确性命令：</p><p>[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx -t</p><h3 id="启动-Nginx"><a href="#启动-Nginx" class="headerlink" title="启动 Nginx"></a>启动 Nginx</h3><p>Nginx 启动命令如下：</p><p>[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx</p><h3 id="访问站点"><a href="#访问站点" class="headerlink" title="访问站点"></a>访问站点</h3><p>从浏览器访问我们配置的站点ip：</p><p>** Nginx 其他命令<br>以下包含了 Nginx 常用的几个命令：</p><p>/usr/local/webserver/nginx/sbin/nginx -s reload            # 重新载入配置文件<br>/usr/local/webserver/nginx/sbin/nginx -s reopen            # 重启 Nginx<br>/usr/local/webserver/nginx/sbin/nginx -s stop              # 停止 Nginx</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;** Nginx(“engine x”)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。&lt;/p&gt;
&lt;p&gt;** 在高连接并发的情况下，Nginx是Apache服务器不错的替代品。
      
    
    </summary>
    
      <category term="运维" scheme="http://www.wenchong.top/categories/operation/"/>
    
    
      <category term="nginx" scheme="http://www.wenchong.top/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop架构——2.8.3</title>
    <link href="http://www.wenchong.top/2018/05/04/Hadoop%E6%9E%B6%E6%9E%84/"/>
    <id>http://www.wenchong.top/2018/05/04/Hadoop架构/</id>
    <published>2018-05-04T01:13:27.168Z</published>
    <updated>2018-05-04T01:46:46.446Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>王小二客栈</title>
    <link href="http://www.wenchong.top/2018/02/17/myblog-test/"/>
    <id>http://www.wenchong.top/2018/02/17/myblog-test/</id>
    <published>2018-02-17T14:20:06.596Z</published>
    <updated>2018-02-17T14:13:57.246Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>zookeeper搭建</title>
    <link href="http://www.wenchong.top/2018/02/15/zookeeper%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/02/15/zookeeper安装/</id>
    <published>2018-02-14T16:00:00.000Z</published>
    <updated>2018-03-05T13:15:04.288Z</updated>
    
    <content type="html"><![CDATA[<ul><li>本文选用：centos6.5、zookeeper-3.4.6<h3 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h3>【软件】准备好jdk环境，此次我们的环境是open_jdk1.8.0_101<br>　　　　zookeeper-3.4.6.tar.gz<br>【步骤】</li><li><ol><li>准备条件<br>如果有内部dns或者外网有域名，则直接使用域名<br>如果没有需要修改/etc/hosts文件，或者直接使用IP</li></ol></li></ul><p>集群规划</p><p>主机类型 IP地址  域名<br>zookeeper1 192.168.1.1zookeeper1.chinasoft.com<br>zookeeper2 192.168.1.2zookeeper2.chinasoft.com<br>zookeeper3 192.168.1.3zookeeper3.chinasoft.com</p><p>注意：zookeeper因为有主节点和从节点的关系，所以部署的集群台数最好为奇数个，否则可能出现脑裂导致服务异常</p><ul><li><ol><li>安装<br>下载地址：<a href="http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/" target="_blank" rel="noopener">http://archive.apache.org/dist/zookeeper/zookeeper-3.4.6/</a><br>解压</li></ol></li></ul><p>tar -zxf zookeeper-3.4.6.tar.gz<br>cd zookeeper-3.4.6</p><p>拷贝配置文件，修改完成后分发给其他节点<br>cd /data/zookeeper-3.4.6/<br>cp zoo_sample.cfg zoo.cfg</p><p>cat zoo.cfg</p><p>tickTime=2000<br>initLimit=10<br>syncLimit=5<br>dataDir=/data/zookeeper-3.4.6/data<br>dataLogDir=/data/zookeeper-3.4.6/logs<br>clientPort=2181<br>server.1=u04rtv01.yaya.corp:2888:3888<br>server.2=u04rtv02.yaya.corp:2888:3888<br>server.3=u04rtv03.yaya.corp:2888:3888</p><ul><li>3.创建data和Log文件夹<br>mkdir /data/zookeeper-3.4.6/data<br>mkdir /data/zookeeper-3.4.6/logs</li></ul><p>　　　　　　　</p><ul><li><p>4、在zoo.cfg中的dataDir指定的目录下，新建myid文件。<br>例如：$ZK_INSTALL/data下，新建myid。在myid文件中输入1。表示为server.1。<br>如果为snapshot/d_2，则myid文件中的内容为 2，依此类推。 </p></li><li><p>启动：在集群中的每台主机上执行如下命令<br>bin/zkServer.sh start </p></li><li><p>查看状态，可以看到其中一台为主节点，其他两台为从节点：<br>bin/zkServer.sh status</p></li><li><p>主节点：<br>./zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: leader</p></li><li>从属节点：<br>./zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: follower</li></ul><ul><li>停止：<br>bin/zkServer.sh stop</li></ul><p>连接：<br>bin/zkCli.sh -server zookeeper1:2181<br>bin/zkCli.sh -server zookeeper2:2181<br>bin/zkCli.sh -server zookeeper3:2181 </p><ul><li>报错：<br>原因就是没有在dataDir目录下创建myid文件并且赋值(如1、2、3分别代表集群中的server1,server2,server3)</li></ul><p>2016-08-22 17:55:16,145 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>2016-08-22 17:55:16,150 [myid:] - INFO  [main:QuorumPeerConfig@340] - Defaulting to majority quorums<br>2016-08-22 17:55:16,150 [myid:] - ERROR [main:QuorumPeerMain@85] - Invalid config, exiting abnormally<br>org.apache.zookeeper.server.quorum.QuorumPeerConfig$ConfigException: Error processing /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:123)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:101)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:78)<br>Caused by: java.lang.IllegalArgumentException: /data/yunva/zookeeper-3.4.6/data/myid file is missing<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parseProperties(QuorumPeerConfig.java:350)<br>        at org.apache.zookeeper.server.quorum.QuorumPeerConfig.parse(QuorumPeerConfig.java:119)<br>        … 2 more<br>Invalid config, exiting abnormally</p><h3 id="单机部署——适用于开发测试"><a href="#单机部署——适用于开发测试" class="headerlink" title="单机部署——适用于开发测试"></a>单机部署——适用于开发测试</h3><p>tar -zxvf zookeeper-3.4.6.tar.gz<br>cd zookeeper-3.4.6/conf<br>cp zoo_sample.cfg zoo.cfg</p><ul><li><p>创建日志目录<br>mkdir /data/yunva/zookeeper-3.4.6/data<br>mkdir /data/yunva/zookeeper-3.4.6/logs</p></li><li><p>配置：conf/zoo.cfg</p></li></ul><p>tickTime=2000<br>initLimit=10<br>syncLimit=5<br>dataDir=/data/yunva/zookeeper-3.4.6/logs<br>dataLogDir=/data/yunva/zookeeper-3.4.6/logs<br>clientPort=2181</p><p>#自动清除日志文件<br>autopurge.snapRetainCount=20<br>autopurge.purgeInterval=48</p><ul><li>启动：</li></ul><p>bin/zkServer.sh start </p><ul><li>连接到Zookeeper：</li></ul><p>bin/zkCli.sh -server 127.0.0.1:2181  适用于Java开发</p><ul><li>查看状态：<br>bin/zkServer.sh status<br>JMX enabled by default<br>Using config: /data/yunva/zookeeper-3.4.6/bin/../conf/zoo.cfg<br>Mode: standalone</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;本文选用：centos6.5、zookeeper-3.4.6&lt;h3 id=&quot;集群部署&quot;&gt;&lt;a href=&quot;#集群部署&quot; class=&quot;headerlink&quot; title=&quot;集群部署&quot;&gt;&lt;/a&gt;集群部署&lt;/h3&gt;【软件】准备好jdk环境，此次我们的环境是open_
      
    
    </summary>
    
      <category term="zookeeper" scheme="http://www.wenchong.top/categories/zookeeper/"/>
    
    
      <category term="zookeepere" scheme="http://www.wenchong.top/tags/zookeepere/"/>
    
  </entry>
  
  <entry>
    <title>centos下sqoop环境搭建</title>
    <link href="http://www.wenchong.top/2018/02/15/centos%E4%B8%8Bsqoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.wenchong.top/2018/02/15/centos下sqoop环境搭建/</id>
    <published>2018-02-14T16:00:00.000Z</published>
    <updated>2018-03-05T13:14:36.442Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Sqoop是一个用来将Hadoop（Hive、HBase）和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如：MySQL ,Oracle ,Postgres等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中。</li></ul><h3 id="Sqoop安装"><a href="#Sqoop安装" class="headerlink" title="Sqoop安装"></a>Sqoop安装</h3><ul><li>1.下载Sqoop安装包<br>在Sqoop官网下载安装包，本次使用的是sqoop-1.4.6.bin<strong>hadoop-2.0.4-alpha.tar.gz安装在/usr/local目录下，下载地址为<a href="http://apache.fayea.com/sqoop/1.4.6/sqoop-1.4.6.bin" target="_blank" rel="noopener">http://apache.fayea.com/sqoop/1.4.6/sqoop-1.4.6.bin</a></strong>hadoop-2.0.4-alpha.tar.gz</li><li>2.解压Sqoop安装包<br>#进入sqoop安装目录<br>[hadoop@BigData ~]$ cd /usr/local<br>#解压sqoop安装包<br>[hadoop@BigData ~]$ tar -zxvf sqoop-1.4.6.bin<strong>hadoop-2.0.4-alpha.tar.gz<br>#删除sqoop安装包<br>[hadoop@BigData ~]$ rm -rf sqoop-1.4.6.bin</strong>hadoop-2.0.4-alpha.tar.gz<br>#重命名sqoop目录名<br>[hadoop@BigData ~]$ mv sqoop-1.4.6.bin__hadoop-2.0.4-alpha sqoop</li><li>3.配置Sqoop环境变量<br>#配置Sqoop环境变量<br>[root@BigData ~]# vi /etc/profile<br>export SQOOP_HOME=/usr/local/sqoop<br>export PATH=$PATH:$SQOOP_HOME/bin<br>#保存之后记得source，使之前的配置生效<br>source /etc/profile</li><li>4.将关系型数据库驱动包放到sqoop/lib目录下<br>MySql：mysql-connector-java-5.1.30.jar<br>Oracle：ojdbc14.jar</li><li>5.修改Sqoop配置文件<br>[hadoop@BigData ~]$ mv sqoop-env-template.sh sqoop-env.sh<br>[hadoop@BigData ~]$ vi sqoop-env.sh<br>#Set path to where bin/hadoop is available<br>export HADOOP_COMMON_HOME=/usr/local/hadoop<br>#Set path to where hadoop-*-core.jar is available<br>export HADOOP_MAPRED_HOME=/usr/local/hadoop<br>#set the path to where bin/hbase is available<br>export HBASE_HOME=/usr/local/hbase<br>#Set the path to where bin/hive is available<br>export HIVE_HOME=/usr/local/hive<br>#Set the path for where zookeper config dir is<br>export ZOOCFGDIR=/usr/local/zookeeper<br>到此，sqoop环境就已搭建成功！</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;Sqoop是一个用来将Hadoop（Hive、HBase）和关系型数据库中的数据相互转移的工具，可以将一个关系型数据库（例如：MySQL ,Oracle ,Postgres等）中的数据导入到Hadoop的HDFS中，也可以将HDFS的数据导入到关系型数据库中。&lt;
      
    
    </summary>
    
      <category term="Sqoop" scheme="http://www.wenchong.top/categories/Sqoop/"/>
    
    
      <category term="sqoop" scheme="http://www.wenchong.top/tags/sqoop/"/>
    
  </entry>
  
  <entry>
    <title>docker安装</title>
    <link href="http://www.wenchong.top/2018/02/05/docker%E5%AE%89%E8%A3%85/"/>
    <id>http://www.wenchong.top/2018/02/05/docker安装/</id>
    <published>2018-02-05T13:09:56.999Z</published>
    <updated>2018-02-18T17:27:27.415Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1：关闭selinux"><a href="#1：关闭selinux" class="headerlink" title="1：关闭selinux"></a>1：关闭selinux</h2><p>临时关闭：setenforce 0<br>永久关闭：</p><h2 id="1-vi-etc-sysconfig-selinux"><a href="#1-vi-etc-sysconfig-selinux" class="headerlink" title="1. vi /etc/sysconfig/selinux"></a>1. vi /etc/sysconfig/selinux</h2><p>插入/编辑以下内容<br>SELINUX=disabled</p><p>#重启生效</p><h2 id="2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel："><a href="#2：在Fedora-EPEL源中已经提供了docker-io包，下载安装epel：" class="headerlink" title="2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel："></a>2：在Fedora EPEL源中已经提供了docker-io包，下载安装epel：</h2><p>rpm -ivh <a href="http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm" target="_blank" rel="noopener">http://mirrors.sohu.com/fedora-epel/6/x86_64/epel-release-6-8.noarch.rpm</a><br>sed -i ‘s/^mirrorlist=https/mirrorlist=http/‘ /etc/yum.repos.d/epel.repo<br>（elpe.repo）<br>[epel]<br>name=epel<br>mirrorlist=<a href="http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch" target="_blank" rel="noopener">http://mirrors.fedoraproject.org/mirrorlist?repo=epel-$releasever&amp;arch=$basearch</a><br>enabled=1<br>gpgcheck=0</p><h2 id="3：安装docker"><a href="#3：安装docker" class="headerlink" title="3：安装docker"></a>3：安装docker</h2><p>yum install docker-io<br>安装完成后</p><h2 id="4：启动docker"><a href="#4：启动docker" class="headerlink" title="4：启动docker"></a>4：启动docker</h2><p>service  docker  start</p><h2 id="5：查看docker版本"><a href="#5：查看docker版本" class="headerlink" title="5：查看docker版本"></a>5：查看docker版本</h2><p>docker vesion</p><h2 id="6：查看docker日志"><a href="#6：查看docker日志" class="headerlink" title="6：查看docker日志"></a>6：查看docker日志</h2><p>cat /var/log/docker</p><p>docker安装完成</p><h1 id="一：卸载docker"><a href="#一：卸载docker" class="headerlink" title="一：卸载docker"></a>一：卸载docker</h1><p>列出你安装过的包<br>[root@localhost ~]# yum list installed | grep docker<br>docker-io.x86_64                     1.7.1-2.el6                        @epel<br>删除软件包<br>yum -y remove docker-io.x86_64<br>删除镜像/容器等<br>rm -rf /var/lib/docker</p><h1 id="二：升级docker版本为1-10-3"><a href="#二：升级docker版本为1-10-3" class="headerlink" title="二：升级docker版本为1.10.3"></a>二：升级docker版本为1.10.3</h1><p>升级之前停止docker服务,并将原有的docker服务进行备份. mv /usr/bin/docker /usr/bin/docker.bak</p><p>nohup wget -c <a href="https://get.docker.com/builds/Linux/x86_64/docker-1.10.3" target="_blank" rel="noopener">https://get.docker.com/builds/Linux/x86_64/docker-1.10.3</a> -O /usr/bin/docker<br>给执行权限：chmod 755 /usr/bin/docker 然后重启服务，并查看版本.</p><h2 id="报错："><a href="#报错：" class="headerlink" title="报错："></a>报错：</h2><p>Starting cgconfig service: Error: cannot mount memory to /cgroup/memory: No such file or directory<br>/sbin/cgconfigparser; error loading /etc/cgconfig.conf: Cgroup mounting failed<br>Failed to parse /etc/cgconfig.conf                         [FAILED]<br>Starting docker:                                       [  OK  ]</p><h2 id="修改：-etc-cgconfig-conf文件"><a href="#修改：-etc-cgconfig-conf文件" class="headerlink" title="修改：/etc/cgconfig.conf文件"></a>修改：/etc/cgconfig.conf文件</h2><p>mount {<br>    cpuset  = /cgroup/cpuset;<br>    cpu = /cgroup/cpu;<br>    cpuacct = /cgroup/cpuacct;</p><h1 id="memory-cgroup-memory"><a href="#memory-cgroup-memory" class="headerlink" title="memory  = /cgroup/memory;"></a>memory  = /cgroup/memory;</h1><pre><code>devices = /cgroup/devices;freezer = /cgroup/freezer;net_cls = /cgroup/net_cls;blkio   = /cgroup/blkio;</code></pre><p>}<br>重新启动docker 正常</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1：关闭selinux&quot;&gt;&lt;a href=&quot;#1：关闭selinux&quot; class=&quot;headerlink&quot; title=&quot;1：关闭selinux&quot;&gt;&lt;/a&gt;1：关闭selinux&lt;/h2&gt;&lt;p&gt;临时关闭：setenforce 0&lt;br&gt;永久关闭：&lt;/p&gt;
&lt;h2
      
    
    </summary>
    
      <category term="docker" scheme="http://www.wenchong.top/categories/docker/"/>
    
    
      <category term="docker" scheme="http://www.wenchong.top/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Centos7伪分布式安装Hadoop2.6和Hbase0.94</title>
    <link href="http://www.wenchong.top/2017/12/01/centos7+hadoop2.6+hbase1.0.x/"/>
    <id>http://www.wenchong.top/2017/12/01/centos7+hadoop2.6+hbase1.0.x/</id>
    <published>2017-11-30T16:00:00.000Z</published>
    <updated>2018-02-18T17:01:12.088Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h1><h2 id="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。"><a href="#一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java：-rpm-qa-grep-java。" class="headerlink" title="一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。"></a>一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的Java： rpm -qa|grep java。</h2><ul><li>卸载： yum -y remove java javaxxxxx(系统自带的Java版本)</li></ul><p>安装jdk，将jdk.tar.gz文件复制到/usr/java中,终端进入/mnt/share ,cp jdk.tar.gz /usr/ava，进入/usr/java解压：tar xzvf jdk.targz</p><p>配置环境变量：vi /etc/profile 输入i编辑<br>在尾部添加：export JAVA_HOME=/usr/java/jdkxxxx<br>export PATH=$JAVA_HOME/bin:$PATH<br>export CLASSPATH=.:JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</p><p>保存并退出： wq<br>使修改生效： source /etc/profile<br>查看Java版本：java -version</p><h2 id="二、Hadoop伪分布式安装"><a href="#二、Hadoop伪分布式安装" class="headerlink" title="二、Hadoop伪分布式安装"></a>二、Hadoop伪分布式安装</h2><ul><li>1、ssh无密码登陆</li></ul><p>终端：ssh-keygen -t rsa (获得rsa公钥私钥,id_rsa和id_rsa.pub)<br>cd .ssh<br>cp id_rsa.pub authorized_keys (将公钥复制给authorized_keys) &lt;分布式则要将所有节点id_rsa.pub相互复制&gt;</p><ul><li>2、 /mnt/share cp hadoop2.x /usr.hadoop</li></ul><p>解压tar xzvf hadoop 2.x</p><ul><li>3、修改core-site.xml、hadoop-env.sh、hdfs-site.xml、mapred-site.xml 、yarn-site.xml(hadoop2.x版本的配置文件在/hadoop2.x/etc/hadoop下)</li></ul><p>①core-site.xml：</p><pre><code>fs.default.namehdfs://localhost:9000</code></pre><p>② hadoop-env.sh：<br>export JAVA_HOME=/usr/java/jdkxxx (jdk路径)</p><p>③ hdfs-site.xml： 先创建好数据节点和名称节点的存放路径</p><pre><code>dfs.datanode.data.dir/user/hadoop/hadoop-2.5.1/datadfs.namenode.name.dir/user/hadoop/hadoop-2.5.1/namedfs.replication1</code></pre><p>④mapred-site.xml: (注意：这个文件是将/hadoop2.x/etc/hadoop下的mapred-site.xml.template复制并重命名 )</p><pre><code>mapreduce.framework.nameyarn</code></pre><p>⑤yarn-site.xml：</p><pre><code>yarn.nodemanager.aux-servicesmapreduce_shuffle</code></pre><ul><li>4、namenode格式化（一定要完成）</li></ul><p>终端：cd /usr/hadoop/hadoop-2.5.1/bin</p><p>./hdfs namenode -format (输入./hadoop namenode -format也行)</p><ul><li>5、运行hadoop</li></ul><p>终端： cd /usr/hadoop/hadoop-2.5.1/sbin (2.x版本后启动/停止在sbin目录下)<br>./start-hdfs.sh<br>./start-yarn.sh<br>(也可以只输入./start-all.sh)</p><p>输入jps查看启动项，当启动了NameNode、DataNode、SecondaryNameNode、ResourceManager、NodeManager即ok。</p><p>可进入Firefox中，输入端口号： localhost:50070 进入hadoop可视化页面。</p><h2 id="三、Hbase0-94安装"><a href="#三、Hbase0-94安装" class="headerlink" title="三、Hbase0.94安装"></a>三、Hbase0.94安装</h2><ul><li>1、/mnt/share cp hbase1.0.1 /usr.hbase</li></ul><p>解压tar xzvf hbase1.0.1</p><ul><li>2、修改hbase配置文件hbase-env.sh、hbase-site.xml</li></ul><p>hbase-env.sh:</p><p>export JAVA_HOME=/usr/java/jdkxxxx (java路径)<br>export HBASE_MANAGES_ZK=true (都得去掉前面#)</p><p>hbase-site.xml：</p><pre><code>hbase.rootdirhdfs://localhost:9000/hbasehbase.cluster.distributedtruehbase.zookeeper.quorumlocalhosthbase.tmp.dirfile:/usr/hbase/tmphbase.zookeeper.property.dataDirfile:/usr/hbase/zookeeperdata</code></pre><ul><li>3、运行hbase</li></ul><p>运行前需先启动hadoop，再进入hbase的bin目录下输入指令 ./start-hbase.sh<br>输入jps查看启动项，如有HMaster、HRegionServer、HQuormPeer,则说明hbase启动成功。<br>输入./hbase Shell (进入shell指令，可通过shell指令建表)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h1&gt;&lt;h2 id=&quot;一、安装Jdk：首先需要卸载系统自带的openjava，查看系统的
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>centos 6.5 内核升级</title>
    <link href="http://www.wenchong.top/2017/11/15/centos6.5%E5%86%85%E6%A0%B8%E5%8D%87%E7%BA%A7/"/>
    <id>http://www.wenchong.top/2017/11/15/centos6.5内核升级/</id>
    <published>2017-11-14T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:56.959Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-查看centos的内核版本"><a href="#1-查看centos的内核版本" class="headerlink" title="1.查看centos的内核版本"></a>1.查看centos的内核版本</h2><p>rname -r</p><h2 id="2-查看系统版本"><a href="#2-查看系统版本" class="headerlink" title="2.查看系统版本"></a>2.查看系统版本</h2><p>cat /etc/centos-release</p><h2 id="3-安装软件"><a href="#3-安装软件" class="headerlink" title="3.安装软件"></a>3.安装软件</h2><p>编译安装新内核，依赖于开发环境和开发库<br>yum grouplist  //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库；</p><p>yum groupinstall “Development Tools”  //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具</p><p>yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行</p><p>yum install qt-devel //如果你没有 X 环境，这一条可以不用</p><p>yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们</p><h2 id="4-编译内核"><a href="#4-编译内核" class="headerlink" title="4.编译内核"></a>4.编译内核</h2><p>Linux内核版本有两种：稳定版和开发版 ，Linux内核版本号由3个数字组成： r.x.y</p><ul><li>r: 主版本号</li><li>x: 次版本号，偶数表示稳定版本；奇数表示开发中版本。</li><li>y: 修订版本号 ， 表示修改的次数<br>官网上有stable, longterm等版本，longterm是比stable更稳定的版本。<br><code>[root@sean ~]#curl -O -L  https://www.kernel.org/pub/linux/kernel/v3.x/linux-3.10.28.tar.xz[root@sean ~]# tar -xf linux-3.10.58.tar.xz -C /usr/src/[root@sean ~]# cd /usr/src/linux-3.10.58/[root@sean linux-3.10.58]# cp /boot/config-2.6.32-220.el6.x86_64 .config</code></li></ul><p>我们在系统原有的内核配置文件的基础上建立新的编译选项，所以复制一份到当前目录下，命名为.config。接下来继续配置：<br>`[root@sean linux-3.10.58]# sh -c ‘yes “” | make oldconfig’</p><p>HOSTCC  scripts/basic/fixdep</p><p>HOSTCC  scripts/kconfig/conf.o</p><p>SHIPPED scripts/kconfig/zconf.tab.c</p><p>SHIPPED scripts/kconfig/zconf.lex.c</p><p>SHIPPED scripts/kconfig/zconf.hash.c</p><p>HOSTCC  scripts/kconfig/zconf.tab.o</p><p>HOSTLD  scripts/kconfig/conf</p><p>scripts/kconfig/conf –oldconfig Kconfig</p><p>.config:555:warning: symbol value ‘m’ invalid for PCCARD_NONSTATIC<br>.config:2567:warning: symbol value ‘m’ invalid for MFD_WM8400<br>.config:2568:warning: symbol value ‘m’ invalid for MFD_WM831X<br>.config:2569:warning: symbol value ‘m’ invalid for MFD_WM8350<br>.config:2582:warning: symbol value ‘m’ invalid for MFD_WM8350_I2C<br>.config:2584:warning: symbol value ‘m’ invalid for AB3100_CORE<br>.config:3502:warning: symbol value ‘m’ invalid for MMC_RICOH_MMC</p><p>*</p><ul><li>Restart config…</li></ul><p>*</p><p>*</p><ul><li>General setup</li></ul><p>*</p><p>…<br>…</p><p>XZ decompressor tester (XZ_DEC_TEST) [N/m/y/?] (NEW)</p><p>Averaging functions (AVERAGE) [Y/?] (NEW)<br>y<br>CORDIC algorithm (CORDIC) [N/m/y/?] (NEW) </p><p>JEDEC DDR data (DDR) [N/y/?] (NEW) </p><p>#</p><p>configuration written to .config`<br>make oldconfig会读取当前目录下的.config文件，在.config文件里没有找到的选项则提示用户填写，然后备份.config文件为.config.old，并生成新的.config文件</p><h2 id="5-开始编译"><a href="#5-开始编译" class="headerlink" title="5.开始编译"></a>5.开始编译</h2><p>[root@sean linux-3.10.58]# make -j4 bzImage  //生成内核文件<br>[root@sean linux-3.10.58]# make -j4 modules  //编译模块<br>[root@sean linux-3.10.58]# make -j4 modules_install  //编译安装模块</p><p>-j后面的数字是线程数，用于加快编译速度，一般的经验是，逻辑CPU，就填写那个数字，例如有8核，则为-j8。（modules部分耗时30多分钟）</p><h2 id="6-安装"><a href="#6-安装" class="headerlink" title="6.安装"></a>6.安装</h2><p>[root@sean linux-3.10.58]# make install<br>实际运行到这一步时，出现ERROR: modinfo: could not find module vmware_balloon，但是不影响内核安装，是由于vsphere需要的模块没有编译，要避免这个问题，需要在make之前时修改.config文件，加入<br>HYPERVISOR_GUEST=yCONFIG_VMWARE_BALLOON=m<br>（这一部分比较容易出问题，参考下文异常部分）</p><h2 id="7-修改grub引导，重启"><a href="#7-修改grub引导，重启" class="headerlink" title="7.修改grub引导，重启"></a>7.修改grub引导，重启</h2><p>安装完成后，需要修改Grub引导顺序，让新安装的内核作为默认内核。<br>编辑 grub.conf文件，<br>vi /etc/grub.conf</p><p>#boot=/dev/sda<br>default=0<br>timeout=5<br>splashimage=(hd0,0)/grub/splash.xpm.gz<br>hiddenmenu<br>title CentOS (3.10.58)<br>    root (hd0,0)<br>…</p><p>数一下刚刚新安装的内核在哪个位置，从0开始，然后设置default为那个数字，一般新安装的内核在第一个位置，所以设置default=0。<br>重启reboot now</p><h2 id="8-确认当内核版本"><a href="#8-确认当内核版本" class="headerlink" title="8.确认当内核版本"></a>8.确认当内核版本</h2><p>[root@sean ~]# uname -r<br>3.10.58</p><p>升级内核成功!</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-查看centos的内核版本&quot;&gt;&lt;a href=&quot;#1-查看centos的内核版本&quot; class=&quot;headerlink&quot; title=&quot;1.查看centos的内核版本&quot;&gt;&lt;/a&gt;1.查看centos的内核版本&lt;/h2&gt;&lt;p&gt;rname -r&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
      <category term="运维" scheme="http://www.wenchong.top/categories/operation/"/>
    
    
      <category term="operation" scheme="http://www.wenchong.top/tags/operation/"/>
    
  </entry>
  
  <entry>
    <title>centos6.5下搭建hadoop2.7单机伪分布环境</title>
    <link href="http://www.wenchong.top/2017/10/01/centos6.5+hadoop2.7/"/>
    <id>http://www.wenchong.top/2017/10/01/centos6.5+hadoop2.7/</id>
    <published>2017-09-30T16:00:00.000Z</published>
    <updated>2018-05-14T06:10:28.607Z</updated>
    
    <content type="html"><![CDATA[<h3 id="设置固定IP地址及网关"><a href="#设置固定IP地址及网关" class="headerlink" title="设置固定IP地址及网关"></a>设置固定IP地址及网关</h3><ul><li><p>设置IP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-eth0</span><br></pre></td></tr></table></figure></li><li><p>修改内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=eth0</span><br><span class="line">HWADDR=08:00:27:BD:9D:B5  #不用改</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">UUID=53e4e4b6-9724-43ab-9da7-68792e611031 #不用改</span><br><span class="line">ONBOOT=yes  #开机启动</span><br><span class="line">NM_CONTROLLED=yes</span><br><span class="line">BOOTPROTO=static  #静态IP</span><br><span class="line">IPADDR=192.168.30.50  #IP地址</span><br><span class="line">NETMASK=255.255.255.0 #子网掩码</span><br></pre></td></tr></table></figure></li><li><p>设置网关</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network</span><br></pre></td></tr></table></figure></li><li><p>添加内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HOSTNAME=Hadoop.Master</span><br><span class="line">GATEWAY=192.168.30.1 #网关</span><br></pre></td></tr></table></figure></li><li><p>设置DNS<br>vi /etc/resolv.conf</p></li><li>添加内容<br>nameserver xxx.xxx.xxx.xxx #根据实际情况设置<br>nameserver 114.114.114.114 #可以设置多个</li><li>重启网卡<br>service network restart</li><li>设置主机名对应IP地址<br>vi /etc/hosts<br>#添加如下内容<br>192.168.30.50 Hadoop.Master<h3 id="添加Hadoop用户"><a href="#添加Hadoop用户" class="headerlink" title="添加Hadoop用户"></a>添加Hadoop用户</h3></li><li>添加用户组<br>groupadd hadoop</li><li>添加用户并分配用户组<br>useradd -g hadoop hadoop</li><li>修改用户密码<br>passwd hadoop<h3 id="关闭服务"><a href="#关闭服务" class="headerlink" title="关闭服务"></a>关闭服务</h3></li><li>关闭防火墙<br>service iptables stop #关闭防火墙服务<br>chkconfig iptables off #关闭防火墙开机启动<br>service ip6tables stop<br>chkconfig ip6tables off</li><li>关闭SELinux<br>vi /etc/sysconfig/selinux<br>#修改如下内容<br>SELINUX=enforcing -&gt; SELINUX=disabled<br>#再执行如下命令<br>setenforce 0<br>getenforce</li><li>关闭其他服务<h3 id="VSFTP安装与配置"><a href="#VSFTP安装与配置" class="headerlink" title="VSFTP安装与配置"></a>VSFTP安装与配置</h3></li><li>检查是否安装<br>chkconfig –list|grep vsftpd</li><li>安装vsftp<br>yum -y install vsftpd</li><li>创建日志文件<br>touch /var/log/vdftpd.log</li><li><p>配置vsftpd服务<br>vi /etc/vsftpd/vsftpd.conf<br>#修改如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">anonymous_enable=NO #关闭匿名访问</span><br><span class="line">xferlog_file=/var/log/vsftpd.log #设置日志文件 -- 我们上一步所创建的文件</span><br><span class="line">idle_session_timeout=600 #会话超时时间</span><br><span class="line">async_abor_enable=YES  #开启异步传输</span><br><span class="line">ascii_upload_enable=YES #开启ASCII上传</span><br><span class="line">ascii_download_enable=YES #开启ASCII下载</span><br></pre></td></tr></table></figure></li><li><p>查看vsftp运行状态<br>service vsftpd status</p><h3 id="启动vsftp"><a href="#启动vsftp" class="headerlink" title="启动vsftp"></a>启动vsftp</h3><p>service vsftpd start<br>#重启 service vsftpd restart<br>#关闭 service vsftpd stop</p></li><li>查看vsftpd服务启动项<br>chkconfig –list|grep vsftpd</li><li>设置vsftp开机启动<br>chkconfig vsftpd on<h3 id="SSH无密码配置"><a href="#SSH无密码配置" class="headerlink" title="SSH无密码配置"></a>SSH无密码配置</h3></li><li>查看ssh与rsync安装状态<br>rpm -qa|grep openssh<br>rpm -qa|grep rsync</li><li>安装ssh与rsync<br>yum -y install ssh<br>yum -y install rsync</li><li>切换hadoop用户<br>su - hadoop</li><li><p>生成ssh密码对</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -P &apos;&apos; -f ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure></li><li><p>将id_dsa.pub追加到授权的key中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></li></ul><h3 id="设置授权key权限"><a href="#设置授权key权限" class="headerlink" title="设置授权key权限"></a>设置授权key权限</h3><p>chmod 600 ~/.ssh/authorized_keys</p><p>#权限的设置非常重要，因为不安全的设置安全设置，会让你不能使用RSA功能</p><h3 id="测试ssh连接"><a href="#测试ssh连接" class="headerlink" title="测试ssh连接"></a>测试ssh连接</h3><p>ssh localhost</p><p>#如果不需要输入密码，则是成功</p><h2 id="安装Java"><a href="#安装Java" class="headerlink" title="安装Java"></a>安装Java</h2><ul><li>下载地址<br><a href="http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html</a></li></ul><p>注：我这里使用的是：jdk-7u80-linux-i586.tar.gz</p><ul><li>安装Java<br>切换至root用户<br>su root</li><li>创建/usr/java文件夹<br>mkdir /usr/java</li><li><p>使用winscp工具上传至服务器</p></li><li><p>将压缩包上传至/home/hadoop目录</p></li></ul><p>注：我这里使用的是winscp，使用hadoop用户连接</p><ul><li>将压缩包解压至/usr/java 目录<br>tar zxvf /home/hadoop/jdk-7u80-linux-i586.tar.gz -C /usr/java/</li><li><p>设置环境变量<br>vi /etc/profile<br>#追加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.7.0_80</span><br><span class="line">export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li><li><p>使环境变量生效<br>source /etc/profile</p></li><li>测试环境变量设置<br>java -version<h2 id="Hadoop安装与配置"><a href="#Hadoop安装与配置" class="headerlink" title="Hadoop安装与配置"></a>Hadoop安装与配置</h2>下载地址<br><a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a></li></ul><p>注:我下载的是hadoop-2.7.1.tar.gz</p><h3 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h3><p>使用winscp工具上传至服务器<br>将压缩包上传至/home/hadoop目录<br>*将压缩包解压至/usr目录<br>tar zxvf /home/hadoop/hadoop-2.7.1.tar.gz -C /usr/</p><ul><li>修改文件夹名称<br>mv /usr/hadoop-2.7.1/ /usr/hadoop</li><li>创建hadoop数据目录<br>mkdir /usr/hadoop/tmp</li><li>将hadoop文件夹授权给hadoop用户<br>chown -R hadoop:hadoop /usr/hadoop/</li><li><p>设置环境变量<br>vi /etc/profile<br>#追加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib</span><br></pre></td></tr></table></figure></li><li><p>使环境变量生效<br>source /etc/profile</p></li><li>测试环境变量设置<br>hadoop version<h3 id="配置HDFS"><a href="#配置HDFS" class="headerlink" title="配置HDFS"></a>配置HDFS</h3></li><li>切换至Hadoop用户<br>su - hadoop</li><li>修改hadoop-env.sh<br>cd /usr/hadoop/etc/hadoop/<br>vi hadoop-env.sh<br>#追加如下内容<br>export JAVA_HOME=/usr/java/jdk1.7.0_80</li><li><p>修改core-site.xml<br>vi core-site.xml<br>#添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://Hadoop.Master:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/usr/hadoop/tmp/&lt;/value&gt;</span><br><span class="line">        &lt;description&gt;A base for other temporary directories.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>修改hdfs-site.xml<br>vi hdfs-site.xml<br>#添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>格式化hdfs<br>hdfs namenode -format<br>注：出现Exiting with status 0即为成功</p></li><li><p>启动hdfs<br>start-dfs.sh<br>#停止命令 stop-dfs.sh<br>注：输出如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">15/09/21 18:09:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Starting namenodes on [Hadoop.Master]</span><br><span class="line">Hadoop.Master: starting namenode, logging to /usr/hadoop/logs/hadoop-hadoop-namenode-Hadoop.Master.out</span><br><span class="line">Hadoop.Master: starting datanode, logging to /usr/hadoop/logs/hadoop-hadoop-datanode-Hadoop.Master.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">The authenticity of host &apos;0.0.0.0 (0.0.0.0)&apos; can&apos;t be established.</span><br><span class="line">RSA key fingerprint is b5:96:b2:68:e6:63:1a:3c:7d:08:67:4b:ae:80:e2:e3.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">0.0.0.0: Warning: Permanently added &apos;0.0.0.0&apos; (RSA) to the list of known hosts.</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /usr/hadoop/logs/hadoop-hadoop-secondarynamenode-Hadoop.Master.out</span><br><span class="line">15/09/21 18:09:45 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicab</span><br></pre></td></tr></table></figure></li><li><p>查看进程<br>jps<br>注：输出类似如下内容<br>1763 NameNode<br>1881 DataNode<br>2146 Jps<br>2040 SecondaryNameNode</p></li><li>使用web查看Hadoop运行状态<br><a href="http://你的服务器ip地址:50070/" target="_blank" rel="noopener">http://你的服务器ip地址:50070/</a><h3 id="在HDFS上运行WordCount"><a href="#在HDFS上运行WordCount" class="headerlink" title="在HDFS上运行WordCount"></a>在HDFS上运行WordCount</h3></li><li>创建HDFS用户目录<br>hdfs dfs -mkdir /user<br>hdfs dfs -mkdir /user/hadoop #根据自己的情况调整/user/<username></username></li><li>复制输入文件（要处理的文件）到HDFS上<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>查看我们复制到HDFS上的文件<br>hdfs dfs -ls input</li><li>运行单词检索（grep）程序<br>hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar grep input output ‘dfs[a-z.]+’<br>#WordCount<br>#hadoop jar /usr/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount input output<br>#说明：output文件夹如已经存在则需要删除或指定其他文件夹。</li><li>查看运行结果<br>hdfs dfs -cat output/*<h3 id="配置YARN"><a href="#配置YARN" class="headerlink" title="配置YARN"></a>配置YARN</h3></li><li><p>修改mapred-site.xml<br>cd /usr/hadoop/etc/hadoop/<br>cp mapred-site.xml.template mapred-site.xml<br>vi mapred-site.xml<br>#添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>修改yarn-site.xml<br>vi yarn-site.xml<br>#添加如下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></li><li><p>启动YARN<br>start-yarn.sh<br>#停止yarn stop-yarn.sh</p></li><li>查看当前java进程<br>jsp<br>#输出如下<br>4918 ResourceManager<br>1663 NameNode<br>1950 SecondaryNameNode<br>5010 NodeManager<br>5218 Jps<br>1759 DataNode</li><li><p>运行你的mapReduce程序</p></li><li><p>配置好如上配置再运行mapReduce程序时即是yarn中运行。</p></li><li><p>使用web查看Yarn运行状态<br><a href="http://你的服务器ip地址:8088/" target="_blank" rel="noopener">http://你的服务器ip地址:8088/</a></p><h3 id="HDFS常用命令"><a href="#HDFS常用命令" class="headerlink" title="HDFS常用命令"></a>HDFS常用命令</h3></li><li>创建HDFS文件夹</li><li>在根目录创建input文件夹<br>hdfs dfs -mkdir -p /input</li><li>在用户目录创建input文件夹<br>说明：如果不指定“/目录”，则默认在用户目录创建文件夹<br>hdfs dfs -mkdir -p input<br>#等同于 hdfs dfs -mkdir -p /user/hadoop/input</li><li>查看HDFS文件夹</li><li>查看HDFS根文件夹<br>hdfs  dfs  -ls /</li><li>查看HDFS用户目录文件夹<br>hdfs  dfs  -ls</li><li>查看HDFS用户目录文件夹下input文件夹<br>hdfs  dfs  -ls input<br>#等同与 hdfs  dfs  -ls /user/hadoop/input</li><li>复制文件到HDFS<br>hdfs dfs -put /usr/hadoop/etc/hadoop input</li><li>删除文件夹<br>hdfs  dfs  -rm -r input</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;设置固定IP地址及网关&quot;&gt;&lt;a href=&quot;#设置固定IP地址及网关&quot; class=&quot;headerlink&quot; title=&quot;设置固定IP地址及网关&quot;&gt;&lt;/a&gt;设置固定IP地址及网关&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;设置IP&lt;/p&gt;
&lt;figure class=&quot;h
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>hive参数优化</title>
    <link href="http://www.wenchong.top/2017/08/29/hive%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/29/hive参数优化/</id>
    <published>2017-08-28T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:39.661Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><ul><li>1.设置合理solt数<br>mapred.tasktracker.map.tasks.maximum<br>每个tasktracker可同时运行的最大map task数，默认值2。<br>mapred.tasktracker.reduce.tasks.maximum<br>每个tasktracker可同时运行的最大reduce task数，默认值1</li><li>2.配置磁盘块<br>mapred.local.dir<br>map task中间结果写本地磁盘路径，默认值${hadoop.tmp.dir}/mapred/local。<br>可配置多块磁盘缓解写压力。当存在多个可以磁盘时，Hadoop将采用轮询方式将不同的map task中间结果写到磁盘上。</li><li>3.配置RPC Handler数<br>mapred.job.tracker.handler.count<br>jobtracker可并发处理来自tasktracker的RPC请求数，默认值10。</li><li>4.配置HTTP线程数<br>tasktracker.http.threads<br>HTTP服务器的工作线程数，用于获取map task的输出结果，默认值40。</li><li>5.启用批调度</li><li>6.选择合适的压缩算法<br>Job输出结果是否压缩<br>mapred.output.compress<br>是否压缩，默认值false。<br>mapred.output.compression.type<br>压缩类型，有NONE, RECORD和BLOCK，默认值RECORD。<br>mapred.output.compression.codec<br>压缩算法，默认值org.apache.hadoop.io.compress.DefaultCodec。<br>map task输出是否压缩<br>mapred.compress.map.output<br>是否压缩，默认值false<br>mapred.map.output.compression.codec<br>压缩算法，默认值org.apache.hadoop.io.compress.DefaultCodec。</li><li>7.设置失败容忍度<br>mapred.max.map.failures.percent<br>例如：set mapred.max.map.failures.percent=30;<br>作业最多允许失败的map task比例，默认值0。<br>mapred.max.reduce.failures.percent<br>作业最多允许失败的reduce task比例，默认值0。<br>mapred.map.max.attempts<br>一个map task的最多重试次数，默认值4。<br>mapred.reduce.max.attempts<br>一个reduce task的最多重试次数，默认值4。</li><li>8.设置跳过坏记录<br>mapred.skip.attempts.to.start.skipping<br>当任务失败次数达到该值时，启用跳过坏记录功能，默认值2。</li></ul><p>mapred.skip.out.dir<br>检测出的坏记录存放目录，默认值为输出目录的_logs/skip，设置为none表示不输出。<br>mapred.skip.map.max.skip.records<br>map task最多允许的跳过记录数，默认值0。<br>mapred.skip.reduce.max.skip.groups<br>reduce task最多允许的跳过记录数，默认值0。</p><ul><li>9.配置jvm重用<br>mapred.job.reuse.jvm.num.tasks<br>一个jvm可连续启动多个同类型任务，默认值1，若为-1表示不受限制。</li><li>10.配置jvm参数<br>mapred.child.java.opts<br>任务启动的jvm参数，默认值-Xmx200m，建议值-XX:-UseGCOverheadLimit -Xms512m -Xmx2048m -verbose:gc -Xloggc:/tmp/@taskid@.gc</li><li><ol><li>map task调优<br>io.sort.mb<br>默认值100M<br>io.sort.record.percent<br>默认值0.05<br>io.sort.spill.percent<br>默认值0.80</li></ol></li><li>12.reduce task调优<br>io.sort.factor<br>默认值10<br>mapred.reduce.parallel.copies<br>默认值5</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;1.设置合理solt数&lt;br&gt;mapred.tasktracke
      
    
    </summary>
    
      <category term="hive" scheme="http://www.wenchong.top/categories/hive/"/>
    
    
      <category term="Hhive" scheme="http://www.wenchong.top/tags/Hhive/"/>
    
  </entry>
  
  <entry>
    <title>kafka参数优化</title>
    <link href="http://www.wenchong.top/2017/08/25/kafka%E4%BC%98%E5%8C%96%E5%8F%82%E6%95%B0/"/>
    <id>http://www.wenchong.top/2017/08/25/kafka优化参数/</id>
    <published>2017-08-24T16:00:00.000Z</published>
    <updated>2018-02-18T17:04:52.386Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><ul><li><p>非负整数，用于唯一标识broker<br>broker.id=0</p></li><li><p>broker 服务监听端口<br>port=9092</p></li><li><p>broker 发布给生产者消费者的hostname，会存储在zookeeper。配置好这个host可以实现内网外网同时访问。<br>advertised.host.name=host1</p></li><li><p>broker 发布给生产者消费者的port，会存储在zookeeper。<br>advertised.port=9092</p></li><li><p>处理网络请求的线程数量，一般默认配置就好<br>num.network.threads=3</p></li><li><p>处理磁盘的线程数量，一般默认配置就好<br>num.io.threads=8</p></li><li><p>socket server 发送数据缓冲区大小<br>socket.send.buffer.bytes=102400</p></li><li><p>socket server 接受数据缓冲区大小<br>socket.receive.buffer.bytes=102400</p></li><li><p>soket server 可接受最大消息大小，防止oom<br>socket.request.max.bytes=104857600</p></li><li><p>kafka存放消息的目录<br>log.dirs=/home/data/kafka/kafka-logs</p></li><li><p>每个topic默认partition数量，根据消费者实际情况配置，配置过小会影响消费性能<br>num.partitions=50</p></li><li><p>kafka启动恢复日志,关闭前日志刷盘的线程数<br>num.recovery.threads.per.data.dir=1</p></li><li><p>日志保留时间<br>log.retention.minutes=30</p></li><li><p>日志保留大小<br>log.retention.bytes=53687091200</p></li><li><p>日志 segment file 大小. 超过这个大小创建新segment file<br>log.segment.bytes=67108864</p></li><li><p>日志 segment file 刷新时间. 超过这个时间创建新segment file<br>log.roll.hours=24</p></li><li><p>日志淘汰检查间隔时间<br>log.retention.check.interval.ms=10000</p></li><li><p>Zookeeper host和port<br>zookeeper.connect=localhost:2181</p></li><li><p>连接zookeeper超时时间<br>zookeeper.connection.timeout.ms=6000</p></li><li><p>清除fetch  purgatory 间隔消息条数<br>fetch.purgatory.purge.interval.requests=100</p></li><li><p>清除producer purgatory 间隔消息条数<br>producer .purgatory.purge.interval.requests=100</p></li><li><p>是否可以通过管理工具删除topic，默认是false<br>delete.topic.enable=true</p></li><li><p>日志传输时候的压缩格式，可选择lz4, snappy, gzip,不压缩。建议打开压缩，可以提高传输性能，压缩格式的选择可以参考文章结尾的参考资料。<br>compression.type=snappy</p></li><li><p>启用压缩的topic名称。若上面参数选择了一个压缩格式，那么压缩仅对本参数指定的topic有效，若本参数为空，则对所有topic有效。<br>compressed.topics=topic1</p></li><li><p>用来从主partion同步数据的线程数，默认为1，建议适当调大，数据量大的时候一个同步线程可能不够用<br>num.replica.fetchers=3</p></li><li><p>消息日志备份因子，默认是1<br>default.replication.factor=2</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;非负整数，用于唯一标识broker&lt;br&gt;broker.i
      
    
    </summary>
    
      <category term="kafka" scheme="http://www.wenchong.top/categories/kafka/"/>
    
    
      <category term="kafka" scheme="http://www.wenchong.top/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Hbase手动优化</title>
    <link href="http://www.wenchong.top/2017/08/20/hbase%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/20/hbase手动优化/</id>
    <published>2017-08-19T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:07.306Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h2><ul><li><p>zookeeper.session.timeout<br>默认值：3分钟（180000ms）<br>说明：RegionServer与Zookeeper间的连接超时时间。当超时时间到后，ReigonServer会被Zookeeper从RS集群清单中移除，HMaster收到移除通知后，会对这台server负责的regions重新balance，让其他存活的* RegionServer接管.<br>调优：<br>这个timeout决定了RegionServer是否能够及时的failover。设置成1分钟或更低，可以减少因等待超时而被延长的failover时间。<br>不过需要注意的是，对于一些Online应用，RegionServer从宕机到恢复时间本身就很短的（网络闪断，crash等故障，运维可快速介入），如果调低timeout时间，反而会得不偿失。因为当ReigonServer被正式从RS集群中移除时，HMaster就开始做balance了（让其他RS根据故障机器记录的WAL日志进行恢复）。当故障的RS在人工介入恢复后，这个balance动作是毫无意义的，反而会使负载不均匀，给RS带来更多负担。特别是那些固定分配regions的场景。</p></li><li><p>Hbase.zookeeper.quorum<br>默认值：localhost<br>说明：hbase所依赖的zookeeper部署<br>调优：<br>部署的zookeeper越多，可靠性就越高，但是部署只能部署奇数个，主要为了便于选出leader。最好给每个zookeeper 1G的内存和独立的磁盘，可以确保高性能。hbase.zookeeper.property.dataDir可以修改zookeeper保存数据的路径。</p></li><li><p>hbase.regionserver.handler.count<br>默认值：10<br>说明：RegionServer的请求处理IO线程数。<br>调优：<br>这个参数的调优与内存息息相关。<br>较少的IO线程，适用于处理单次请求内存消耗较高的Big PUT场景（大容量单次PUT或设置了较大cache的scan，均属于Big PUT）或ReigonServer的内存比较紧张的场景。<br>较多的IO线程，适用于单次请求内存消耗低，TPS要求非常高的场景。设置该值的时候，以监控内存为主要参考。<br>这里需要注意的是如果server的region数量很少，大量的请求都落在一个region上，因快速充满memstore触发flush导致的读写锁会影响全局TPS，不是IO线程数越高越好。<br>压测时，开启Enabling RPC-level logging，可以同时监控每次请求的内存消耗和GC的状况，最后通过多次压测结果来合理调节IO线程数。<br>这里是一个案例?Hadoop and HBase Optimization for Read Intensive Search Applications，作者在SSD的机器上设置IO线程数为100，仅供参考。</p></li><li><p>hbase.hregion.max.filesize<br>默认值：256M<br>说明：在当前ReigonServer上单个Reigon的最大存储空间，单个Region超过该值时，这个Region会被自动split成更小的region。<br>调优：<br>小region对split和compaction友好，因为拆分region或compact小region里的storefile速度很快，内存占用低。缺点是split和compaction会很频繁。<br>特别是数量较多的小region不停地split, compaction，会导致集群响应时间波动很大，region数量太多不仅给管理上带来麻烦，甚至会引发一些Hbase的bug。<br>一般512以下的都算小region。</p></li></ul><p>大region，则不太适合经常split和compaction，因为做一次compact和split会产生较长时间的停顿，对应用的读写性能冲击非常大。此外，大region意味着较大的storefile，compaction时对内存也是一个挑战。<br>当然，大region也有其用武之地。如果你的应用场景中，某个时间点的访问量较低，那么在此时做compact和split，既能顺利完成split和compaction，又能保证绝大多数时间平稳的读写性能。</p><p>既然split和compaction如此影响性能，有没有办法去掉？<br>compaction是无法避免的，split倒是可以从自动调整为手动。<br>只要通过将这个参数值调大到某个很难达到的值，比如100G，就可以间接禁用自动split（RegionServer不会对未到达100G的region做split）。<br>再配合RegionSplitter这个工具，在需要split时，手动split。<br>手动split在灵活性和稳定性上比起自动split要高很多，相反，管理成本增加不多，比较推荐online实时系统使用。</p><p>内存方面，小region在设置memstore的大小值上比较灵活，大region则过大过小都不行，过大会导致flush时app的IO wait增高，过小则因store file过多影响读性能。</p><ul><li><p>hbase.regionserver.global.memstore.upperLimit/lowerLimit<br>默认值：0.4/0.35<br>upperlimit说明：hbase.hregion.memstore.flush.size 这个参数的作用是当单个Region内所有的memstore大小总和超过指定值时，flush该region的所有memstore。RegionServer的flush是通过将请求添加一个队列，模拟生产消费模式来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发OOM。<br>这个参数的作用是防止内存占用过大，当ReigonServer内所有region的memstores所占用内存总和达到heap的40%时，HBase会强制block所有的更新并flush这些region以释放所有memstore占用的内存。<br>lowerLimit说明： 同upperLimit，只不过lowerLimit在所有region的memstores所占用内存达到Heap的35%时，不flush所有的memstore。它会找一个memstore内存占用最大的region，做个别flush，此时写更新还是会被block。lowerLimit算是一个在所有region强制flush导致性能降低前的补救措施。在日志中，表现为 “** Flush thread woke up with memory above low water.”<br>调优：这是一个Heap内存保护参数，默认值已经能适用大多数场景。<br>参数调整会影响读写，如果写的压力大导致经常超过这个阀值，则调小读缓存hfile.block.cache.size增大该阀值，或者Heap余量较多时，不修改读缓存大小。<br>如果在高压情况下，也没超过这个阀值，那么建议你适当调小这个阀值再做压测，确保触发次数不要太多，然后还有较多Heap余量的时候，调大hfile.block.cache.size提高读性能。<br>还有一种可能性是?hbase.hregion.memstore.flush.size保持不变，但RS维护了过多的region，要知道 region数量直接影响占用内存的大小。</p></li><li><p>hfile.block.cache.size</p></li></ul><p>默认值：0.2<br>说明：storefile的读缓存占用Heap的大小百分比，0.2表示20%。该值直接影响数据读的性能。<br>调优：当然是越大越好，如果写比读少很多，开到0.4-0.5也没问题。如果读写较均衡，0.3左右。如果写比读多，果断默认吧。设置这个值的时候，你同时要参考?hbase.regionserver.global.memstore.upperLimit?，该值是memstore占heap的最大百分比，两个参数一个影响读，一个影响写。如果两值加起来超过80-90%，会有OOM的风险，谨慎设置。</p><ul><li><p>hbase.hstore.blockingStoreFiles<br>默认值：7<br>说明：在flush时，当一个region中的Store（Coulmn Family）内有超过7个storefile时，则block所有的写请求进行compaction，以减少storefile数量。<br>调优：block写请求会严重影响当前regionServer的响应时间，但过多的storefile也会影响读性能。从实际应用来看，为了获取较平滑的响应时间，可将值设为无限大。如果能容忍响应时间出现较大的波峰波谷，那么默认或根据自身场景调整即可。</p></li><li><p>hbase.hregion.memstore.block.multiplier<br>默认值：2<br>说明：当一个region里的memstore占用内存大小超过hbase.hregion.memstore.flush.size两倍的大小时，block该region的所有请求，进行flush，释放内存。<br>虽然我们设置了region所占用的memstores总内存大小，比如64M，但想象一下，在最后63.9M的时候，我Put了一个200M的数据，此时memstore的大小会瞬间暴涨到超过预期的hbase.hregion.memstore.flush.size的几倍。这个参数的作用是当memstore的大小增至超过hbase.hregion.memstore.flush.size 2倍时，block所有请求，遏制风险进一步扩大。<br>调优： 这个参数的默认值还是比较靠谱的。如果你预估你的正常应用场景（不包括异常）不会出现突发写或写的量可控，那么保持默认值即可。如果正常情况下，你的写请求量就会经常暴长到正常的几倍，那么你应该调大这个倍数并调整其他参数值，比如hfile.block.cache.size和hbase.regionserver.global.memstore.upperLimit/lowerLimit，以预留更多内存，防止HBase server OOM。</p></li><li><p>hbase.hregion.memstore.mslab.enabled<br>默认值：true<br>说明：减少因内存碎片导致的Full GC，提高整体性能。<br>调优：详见 <a href="http://kenwublog.com/avoid-full-gc-in-hbase-using-arena-allocation" target="_blank" rel="noopener">http://kenwublog.com/avoid-full-gc-in-hbase-using-arena-allocation</a></p></li><li><p>hbase.client.scanner.caching<br>默认值：1<br>说明：scanner调用next方法一次获取的数据条数<br>调优：少的RPC是提高hbase执行效率的一种方法，理论上一次性获取越多数据就会越少的RPC，也就越高效。但是内存是最大的障碍。设置这个值的时候要选择合适的大小，一面一次性获取过多数据占用过多内存，造成其他程序使用内存过少。或者造成程序超时等错误（这个超时与hbase.regionserver.lease.period相关）。</p></li><li><p>hbase.regionserver.lease.period<br>默认值：60000<br>说明：客户端租用HRegion server 期限，即超时阀值。<br>调优：<br>这个配合hbase.client.scanner.caching使用，如果内存够大，但是取出较多数据后计算过程较长，可能超过这个阈值，适当可设置较长的响应时间以防被认为宕机。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;配置优化&quot;&gt;&lt;a href=&quot;#配置优化&quot; class=&quot;head
      
    
    </summary>
    
      <category term="Hbase" scheme="http://www.wenchong.top/categories/Hbase/"/>
    
    
      <category term="Hbase" scheme="http://www.wenchong.top/tags/Hbase/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce参数优化</title>
    <link href="http://www.wenchong.top/2017/08/19/MapReduce%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
    <id>http://www.wenchong.top/2017/08/19/MapReduce参数优化/</id>
    <published>2017-08-18T16:00:00.000Z</published>
    <updated>2018-02-18T17:05:07.503Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="1-core-default-xml："><a href="#1-core-default-xml：" class="headerlink" title="1 core-default.xml："></a>1 core-default.xml：</h2><ul><li>hadoop.tmp.dir：</li></ul><p>默认值： /tmp<br>说明： 尽量手动配置这个选项，否则的话都默认存在了里系统的默认临时文件/tmp里。并且手动配置的时候，如果服务器是多磁盘的，每个磁盘都设置一个临时文件目录，这样便于mapreduce或者hdfs等使用的时候提高磁盘IO效率。</p><ul><li>fs.trash.interval：</li></ul><p>默认值： 0<br>说明： 这个是开启hdfs文件删除自动转移到垃圾箱的选项，值为垃圾箱文件清除时间。一般开启这个会比较好，以防错误删除重要文件。单位是分钟。</p><ul><li>io.file.buffer.size：</li></ul><p>默认值：4096<br>说明：SequenceFiles在读写中可以使用的缓存大小，可减少 I/O 次数。在大型的 Hadoop cluster，建议可设定为 65536 到 131072。</p><h2 id="2-hdfs-default-xml："><a href="#2-hdfs-default-xml：" class="headerlink" title="2 hdfs-default.xml："></a>2 hdfs-default.xml：</h2><ul><li>dfs.blocksize：</li></ul><p>默认值：134217728<br>说明： 这个就是hdfs里一个文件块的大小了，CDH5中默认128M。太大的话会有较少map同时计算，太小的话也浪费可用map个数资源，而且文件太小namenode就浪费内存多。根据需要进行设置。</p><ul><li>dfs.namenode.handler.count：</li></ul><p>默认值：10<br>说明：设定 namenode server threads 的数量，这些 threads 會用 RPC 跟其他的 datanodes 沟通。当 datanodes 数量太多时会发現很容易出現 RPC timeout，解決方法是提升网络速度或提高这个值，但要注意的是 thread 数量多也表示 namenode 消耗的内存也随着增加</p><h2 id="3-mapred-default-xml："><a href="#3-mapred-default-xml：" class="headerlink" title="3 mapred-default.xml："></a>3 mapred-default.xml：</h2><ul><li>mapred.reduce.tasks（mapreduce.job.reduces）：</li></ul><p>默认值：1<br>说明：默认启动的reduce数。通过该参数可以手动修改reduce的个数。</p><ul><li>mapreduce.task.io.sort.factor：</li></ul><p>默认值：10<br>说明：Reduce Task中合并小文件时，一次合并的文件数据，每次合并的时候选择最小的前10进行合并。</p><ul><li>mapreduce.task.io.sort.mb：</li></ul><p>默认值：100<br>说明： Map Task缓冲区所占内存大小。</p><ul><li>mapred.child.java.opts：</li></ul><p>默认值：-Xmx200m<br>说明：jvm启动的子线程可以使用的最大内存。建议值-XX:-UseGCOverheadLimit -Xms512m -Xmx2048m -verbose:gc -Xloggc:/tmp/@taskid@.gc</p><ul><li>mapreduce.jobtracker.handler.count：</li></ul><p>默认值：10<br>说明：JobTracker可以启动的线程数，一般为tasktracker节点的4%。</p><ul><li>mapreduce.reduce.shuffle.parallelcopies：</li></ul><p>默认值：5<br>说明：reuduce shuffle阶段并行传输数据的数量。这里改为10。集群大可以增大。</p><ul><li>mapreduce.tasktracker.http.threads：</li></ul><p>默认值：40<br>说明：map和reduce是通过http进行数据传输的，这个是设置传输的并行线程数。</p><ul><li>mapreduce.map.output.compress：</li></ul><p>默认值：false<br>说明： map输出是否进行压缩，如果压缩就会多耗cpu，但是减少传输时间，如果不压缩，就需要较多的传输带宽。配合 mapreduce.map.output.compress.codec使用，默认是 org.apache.hadoop.io.compress.DefaultCodec，可以根据需要设定数据压缩方式。</p><ul><li>mapreduce.reduce.shuffle.merge.percent：</li></ul><p>默认值： 0.66<br>说明：reduce归并接收map的输出数据可占用的内存配置百分比。类似mapreduce.reduce.shuffle.input.buffer.percen属性。</p><ul><li>mapreduce.reduce.shuffle.memory.limit.percent：</li></ul><p>默认值： 0.25<br>说明：一个单一的shuffle的最大内存使用限制。</p><ul><li>mapreduce.jobtracker.handler.count：</li></ul><p>默认值： 10<br>说明：可并发处理来自tasktracker的RPC请求数，默认值10。</p><ul><li>mapred.job.reuse.jvm.num.tasks（mapreduce.job.jvm.numtasks）：</li></ul><p>默认值： 1<br>说明：一个jvm可连续启动多个同类型任务，默认值1，若为-1表示不受限制。</p><ul><li>mapreduce.tasktracker.tasks.reduce.maximum：</li></ul><p>默认值： 2<br>说明：一个tasktracker并发执行的reduce数，建议为cpu核数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;1-core-default-xml：&quot;&gt;&lt;a href=&quot;#1-
      
    
    </summary>
    
      <category term="MapReduce" scheme="http://www.wenchong.top/categories/MapReduce/"/>
    
    
      <category term="MapReduce" scheme="http://www.wenchong.top/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>amabri卸载</title>
    <link href="http://www.wenchong.top/2017/08/10/ambari%E5%8D%B8%E8%BD%BD/"/>
    <id>http://www.wenchong.top/2017/08/10/ambari卸载/</id>
    <published>2017-08-09T16:00:00.000Z</published>
    <updated>2018-02-18T17:00:22.609Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-删除hdp-repo和hdp-util-repo"><a href="#1-删除hdp-repo和hdp-util-repo" class="headerlink" title="1.删除hdp.repo和hdp-util.repo"></a>1.删除hdp.repo和hdp-util.repo</h2><p>cd /etc/yum.repos.d/<br>rm -rf hdp<em><br>rm -rf HDP</em><br>rm -rf ambari*</p><h2 id="2-删除安装包"><a href="#2-删除安装包" class="headerlink" title="2.删除安装包"></a>2.删除安装包</h2><p>用yum list installed | grep HDP来检查安装的ambari的包<br>yum remove -y  sqoop.noarch<br>yum remove -y  lzo-devel.x86_64<br>yum remove -y  hadoop-libhdfs.x86_64<br>yum remove -y  rrdtool.x86_64<br>yum remove -y  hbase.noarch<br>yum remove -y  pig.noarch<br>yum remove -y  lzo.x86_64<br>yum remove -y  ambari-log4j.noarch<br>yum remove -y  oozie.noarch<br>yum remove -y  oozie-client.noarch<br>yum remove -y  gweb.noarch<br>yum remove -y  snappy-devel.x86_64<br>yum remove -y  hcatalog.noarch<br>yum remove -y  python-rrdtool.x86_64<br>yum remove -y  nagios.x86_64<br>yum remove -y  webhcat-tar-pig.noarch<br>yum remove -y  snappy.x86_64<br>yum remove -y  libconfuse.x86_64<br>yum remove -y  webhcat-tar-hive.noarch<br>yum remove -y  ganglia-gmetad.x86_64<br>yum remove -y  extjs.noarch<br>yum remove -y  hive.noarch<br>yum remove -y  hadoop-lzo.x86_64<br>yum remove -y  hadoop-lzo-native.x86_64<br>yum remove -y  hadoop-native.x86_64<br>yum remove -y  hadoop-pipes.x86_64<br>yum remove -y  nagios-plugins.x86_64<br>yum remove -y  hadoop.x86_64<br>yum remove -y  zookeeper.noarch<br>yum remove -y  hadoop-sbin.x86_64<br>yum remove -y  ganglia-gmond.x86_64<br>yum remove -y  libganglia.x86_64<br>yum remove -y  perl-rrdtool.x86_64<br>yum remove -y  epel-release.noarch<br>yum remove -y  compat-readline5*<br>yum remove -y  fping.x86_64<br>yum remove -y  perl-Crypt-DES.x86_64<br>yum remove -y  exim.x86_64<br>yum remove -y ganglia-web.noarch<br>yum remove -y perl-Digest-HMAC.noarch<br>yum remove -y perl-Digest-SHA1.x86_64<br>yum remove -y bigtop-jsvc.x86_64</p><h2 id="3-删除快捷方式"><a href="#3-删除快捷方式" class="headerlink" title="3.删除快捷方式"></a>3.删除快捷方式</h2><p>cd /etc/alternatives<br>rm -rf hadoop-etc<br>rm -rf zookeeper-conf<br>rm -rf hbase-conf<br>rm -rf hadoop-log<br>rm -rf hadoop-lib<br>rm -rf hadoop-default<br>rm -rf oozie-conf<br>rm -rf hcatalog-conf<br>rm -rf hive-conf<br>rm -rf hadoop-man<br>rm -rf sqoop-conf<br>rm -rf hadoop-conf</p><h2 id="4-删除用户"><a href="#4-删除用户" class="headerlink" title="4.删除用户"></a>4.删除用户</h2><p>userdel nagios<br>userdel hive<br>userdel ambari-qa<br>userdel hbase<br>userdel oozie<br>userdel hcat<br>userdel mapred<br>userdel hdfs<br>userdel rrdcached<br>userdel zookeeper </p><p>#userdel mysql<br>userdel sqoop<br>userdel puppet<br>userdel yarn<br>userdel tez<br>userdel hadoop<br>userdel knox<br>userdel storm<br>userdel falcon<br>userdel flume<br>userdel nagios<br>userdel admin<br>userdel postgres<br>userdel  hdfs<br>userdel  zookeeper<br>userdel hbase</p><h2 id="5-删除文件夹"><a href="#5-删除文件夹" class="headerlink" title="5.删除文件夹"></a>5.删除文件夹</h2><p>rm -rf /hadoop<br>rm -rf /etc/hadoop<br>rm -rf /etc/hbase<br>rm -rf /etc/hcatalog<br>rm -rf /etc/hive<br>rm -rf /etc/ganglia<br>rm -rf /etc/nagios<br>rm -rf /etc/oozie<br>rm -rf /etc/sqoop<br>rm -rf /etc/zookeeper<br>rm -rf /var/run/hadoop<br>rm -rf /var/run/hbase<br>rm -rf /var/run/hive<br>rm -rf /var/run/ganglia<br>rm -rf /var/run/nagios<br>rm -rf /var/run/oozie<br>rm -rf /var/run/zookeeper<br>rm -rf /var/log/hadoop<br>rm -rf /var/log/hbase<br>rm -rf /var/log/hive<br>rm -rf /var/log/nagios<br>rm -rf /var/log/oozie<br>rm -rf /var/log/zookeeper<br>rm -rf /usr/lib/hadoop<br>rm -rf /usr/lib/hbase<br>rm -rf /usr/lib/hcatalog<br>rm -rf /usr/lib/hive<br>rm -rf /usr/lib/oozie<br>rm -rf /usr/lib/sqoop<br>rm -rf /usr/lib/zookeeper<br>rm -rf /var/lib/hive<br>rm -rf /var/lib/ganglia<br>rm -rf /var/lib/oozie<br>rm -rf /var/lib/zookeeper<br>rm -rf /var/tmp/oozie<br>rm -rf /tmp/hive<br>rm -rf /tmp/nagios<br>rm -rf /tmp/ambari-qa<br>rm -rf /tmp/sqoop-ambari-qa<br>rm -rf /var/nagios<br>rm -rf /hadoop/oozie<br>rm -rf /hadoop/zookeeper<br>rm -rf /hadoop/mapred<br>rm -rf /hadoop/hdfs<br>rm -rf /tmp/hadoop-hive<br>rm -rf /tmp/hadoop-nagios<br>rm -rf /tmp/hadoop-hcat<br>rm -rf /tmp/hadoop-ambari-qa<br>rm -rf /tmp/hsperfdata_hbase<br>rm -rf /tmp/hsperfdata_hive<br>rm -rf /tmp/hsperfdata_nagios<br>rm -rf /tmp/hsperfdata_oozie<br>rm -rf /tmp/hsperfdata_zookeeper<br>rm -rf /tmp/hsperfdata_mapred<br>rm -rf /tmp/hsperfdata_hdfs<br>rm -rf /tmp/hsperfdata_hcat<br>rm -rf /tmp/hsperfdata_ambari-qa<br>rm -rf /etc/flume<br>rm -rf /etc/storm<br>rm -rf /etc/hive-hcatalog<br>rm -rf /etc/tez<br>rm -rf /etc/falcon<br>rm -rf /var/run/flume<br>rm -rf /var/run/storm<br>rm -rf /var/run/webhcat<br>rm -rf /var/run/hadoop-yarn<br>rm -rf /var/run/hadoop-mapreduce<br>rm -rf /var/log/flume<br>rm -rf /var/log/storm<br>rm -rf /var/log/hadoop-yarn<br>rm -rf /var/log/hadoop-mapreduce<br>rm -rf /usr/lib/nagios<br>rm -rf /var/lib/hdfs<br>rm -rf /var/lib/hadoop-hdfs<br>rm -rf /var/lib/hadoop-yarn<br>rm -rf /var/lib/hadoop-mapreduce<br>rm -rf /tmp/hadoop-hdfs</p><h2 id="5-重置数据库，删除ambari包"><a href="#5-重置数据库，删除ambari包" class="headerlink" title="5.重置数据库，删除ambari包"></a>5.重置数据库，删除ambari包</h2><p>#采用这句命令来检查yum list installed | grep ambari<br>ambari-server stop<br>ambari-agent stop<br>ambari-server reset<br>yum remove -y ambari-<em><br>yum remove -y postgresql<br>rm -rf /etc/yum.repos.d/ambari</em><br>rm -rf /var/lib/ambari<em><br>rm -rf /var/log/ambari</em><br>rm -rf /etc/ambari*</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-删除hdp-repo和hdp-util-repo&quot;&gt;&lt;a href=&quot;#1-删除hdp-repo和hdp-util-repo&quot; class=&quot;headerlink&quot; title=&quot;1.删除hdp.repo和hdp-util.repo&quot;&gt;&lt;/a&gt;1.删除hdp.
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>错误及解决方案</title>
    <link href="http://www.wenchong.top/2017/08/10/ambari%E6%90%AD%E5%BB%BA%E9%94%99%E8%AF%AF/"/>
    <id>http://www.wenchong.top/2017/08/10/ambari搭建错误/</id>
    <published>2017-08-09T16:00:00.000Z</published>
    <updated>2018-05-14T06:07:44.326Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Exiting with exit code 1. </span><br><span class="line">REASON: Database check failed to complete. Please check /var/log/ambari-server/ambari-server.log and /var/log/ambari-server/ambari-server-check-database.log for more information.</span><br></pre></td></tr></table></figure><p>解决方法：查看日志，具体什么错.例如：数据库未开启、数据库配置问题</p><p>撤销已经赋予给 MySQL 用户权限的权限。<br>revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">revoke  all on *.* from &apos;root&apos;@&apos;192.168.0.197&apos;;</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@datanode01 ~]# yum makecache</span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Determining fastest mirrors</span><br><span class="line">ambari-2.4.1.0                                                   | 2.9 kB     00:00     </span><br><span class="line">ambari-2.4.1.0/filelists_db                                      | 139 kB     00:00     </span><br><span class="line">ambari-2.4.1.0/primary_db                                        | 8.3 kB     00:00     </span><br><span class="line">ambari-2.4.1.0/other_db                                          | 1.3 kB     00:00     </span><br><span class="line">file:///mnt/repodata/repomd.xml: [Errno 14] Could not open/read file:///mnt/repodata/repomd.xml</span><br><span class="line">Trying other mirror.</span><br><span class="line">Error: Cannot retrieve repository metadata (repomd.xml) for repository: c6-media. Please verify its path and try again</span><br></pre></td></tr></table></figure><p>如果有后面两个文件，处理方式mv CentOS-Media.repo CentOS-Media.repo.bak<br>没有的话，源问题，换源repos</p><h3 id="tip"><a href="#tip" class="headerlink" title="tip:"></a>tip:</h3><p>1、当提示要做如下操作的时候<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Be?sure?you?have?run:ambari-server?setup?--jdbc-db=mysql?--jdbc-driver=/path/to/mysql/****</span><br></pre></td></tr></table></figure></p><p>需要下载mysql-connector-java-5.1.39.tar驱动，解压得到mysql-connector-java-5.1.39-bin.jar文件<br>执行如下命令：ambari-server?setup?–jdbc-db=mysql?–jdbc-driver=/usr/lib/java/mysql-connector-java-5.1.39/mysql-connector-java-5.1.39-<br>bin.jar<br>同时，设置文件权限为644</p><h3 id="2017-7-19"><a href="#2017-7-19" class="headerlink" title="2017.7.19"></a>2017.7.19</h3><p>1.ERROR namenode.NameNode (NameNode.java:main(1759)) - Failed to start namenode.<br>java.net.BindException: Port in use: datanode01:50070<br>  不能获取映射地址，需要修改hosts中的映射ip为真实ip（ifconfig）<br>2.错删自定义的service导致不能登录amnari UI（日志报出database问题） （百度方案无解，最后重装ambari-server(发现重装无法下手，百度后删除ambari相关组件以及数据库的完全卸载，完成)）<br>3.使用ambari-server启动HDFS时，DataNode无法启动（出现port in use：localhost 0）。解决方式，在hosts文件中localhost 172.0.0.1被#；去除#后解决</p><h3 id="一般故障排除"><a href="#一般故障排除" class="headerlink" title="一般故障排除"></a>一般故障排除</h3><p>Ambari服务器：检查/var/log/ambari-server/ambari-server.[log|out]是否存在错误。<br>Ambari代理：检查/var/log/ambari-agent/ambari-agent.[log|out]是否存在错误。<br>请注意，如果Ambari Agent在/var/log/ambari-agent/ambari-agent.out中有任何输出，则表明存在重大问题。</p><h3 id="服务无法启动"><a href="#服务无法启动" class="headerlink" title="服务无法启动"></a>服务无法启动</h3><p>HDFS：检查/ var / log / hadoop / hdfs下的日志文件<br>MapReduce：检查/ var / log / hadoop / mapred下的日志文件<br>HBase：检查/ var / log / hbase下的日志文件<br>Hive：检查/ var / log / hive下的日志文件<br>Oozie：检查/ var / log / oozie下的日志文件<br>ZooKeeper：检查/ var / log / zookeeper下的日志文件<br>WebHCat：检查/ var / log / webhcat下的日志文件<br>Nagios：检查/ var / log / nagios下的日志文件</p><h3 id="2017-7-20"><a href="#2017-7-20" class="headerlink" title="2017.7.20"></a>2017.7.20</h3><p>Service ‘userhome’ check failed: java.io.FileNotFoundException: File does not exist: /user/admin<br>解决方案：sudo -u hdfs hdfs dfs  -mkdir /user/admin<br>sudo -u hdfs hdfs dfs  -chown admin:hadoop /user/admin</p><h3 id="资源池问题"><a href="#资源池问题" class="headerlink" title="资源池问题"></a>资源池问题</h3><p>FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Initialization failed forblock pool Block pool BP-1480406410-192.168.1.181-1398701121586 (storage idDS-167510828-192.168.1.191-50010-1398750515421)<br>原因：每次namenode format会重新创建一个namenodeId,而data目录包含了上次format时的id,namenode format清空了namenode下的数据,但是没有清空datanode下的数据,导致启动时失败,所要做的就是每次fotmat前,清空data下的所有目录.<br>: d6 E2 t&amp; M” g7 a* q3 l, H<br>解决办法：停掉集群，删除问题节点的data目录下的所有内容。即hdfs-site.xml文件中配置的dfs.data.dir目录。重新格式化namenode。</p><p>另一个更省事的办法：先停掉集群，然后将datanode节点目录/dfs/data/current/VERSION中的修改为与namenode一致即可。<br>其实我没解决，直接重装</p><h3 id="block-missing问题"><a href="#block-missing问题" class="headerlink" title="block missing问题"></a>block missing问题</h3><p>会导致进入安全模式：处理方式，删除缺失包，在HDFS用户下退出安全模式</p><p>添加节点时，需要查看该节点root磁盘下的剩余大小，如果磁盘空间不足，则扩大磁盘再添加节点。<br>不要问我为什么，说多了都是泪。集群就是这么崩盘的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>Ambari搭建</title>
    <link href="http://www.wenchong.top/2017/08/09/ambari%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.wenchong.top/2017/08/09/ambari搭建/</id>
    <published>2017-08-08T16:00:00.000Z</published>
    <updated>2018-05-14T06:06:38.838Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-物理条件：三台centos"><a href="#1-物理条件：三台centos" class="headerlink" title="1.物理条件：三台centos"></a>1.物理条件：三台centos</h2><p>前期条件：修改每台centos的名称，分别为namenode、datanode01、datanode02<br>          ssh免密码配置：namenode 可以免密码登录到datanode01、datanode02<br>配置ssh<br>      在namenode上生成密钥对：ssh-keygen  –t  rsa<br>      在/root/.ssh中会有生成的密钥对<br>      将namenode  的 id_rsa.pub写入datanode01的/root/.ssh  authorized_keys文件中。再将datanode01的authorized_keys 写入namenode /root/.ssh<br>datanode02同理操作<br>scp .ssh/id_rsa.pub chenlb@192.168.1.181:/home/chenlb/id_rsa.pub<br>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys<br>  将namenode中的三个机器的私钥 id_rsa提取到桌面，后续使用<br>安装ntp服务<br>yum install ntp<br>service ntpd start<br>chkconfig ntpd on</p><h2 id="2-更换源："><a href="#2-更换源：" class="headerlink" title="2.更换源："></a>2.更换源：</h2><p>将/etc/yum.repos.d/下的原centos.repos备份，然后添加本地源（我这是之前师傅在其他服务器布            置好了的源，你们可在网上查找相关源）</p><h2 id="3-验证本机名"><a href="#3-验证本机名" class="headerlink" title="3.验证本机名"></a>3.验证本机名</h2><pre><code>Hostname   -f</code></pre><p>  显示<br>      namenode   其他两台一样</p><h2 id="4-关闭防火墙"><a href="#4-关闭防火墙" class="headerlink" title="4.关闭防火墙"></a>4.关闭防火墙</h2><pre><code>Service iptables stop</code></pre><p>禁用自启动<br>      Chkconfig   iptables  off</p><h2 id="5-禁用ipv6"><a href="#5-禁用ipv6" class="headerlink" title="5.禁用ipv6"></a>5.禁用ipv6</h2><pre><code>使用lsmod查看系统启动的模块：ipv6相关的模块是net-pf-10  ipv6在vi  /etc/modprobe.d/dist.conf    中最后添加</code></pre><p> alias   net-pf-10   off<br>                                    alias  ipv6   off<br>      重启后，再使用lsmod查看ipv6的相应模块还在不在</p><h2 id="6-禁用SELinux"><a href="#6-禁用SELinux" class="headerlink" title="6.禁用SELinux"></a>6.禁用SELinux</h2><p>配置selinux<br>vi  /etc/sysconfig/selinux<br>插入<br>SELINUX=disabled<br>暂时禁用      setenforce  0</p><h2 id="7-配置禁用THP-每次重启机器后需要从新配置"><a href="#7-配置禁用THP-每次重启机器后需要从新配置" class="headerlink" title="7.配置禁用THP(每次重启机器后需要从新配置)"></a>7.配置禁用THP(每次重启机器后需要从新配置)</h2><p>  查看当前THP状态<br>  cat   /sys/kernel/mm/transparent_hugepage/enabled<br>  如果为always  madvise   [never]则为禁用<br>配置禁用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/defrag</span><br><span class="line">echo  never  &gt;  /sys/kernel/mm/redhat_transparent_hugepage/enabled</span><br><span class="line">echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/defrag</span><br><span class="line">echo  never  &gt;  /sys/kernel/mm/ transparent_hugepage/enabled</span><br></pre></td></tr></table></figure></p><h2 id="8-clean源-重新加载"><a href="#8-clean源-重新加载" class="headerlink" title="8.clean源 重新加载"></a>8.clean源 重新加载</h2><pre><code>yum clean allyum makecache</code></pre><h2 id="9-配置mysql作为数据库（只在ambari-server安装机器上做）"><a href="#9-配置mysql作为数据库（只在ambari-server安装机器上做）" class="headerlink" title="9.配置mysql作为数据库（只在ambari-server安装机器上做）"></a>9.配置mysql作为数据库（只在ambari-server安装机器上做）</h2><p>   查看当前安装数据库信息   rpm  -qa  |   grep   -i   mysql<br>    卸载方法 yum   -y   remove  +name<br>    安装MySQL  查看当前源中是否有提供的MySQL<br>    yum   list  |   grep   mysql<br>    安装mysql-server<br>安装<br>    安装后mysql 只有一个用户root 且第一次开启时需要设置密码，我们这通过命令提前设置                   mysqladmin  -u  root  password  ‘’</p><pre><code>设置为自启动  chkconfig  mysqld  on登录到root用户</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">mysql   -u  root   -p </span><br><span class="line">create  user  ‘amabri’@’% ’    identified   by   ‘bigdata’;</span><br><span class="line">grant   all   privileges   on   *.*    to    ‘ambari’@’%’;</span><br><span class="line">create   user   ‘ambari’@’localhost’   identified   by    ‘bigdata’;</span><br><span class="line">grant    all    privileges   on   *.*   to    ‘ambari’@’localhost’;</span><br><span class="line">create   user   ‘ambari’@’namenode’   identified   by   ‘bigdata’;</span><br><span class="line">grant   all   privileges   on   *.*   to   ‘ambari’@’namenode’;</span><br><span class="line">登录ambari用户</span><br><span class="line">mysql    -u   ambari    -p</span><br><span class="line">bigdata</span><br><span class="line">create  database   ambari;</span><br><span class="line">use  ambari;</span><br></pre></td></tr></table></figure><h2 id="10-部署"><a href="#10-部署" class="headerlink" title="10.部署"></a>10.部署</h2><p> （1） yum安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum  -y  install  ambari-server (每台都要装)</span><br></pre></td></tr></table></figure></p><p>后进入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql -u ambari -p</span><br><span class="line">bigdata</span><br><span class="line">use ambari;</span><br><span class="line">source /var/lib/ambari-server/resources/Ambari-DDL-MySQL-CREATE.sql;</span><br></pre></td></tr></table></figure></p><p> （2） jdk的安装<br>       下载jdk1.8.0_45安装包  放入/usr/lib/jvm/jdk1.8.0_45/ 解压<br>       配置环境变量  /etc/profile 文件最后加上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#Java environment</span><br><span class="line">       JAVA_HOME=/usr/java/jdk1.8.0_45</span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib/</span><br><span class="line">export JAVA_HOME</span><br><span class="line">export PATH</span><br><span class="line">export CLASSPATH</span><br></pre></td></tr></table></figure></p><p>执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_45/bin/java 300 </span><br><span class="line">sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_45/bin/javac 300</span><br><span class="line">sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_45/bin/jar 300</span><br></pre></td></tr></table></figure></p><p>查看当前Java版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java  -version</span><br></pre></td></tr></table></figure></p><p> （3） 安装ambari-server    (安装在一台centos上即可，部署为ambari-server的机器)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ambari-server  setup   -j  /usr/lib/jvm/jdk1.8.0­_45/</span><br></pre></td></tr></table></figure></p><p>安装显示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">Using python  /usr/bin/python</span><br><span class="line"> Setup ambari‐server</span><br><span class="line">  Checking SELinux...</span><br><span class="line"> SELinux status is &apos;enabled&apos;</span><br><span class="line"> SELinux mode is &apos;permissive&apos;</span><br><span class="line">  WARNING: SELinux is set to &apos;permissive&apos; mode and temporarily disabled.</span><br><span class="line"> OK to continue [y/n] (y)?</span><br><span class="line"> Customize user account for ambari‐server daemon [y/n] (n)?</span><br><span class="line"> Adjusting ambari‐server permissions and ownership...</span><br><span class="line">  Checking firewall status...</span><br><span class="line">  Checking JDK...</span><br><span class="line"> WARNING: JAVA_HOME /usr/lib/jvm/jdk1.8.0_45 must be valid on ALL hosts  WARNING: JCE Policy files are required for configuring Kerberos security. If you plan to use Kerberos,please make sure JCE Unlimited</span><br><span class="line">  Completing setup...</span><br><span class="line">  Configuring database...</span><br><span class="line">  Enter advanced database configuration [y/n] (n)? y</span><br><span class="line">  Configuring database...  =============================================================================</span><br><span class="line">  Choose one of the following options:</span><br><span class="line">  [1] ‐ PostgreSQL (Embedded)</span><br><span class="line">  [2] ‐ Oracle</span><br><span class="line">  [3] ‐ MySQL / MariaDB</span><br><span class="line">  [4] ‐ PostgreSQL</span><br><span class="line">  [5] ‐ Microsoft SQL Server (Tech Preview)</span><br><span class="line">  [6] ‐ SQL Anywhere</span><br><span class="line">  [7] ‐ BDB  =============================================================================</span><br><span class="line"> Enter choice (3): 3</span><br><span class="line">  Hostname (localhost):</span><br><span class="line">  Port (3306):</span><br><span class="line">  Database name (ambari):</span><br><span class="line">  Username (ambari):</span><br><span class="line">  Enter Database Password (bigdata):</span><br><span class="line">  Configuring ambari database...</span><br><span class="line">  Copying JDBC drivers to server resources...</span><br><span class="line">  Configuring remote database connection properties...</span><br><span class="line">WARNING: Before starting Ambari Server, you must run the following DDL against the databa se to create the schema: /var/lib/ambari</span><br><span class="line"> Proceed with configuring remote database connection properties [y/n] (y)? y</span><br><span class="line">  Extracting system views...............</span><br><span class="line">  Adjusting ambari‐server permissions and ownership...</span><br><span class="line">  Ambari Server &apos;setup&apos; completed successfully.</span><br></pre></td></tr></table></figure></p><p> （4）启动ambari-server<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ambari-server start</span><br></pre></td></tr></table></figure></p><pre><code>启动成功后通过：http：//namenode:8080访问登录账号及密码：admin</code></pre><p> （6） 进程操作<br>    1.查看ambari进程<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps   -ef   |   grep   ambari</span><br></pre></td></tr></table></figure></p><pre><code>2.停止ambari进程</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ambari-server  stop</span><br></pre></td></tr></table></figure><pre><code>3.重启ambari进程</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ambari-server  restart</span><br></pre></td></tr></table></figure><p> （7） 修改端口<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi   /etc/ambari-server/conf/ambari.properties</span><br></pre></td></tr></table></figure></p><pre><code>插入或编辑以下内容Client.api.port = &lt;port_number&gt;</code></pre><h2 id="11-安装ambari-agent-每台机器都要装"><a href="#11-安装ambari-agent-每台机器都要装" class="headerlink" title="11 安装ambari-agent(每台机器都要装)"></a>11 安装ambari-agent(每台机器都要装)</h2><pre><code>1.安装ambari-agent</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum   install  ambari-agent</span><br></pre></td></tr></table></figure><pre><code>2.配置</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi  /etc/ambari-agent/conf/ambari-agent.ini</span><br></pre></td></tr></table></figure><pre><code>插入或更改以下内容hostname = namenode</code></pre><p>最后<br>使用谷歌浏览器登录：<a href="http://namenode:8080" target="_blank" rel="noopener">http://namenode:8080</a>        账号：admin    密码：admin<br>注意：选择操作系统时，应该选择当前机器的版本。如果是本地源，<br>则需要修改HDP、HDP-UTILS的位置</p><p>If you are lucky enough, that I wish you success.<br>Said too much, tears.</p><p>如果出现ip绑定问题，修改/etc/hosts/中的ip为每台机器的真实ip<br>查看ip命令ifconfig<br>出现mysql  drive驱动问题   yum  install  mysql-connector-java</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-物理条件：三台centos&quot;&gt;&lt;a href=&quot;#1-物理条件：三台centos&quot; class=&quot;headerlink&quot; title=&quot;1.物理条件：三台centos&quot;&gt;&lt;/a&gt;1.物理条件：三台centos&lt;/h2&gt;&lt;p&gt;前期条件：修改每台centos的名称
      
    
    </summary>
    
      <category term="搭建" scheme="http://www.wenchong.top/categories/%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="ambari" scheme="http://www.wenchong.top/tags/ambari/"/>
    
  </entry>
  
  <entry>
    <title>centos和Ubuntu本地源制作</title>
    <link href="http://www.wenchong.top/2017/08/05/centos%E5%92%8CUbuntu%E5%88%B6%E4%BD%9C%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    <id>http://www.wenchong.top/2017/08/05/centos和Ubuntu制作本地源/</id>
    <published>2017-08-04T16:00:00.000Z</published>
    <updated>2018-02-18T17:01:39.140Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="CentOS系统"><a href="#CentOS系统" class="headerlink" title="CentOS系统"></a>CentOS系统</h2><ul><li>使用yum安装软件时，下载的* .rpm包缓存在/var/cache/yum/x86_64/7/；</li><li>创建目录</li><li>用于存放特定软件所需的软件包；</li></ul><p>mkdir -p /opt/packages</p><ul><li>下载软件包<br>yum install -y –downloadonly –downloaddir=/opt/packages python-openstackclient</li><li>生成repo文件<br>yum install -y createrepo</li></ul><p>createrepo /opt/packages</p><ul><li>生成压缩包</li></ul><p>tar -zcf packages.tgz packages/</p><ul><li>配置本地源</li></ul><p>tar -zxf packages.tgz -C /opt<br>vim /etc/yum.repos.d/local.repo</p><p>[Local]<br>name=Local Yum<br>baseurl=file:////opt/packages/<br>gpgcheck=0<br>enabled=1</p><ul><li>客户端安装软件：<br>yum install python-openstackclient<h2 id="Ubuntu系统"><a href="#Ubuntu系统" class="headerlink" title="Ubuntu系统"></a>Ubuntu系统</h2></li><li>使用apt命令安装软件时，下载的* .deb包缓存在/var/cache/apt/archives/；</li><li>创建目录</li><li>用于存放特定软件所需的软件包；</li></ul><p>mkdir -p /opt/packages</p><ul><li>下载软件包</li><li>清除旧的缓存：</li></ul><p>rm -f /var/cache/apt/archives/* .deb</p><ul><li>下载软件包：</li></ul><p>apt install -d -y –force-yes PACKAGE-NAME</p><ul><li>拷贝软件包</li></ul><p>cp /var/cache/apt/archives/* .deb /opt/packages/</p><ul><li>生成Packages.gz包<br>Packages.gz中包含软件包信息以及其依赖关系信息；</li><li>安装dpkg-dev以便使用dpkg-scanpackages命令生成Packages.gz文件；</li></ul><p>apt install -y dpkg-dev</p><ul><li>单机版本地源</li><li>此处忽略一切的警告(warning)；</li></ul><p>cd /opt/<br>dpkg-scanpackages packages/ /dev/null | gzip &gt; /opt/packages/Packages.gz -r</p><ul><li>制作成压缩包，便于网络传输；</li></ul><p>cd /opt/<br>tar -zcf packages.tgz packages/</p><ul><li><p>将压缩包拷贝到目标主机；</p></li><li><p>解压压缩包并配置软件源(目标主机)：</p></li></ul><p>tar -zxf packages.tgz -C /opt<br>echo ‘deb file:///opt/ packages/‘ &gt; /etc/apt/sources.list</p><ul><li><p>临时的Web共享本地源</p></li><li><p>此处忽略一切的警告(warning)；</p></li></ul><p>cd /opt/packages/<br>dpkg-scanpackages . /dev/null | gzip &gt; /opt/packages/Packages.gz -r</p><ul><li>使用Python自带的SimpleHTTPServer会在当前目录启动一个简易的Web服务器；</li></ul><p>cd /opt/packages/<br>python -m SimpleHTTPServer PORT</p><ul><li>配置软件源(目标主机):<br>echo ‘deb <a href="http://IP:PORT/" target="_blank" rel="noopener">http://IP:PORT/</a> /‘ &gt; /etc/apt/sources.list</li><li><p>搭建Web服务共享本地源</p></li><li><p>搭建主流的Web服务：Apache服务或Nginx服务；</p></li><li>配置Web服务，根目录指向/opt/packages/；</li><li>配置软件源(目标主机):<br>echo ‘deb <a href="http://IP:PORT/" target="_blank" rel="noopener">http://IP:PORT/</a> /‘ &gt; /etc/apt/sources.list</li><li>安装软件(目标主机)<br>apt update<br>apt install -y –force-yes PACKAGE-NAME</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;CentOS系统&quot;&gt;&lt;a href=&quot;#CentOS系统&quot; cla
      
    
    </summary>
    
      <category term="本地源" scheme="http://www.wenchong.top/categories/%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    
    
      <category term="本地源" scheme="http://www.wenchong.top/tags/%E6%9C%AC%E5%9C%B0%E6%BA%90/"/>
    
  </entry>
  
  <entry>
    <title>HDFS手动优化</title>
    <link href="http://www.wenchong.top/2017/07/11/HDFS%E6%89%8B%E5%8A%A8%E4%BC%98%E5%8C%96%20/"/>
    <id>http://www.wenchong.top/2017/07/11/HDFS手动优化 /</id>
    <published>2017-07-10T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:24.090Z</updated>
    
    <content type="html"><![CDATA[<h3 id="只记录那二年踏过的坑"><a href="#只记录那二年踏过的坑" class="headerlink" title="只记录那二年踏过的坑"></a>只记录那二年踏过的坑</h3><h2 id="一-Linux文件系统参数调整"><a href="#一-Linux文件系统参数调整" class="headerlink" title="一 Linux文件系统参数调整"></a>一 Linux文件系统参数调整</h2><p>（1） noatime 和 nodiratime属性<br>文件挂载时设置这两个属性可以明显提高性能。。默认情况下，Linux ext2/ext3 文件系统在文件被访问、创建、修改时会记录下文件的时间戳，比如：文件创建时间、最近一次修改时间和最近一次访问时间。如果系统运行时要访问大量文件，关闭这些操作，可提升文件系统的性能。Linux 提供了 noatime 这个参数来禁止记录最近一次访问时间戳。<br>（2） readahead buffer<br>调整linux文件系统中预读缓冲区地大小，可以明显提高顺序读文件的性能。默认buffer大小为256 sectors，可以增大为1024或者2408 sectors（注意，并不是越大越好）。可使用blockdev命令进行调整。<br>（3） 避免RAID和LVM操作<br>避免在TaskTracker和DataNode的机器上执行RAID和LVM操作，这通常会降低性能。<br>3.2.2 Hadoop通用参数调整<br>（1） dfs.namenode.handler.count或mapred.job.tracker.handler.count<br>amenode或者jobtracker中用于处理RPC的线程数，默认是10，较大集群，可调大些，比如64。<br>（2） dfs.datanode.handler.count<br>datanode上用于处理RPC的线程数。默认为3，较大集群，可适当调大些，比如8。需要注意的是，每添加一个线程，需要的内存增加。<br>（3） tasktracker.http.thread<br>HTTP server上的线程数。运行在每个TaskTracker上，用于处理map task输出。大集群，可以将其设为40~50。</p><h2 id="二-HDFS相关配置"><a href="#二-HDFS相关配置" class="headerlink" title="二 HDFS相关配置"></a>二 HDFS相关配置</h2><p>（1） dfs.replicatio<br>文件副本数，通常设为3，不推荐修改。<br>（2） dfs.block.size<br>HDFS中数据block大小，默认为64M，对于较大集群，可设为128MB或者256MB。（也可以通过参数mapred.min.split.size配置）<br>（3） mapred.local.dir和dfs.data.dir<br>这两个参数mapred.local.dir和dfs.data.dir 配置的值应当是分布在各个磁盘上目录，这样可以充分利用节点的IO读写能力。运行 Linux sysstat包下的iostat -dx 5命令可以让每个磁盘都显示它的利用率。<br>3.2.4 map/reduce 相关配置<br>（1） {map/reduce}.tasks.maximum<br>同时运行在TaskTracker上的最大map/reduce task数，一般设为(core_per_node)/2~2*（cores_per_node）。<br>（2） io.sort.factor<br>当一个map task执行完之后，本地磁盘上(mapred.local.dir)有若干个spill文件，map task最后做的一件事就是执行merge sort，把这些spill文件合成一个文件（partition）。执行merge sort的时候，每次同时打开多少个spill文件由该参数决定。打开的文件越多，不一定merge sort就越快，所以要根据数据情况适当的调整。<br>（3） mapred.child.java.opt<br>设置JVM堆的最大可用内存，需从应用程序角度进行配置。</p><h2 id="三-map-task相关配置"><a href="#三-map-task相关配置" class="headerlink" title="三 map task相关配置"></a>三 map task相关配置</h2><p>（1） io.sort.m<br>Map task的输出结果和元数据在内存中所占的buffer总大小。默认为100M，对于大集群，可设为200M。当buffer达到一定阈值，会启动一个后台线程来对buffer的内容进行排序，然后写入本地磁盘(一个spill文件)。<br>（2） io.sort.spill.percent<br>这个值就是上述buffer的阈值，默认是0.8，即80%，当buffer中的数据达到这个阈值，后台线程会起来对buffer中已有的数据进行排序，然后写入磁盘。<br>（3） io.sort.record<br>Io.sort.mb中分配给元数据的内存百分比，默认是0.05。这个需要根据应用程序进行调整。<br>（4） mapred.compress.map.output/ Mapred.output.compre<br>中间结果和最终结果是否要进行压缩，如果是，指定压缩方式（Mapred.compress.map.output.codec/ Mapred.output.compress.codec）。推荐使用LZO压缩。Intel内部测试表明，相比未压缩，使用LZO压缩的TeraSort作业运行时间减少60%，且明显快于Zlib压缩。<br>3.2.6 reduce task相关配置<br>（1） Mapred.reduce.parallel<br>Reduce shuffle阶段copier线程数。默认是5，对于较大集群，可调整为16~25。</p><h2 id="四-通过hadoop的参数进行调优"><a href="#四-通过hadoop的参数进行调优" class="headerlink" title="四 通过hadoop的参数进行调优"></a>四 通过hadoop的参数进行调优</h2><p>(1):设置合理的槽位数目(具体配置 mapred.tasktracker.map.tasks.maximum | mapred.tasktracker.reduce.tasks.maximum |<br>     mapreduce.tasktracker.map.tasks.maximum | mapreduce.tasktracker.reduce.tasks.maximum)<br>(2):调整心跳间隔,对于300台以下的集群 可以把心跳设置成300毫秒(默认是3秒),mapreduce.jobtracker.hearbeat.interval.min | mapred.hearbeats.in.second | mapreduce.jobtracker.heartbeats.scaling.factor<br>(3):启用外心跳,为了减少任务分配延迟(比如我们的任务心跳设置为10秒钟,当有一个任务挂掉了之后,他就不能马上通知jobtracker),<br>所以hadoop引入了外心跳,外心跳是任务运行结束或者任务运行失败的时候触发的,能够在出现空闲资源时第一时间通知jobtracker,以便他能够迅速为空闲资源分配新的任务<br>外心跳的配置参数是 mapreduce.tasktracker.outofband.hearbeat<br>   (4):磁盘快的配置. map task会把中间结果放到本地磁盘中,所以对于I/O密集的任务来说这部分数据会对本地磁盘造成很大的压力,我们可以配置多块可用磁盘,hadoop将采用轮训的方式将不同的maptask的中间结果写到磁盘上<br>                    maptask中间结果的配置参数是mapred.local.dir | mapreduce.cluster.local.dir<br>   (5):配置RPC Handler的数量,jobracker需要冰法处理来自各个tasktracker的RPC请求,我们可以根据集群规模和服务器并发处理的情况调整RPC Handler的数目,以使jobtracker的服务能力最佳<br>    配置参数是 mapred.job.tracker.handler.count | mapreduce.jobtracker.handler.count  (默认是10)<br>   (6):配置HTTP线程数.  在shuffle阶段,reduce task 通过http请求从各个tasktracker上读取map task中间结果,而每个tasktracker通过jetty server处理这些http请求,所以可以适当配置调整jetty server的工作线程数<br>    配置参数是 tasktracker.http.thread | mapreduce.tasktracker.http.threads  (默认是40)<br>   (7):如果我们在运行作业的过程中发现某些机器被频繁地添加到黑名单里面,我们可以把此功能关闭<br>   (8):使用合理调度器<br>   (9):使用合适的压缩算法,在hadoop里面支持的压缩格式是: gzip,zip,bzip2,LZO,Snappy,LZO和Snappy的呀搜比和压缩效率都很优秀,Snappy是谷歌的开源数据压缩哭,他已经内置在hadoop1.0之后的版本,LZO得自己去编译<br>   (10):开启预读机制. 预读机制可以有效提高磁盘I/O的读性能,目前标准版的apache hadoop不支持此功能,但是在cdh中是支持的<br>    配置参数是: mapred.tasktracker.shuffle.fadvise=true (是否启用shuffle预读取机制)<br>              mapred.tasktracker.shuffle.readahead.bytes=4MB (shuffle预读取缓冲区大小)<br>              mapreduce.ifile.readahead = true (是否启用ifile预读取机制)<br>              mapreduce.ifile.readahead.bytes = 4MB (IFile预读取缓冲区大小)<br>   (11):启用推测执行机制<br>   (12):map task调优: 合理调整io.sort.record.percent值,可减少中间文件数据,提高任务执行效率.<br>    (map task的输出结果将被暂时存放到一个环形缓冲区中,这个缓冲区的大小由参数”io.sort.mb”指定,单位MB,默认是100MB,<br>    该缓冲区主要由两部分组成,索引和实际数据,默认情况下,索引占整个buffer的比例为io.sort.record.percent,默认是5%,<br>    剩余空间存放数据,仅当满足以下任意一个条件时才会触发一次flush,生成一个临时文件,索引或者数据空间使用率达到比例为<br>    io.sort.spill.percent的80%)<br>    所以具体调优参数如下:  io.sort.mb | io.sort.record.percent | io.sort.spill.percent<br>    (13):reduce task调优   reduce task会启动多个拷贝线程从每个map task上读取相应的中间结果,参数是”mapred.reduce.parallel.copies”(默认是5)<br>    原理是这样的–&gt;对于每个待拷贝的文件,如果文件小于一定的阀值A,则将其放入到内存中,否则已文件的形式存放到磁盘上,<br>    如果内存中文件满足一定条件D,则会将这些数据写入磁盘中,而当磁盘上文件数目达到io.sort.factor(默认是10)时,<br>    所以如果中间结果非常大,可以适当地调节这个参数的值<br>    (14):跳过坏记录 看具体参数说明,=号后面是默认值<br>    mapred.skip.attempts.to.start.skipping=2 当任务失败次数达到该值时,才会进入到skip mode,即启用跳过坏记录gongnneg<br>    mapred.skip.map.max,skip.records=0 用户可通过该参数设置最多运行跳过的记录数目<br>    mapred.skip.reduce.max.skip.groups=0 用户可通过设置该参数设置Reduce Task最多允许跳过的记录数目<br>    mapred.skip.out.dir =${mapred.output.dir}/logs/ 检测出得坏记录存放到目录里面(一般为HDFS路径),hadoop将坏记录保存起来以便于用户调试和跟踪</p><pre><code>(15):使用JVM重用 : mapred.job.reuse.jvm.aum.tasks | mapreduce.job.jvm.num.tasks = -1</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;只记录那二年踏过的坑&quot;&gt;&lt;a href=&quot;#只记录那二年踏过的坑&quot; class=&quot;headerlink&quot; title=&quot;只记录那二年踏过的坑&quot;&gt;&lt;/a&gt;只记录那二年踏过的坑&lt;/h3&gt;&lt;h2 id=&quot;一-Linux文件系统参数调整&quot;&gt;&lt;a href=&quot;#一-Linu
      
    
    </summary>
    
      <category term="HDFS" scheme="http://www.wenchong.top/categories/HDFS/"/>
    
    
      <category term="HDFS" scheme="http://www.wenchong.top/tags/HDFS/"/>
    
  </entry>
  
  <entry>
    <title>java读取Excel表格中的数据</title>
    <link href="http://www.wenchong.top/2017/05/20/java%E8%AF%BB%E5%8F%96Excel%E8%A1%A8%E6%A0%BC%E6%95%B0%E6%8D%AE/"/>
    <id>http://www.wenchong.top/2017/05/20/java读取Excel表格数据/</id>
    <published>2017-05-19T16:00:00.000Z</published>
    <updated>2018-02-18T17:03:56.955Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-需求"><a href="#1-需求" class="headerlink" title="1.需求"></a>1.需求</h3><p>用java代码读取Excel.xls表格中的数据</p><h3 id="2-java代码"><a href="#2-java代码" class="headerlink" title="2.java代码"></a>2.java代码</h3><p>package com.test;<br>import java.io.File;<br>import jxl.*;<br>public class ReadExcel{<br>    public static void main(String[] args){<br>        ing i;<br>        Sheet sheet;<br>        Workbook book;<br>        Cell cell1,cell2,cell3,cell4,cell5,cell6,cell7;<br>        try{</p><pre><code>        //Excel.xls为要读取的excel文件        book = Workbook.getWorkbook(new File(&quot;文件物理地址&quot;)))；        //获取第一个工作表对象（excel中sheet的编号从0开始，0,1,2,3，.....）        sheet = book.getSheet(0);        //获取左上角的单元格        cell1 = sheet.getCell(0,0);(行，列)        System.out.println(&quot;标题：&quot;+cell1.getContents());        i = 1;        while(true){            //获取每一行单元格            cell1 = sheet.getCell(0,i);            cell2 = sheet.getCell(1,i);            cell3 = sheet.getCell(2,i);            cell4 = sheet.getCell(3,i);            cell5 = sheet.getCell(4,i);            cell6 = sheet.getCell(5,i);            cell7 = sheet.getCell(6,i);            if(&quot;&quot;.equals(cell1.getContents()) == true) //如果读取的数据为空            break;            System.out.println(cell1.getContents()+&quot;\t&quot;+cell2.getContents()+&quot;\t&quot;+cell3.getContents()+&quot;\t&quot;+cell4.getContents()+&quot;\t&quot;+cell5.getContents()+&quot;\t&quot;+cell6.getContents()+&quot;\t&quot;);            i++;        }        book.close();    }    catch(Exceprion e){        }}</code></pre><p>}</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-需求&quot;&gt;&lt;a href=&quot;#1-需求&quot; class=&quot;headerlink&quot; title=&quot;1.需求&quot;&gt;&lt;/a&gt;1.需求&lt;/h3&gt;&lt;p&gt;用java代码读取Excel.xls表格中的数据&lt;/p&gt;
&lt;h3 id=&quot;2-java代码&quot;&gt;&lt;a href=&quot;#2-jav
      
    
    </summary>
    
      <category term="study-Java" scheme="http://www.wenchong.top/categories/study-Java/"/>
    
    
      <category term="Java" scheme="http://www.wenchong.top/tags/Java/"/>
    
  </entry>
  
</feed>
